---
title: March 2025
date: 2025-03-31
categories: [Newsletters]
tags: [Clinical Trials, LLM, Multimodal AI, Patient Recruitment, Drug Discovery, Treatment Effect, Safety Monitoring, Data Privacy, Explainability, Federated Learning]
description: This issue explores advancements in AI and machine learning impacting clinical research, focusing on patient recruitment, trial design optimization, treatment effect analysis, safety monitoring, secure data architectures, and ensuring AI trustworthiness. The described progress emphasizes the transformative potential of AI while acknowledging existing challenges such as data biases, computational intensity, and the need for interpretability and ethical considerations.
---

# Introduction

The ongoing evolution of artificial intelligence (AI) and machine learning (ML), particularly the advent of Large Language Models (LLMs) and multimodal AI, is fundamentally reshaping the landscape of clinical research. The advancements presented focus on optimizing the entire clinical trial lifecycle, from initial patient identification and recruitment to complex trial design, robust treatment effect analysis, and enhanced safety monitoring. This encompasses innovations in processing complex clinical information, enabling secure data architectures through generative AI, and establishing frameworks to ensure the trustworthiness and transparency of AI-driven systems. By integrating advanced computational capabilities with clinical domain knowledge, these developments aim to accelerate drug discovery, facilitate the personalization of therapeutic interventions, and ultimately improve patient outcomes.

# Revolutionizing Patient Recruitment & Eligibility

Patient recruitment and eligibility screening remain formidable bottlenecks in clinical trials, often leading to significant delays and increased costs [1]. Traditional manual chart reviews are labor-intensive, error-prone, and struggle with the increasing complexity of eligibility criteria [2]. Emerging AI, particularly Large Language Models (LLMs), is revolutionizing this landscape by automating key processes, enhancing efficiency, and improving patient engagement.

A significant advancement comes from the application of multimodal LLMs that can directly process unstructured Electronic Health Record (EHR) data, including images, without relying on error-prone and time-consuming image-to-text conversions (Optical Character Recognition, OCR) [1]. This approach leverages the visual capabilities of modern LLMs and multimodal embeddings for efficient medical record search, enabling interpretation of complex visual information such as tables, charts, and handwritten notes. The pipeline introduced in [1] demonstrated an 80% improvement in pre-screening time compared to manual chart reviews, achieving high criterion-level accuracy. The rationale behind this is that direct visual processing avoids information loss inherent in converting visual data to text, allowing LLMs to fully leverage comprehensive patient information. Despite these gains, challenges persist in replicating nuanced human decision-making, differentiating between firm and uncertain assessments, and reliably aggregating criterion-level decisions into definitive patient-level recommendations, especially when medical records are incomplete [1]. These models often struggle with the inherent ambiguity and variability found in real-world clinical presentations and terminology [3]. The need for human-in-the-loop validation is thus crucial to ensure accuracy and build trust [4]. Related systems like `TrialMatchAI` also leverage fine-tuned LLMs and Retrieval-Augmented Generation (RAG) frameworks to automate patient-to-trial matching, focusing on explainability and traceability by providing decision rationales [5].

LLMs are also proving instrumental in automating disease detection and constructing comprehensive patient journey representations. By analyzing unstructured EHR data, LLMs can automate disease identification, streamlining recruitment and facilitating real-time disease surveillance [3]. However, their generalizability across diverse populations and potential for false positives remain areas for improvement. To capture the full spectrum of patient experiences, Patient Journey Knowledge Graphs (PJKGs) are being constructed using LLMs to integrate diverse patient information, including formal clinical documentation and unstructured patient-provider conversations [6]. PJKGs employ an ontology to define relationships between clinical encounters, diagnoses, treatments, and outcomes. LLMs perform entity and relationship extraction from raw text (e.g., transcribed conversations), structuring this fragmented data into a unified, semantically rich graph. This enables advanced temporal and causal reasoning, allowing for a holistic understanding of a patient's health trajectory, which is invaluable for matching individuals to trials based on detailed eligibility criteria and for designing patient-centric trials [6]. Despite their promise, current PJKG construction methods are limited by dataset size, a reliance on general-purpose LLMs without extensive fine-tuning, and a lack of seamless integration with full EHRs, which can hinder the capture of comprehensive patient journeys [6]. The broader field of Natural Language Processing (NLP) in clinical trial eligibility matching, as surveyed in [2], emphasizes the need for advanced semantic and temporal representations, expanded data integration, and rigorous evaluations to fully realize NLP's transformative potential.

Beyond matching, LLMs are improving patient communication and the critical informed consent process. The `FollowupQ` framework demonstrates how multi-agent LLM systems can process patient messages and EHR data to automatically generate personalized follow-up questions, thereby reducing conversational ambiguity and provider communication burden. This can lead to more efficient pre-screening of potential trial participants and more structured data collection throughout a trial [7]. Furthermore, `InformGen` is an AI copilot that leverages LLMs with optimized document parsing and a human-in-the-loop system to draft highly accurate and compliant informed consent forms (ICFs) [8]. This system achieves near-perfect compliance with FDA regulations and significantly enhances factual accuracy through iterative refinement with human experts. The underlying mechanism involves RAG wherein LLMs dynamically access and synthesize information from clinical trial protocols to generate consent text, ensuring traceability via inline citations [8]. This not only accelerates ICF development but also contributes to ethical and legally sound clinical research. The drive for patient-initiated trial matching is also being addressed by developing datasets like NLI4PR, which rephrases medical language into patient-friendly terms, empowering individuals to assess their own eligibility for clinical trials directly [9]. This shift promotes patient engagement and broadens participation but highlights the challenge of ensuring accurate interpretation of lay language. The general application of LLMs in outpatient referral systems further underscores their utility in guiding patients efficiently through healthcare pathways, including initial eligibility assessments for trials [10].

In summary, AI-powered LLMs are revolutionizing patient recruitment by automating complex eligibility assessments, streamlining data extraction from diverse sources, enhancing patient communication, and ensuring regulatory compliance in document generation. While significant progress has been made, challenges related to data quality, generalizability, the need for robust validation in real-world settings, and the delicate balance between automation and essential human oversight remain crucial considerations for the responsible and effective deployment of these transformative technologies.

# AI-Driven Optimization of Trial Design and Outcomes

AI-driven advancements are profoundly reshaping the landscape of clinical trial design and execution, fostering more adaptive, efficient, and personalized approaches. These innovations span the optimization of dosage levels, dynamic adjustments to trial parameters, and sophisticated predictive models for patient stratification and outcome forecasting, ultimately aiming to accelerate timelines and enhance decision-making through simulation and advanced analytics.

One significant area of progress lies in **optimizing dosage and dynamic treatment regimens**. The contextual bandit framework, typically used for sequential optimization, has been adapted to clinical trials to accelerate dosage optimization. A notable approach conditions a Bayesian Gaussian Process model on the concavity of the mean reward function, reflecting common dose-response curves where increasing dosage eventually yields diminishing returns or increased adverse effects [11]. This method balances exploration and exploitation, crucial for patient safety and data gathering in trials. However, its effectiveness hinges on the concavity assumption, which may not hold for all drug interactions, and the computational intensity of Gaussian Processes can limit scalability [11]. Complementing this, frameworks like Randomize First Augment Next (RFAN) integrate active learning to guide patient recruitment and treatment assignment in Phase III trials, aiming to derive effective treatment policies, especially for underserved populations, and incorporating early stopping strategies for efficiency [12]. Despite promising empirical results on synthetic and semi-synthetic data, the real-world regulatory acceptance and logistical complexity of implementing Bayesian active learning remain challenges [12]. Further, the Earliest Disagreement Q-Evaluation (EDQ) framework addresses the complex problem of off-policy evaluation in dynamic treatment regimes (DTRs) with irregularly sampled data, crucial for optimizing treatment timing and personalized strategies [13]. While compatible with sequence models like transformers, its theoretical guarantees rely on strong ignorability assumptions, and its validation primarily on simulated data necessitates real-world testing [13]. These efforts align with broader research in estimating heterogeneous treatment effects from time-varying treatments and covariates, often leveraging representation balancing techniques and neural architectures to handle temporal dependencies and control bias from treatment-confounder feedback [14]. Techniques like Deconfounded Warm-Start Thompson Sampling [15] demonstrate how leveraging insights from confounded observational data can improve trial efficiency. The concept of "emulated clinical trials" [16] further explores how to compare proposed DTRs against a "standard of care" derived from observational data, addressing the gap between optimal decision rules and current clinical practice. Model-based reinforcement learning with latent imagination, such as MedDreamer, shows promise in refining policies using real and imagined experiences on complex, irregular EHRs, moving beyond suboptimal historical decisions [17].

Another critical aspect involves **leveraging real-world data for patient stratification and outcome prediction**. The Deep Causal Behavioral Policy Learning (DC-BPL) framework offers a novel approach to learning and emulating optimal clinical behavioral policies from electronic health records (EHRs) [18]. This capability can inform trial design by identifying optimal treatment strategies for specific patient subgroups, predict patient adherence, and integrate real-world evidence to enhance the generalizability of trial findings. The underlying large clinical behavioral model (LCBM) uses a transformer architecture to encode tacit clinical knowledge [18]. However, DC-BPL's performance is highly dependent on the quality and representativeness of EHR data, and its causal inferences rely on strong, often untestable, assumptions about unmeasured confounding. Challenges also arise from generalizability across healthcare settings, interpretability of deep learning models, and ethical concerns regarding data privacy and algorithmic bias [18]. Similarly, the TS4NAP approach leverages medical taxonomies and graph matching to predict next activities in patient treatment pathways, which can optimize patient enrollment and enhance protocol design by anticipating potential treatment sequences and complications [19]. This approach's reliance on specific taxonomies and high computational complexity limit its broader applicability, and its validation on the MIMIC-IV dataset needs further confirmation in a real-world clinical trial setting [19]. For robust risk prediction and patient stratification, a comprehensive benchmarking study of machine learning (ML) methods on large-scale survival data, such as the UK Biobank, found that simpler penalized COX-PH models often perform robustly, while more complex models like LightGBM can also be effective [20]. The choice of model depends on endpoint frequency and predictor matrix properties, underscoring the trade-off between complexity and interpretability, a crucial factor in clinical decision-making [20]. Predictive modeling leveraging EHRs and advanced ML algorithms, including ensemble and deep learning methods, shows potential for improving patient care, resource allocation, and proactive healthcare management [21]. The utility of such models can be enhanced by methods that learn the multi-outcome distribution of medical treatments, capturing interdependencies between various outcomes like efficacy, complications, and adverse events [22]. Furthermore, advancements in synthetic EHR generation, including diffusion-based methods like TarDiff, aim to produce utility-optimized data to improve downstream model performance and address data scarcity and class imbalance [23], while the use of LLMs and Small Language Models (SLMs) for tasks like drug overdose prediction [24] and clinical trial outcome prediction [25] offers promising avenues, despite challenges in preserving realistic data distributions and ensuring interpretability [27]. Foundation models for structured EHRs are also being evaluated for their clinical utility across various tasks, aiming to advance robust evaluation metrics for these powerful models [28].

Finally, AI is contributing to **optimizing trial operations and resource allocation**. Determining appropriate sample sizes is critical for developing reliable ML models in medical research. A proposed method focuses on calculating sample sizes for both training and testing sets, particularly for binary outcomes, ensuring adequate statistical power for model development and validation [29]. While straightforward, this method's reliance on prior performance estimates and focus on binary outcomes are limitations [29]. Beyond statistical considerations, generative AI is being explored for reconstructing Discrete-Event Simulation (DES) models from published research, enabling *in silico* clinical trial optimization, resource allocation, and adaptive trial designs through simulation [30]. Automating model creation can reduce development time, but it requires significant human oversight, including prompt engineering, code testing, and validation, as generative AI models are prone to errors and inconsistencies, especially for complex scenarios [30]. The need for robust, reliable, and interpretable AI in healthcare necessitates thorough Uncertainty Quantification (UQ) throughout the ML pipeline [31]. Frameworks like CREDO provide distribution-free upper bounds on the probability of suboptimal decisions, bridging algorithmic tools with human judgment in high-stakes settings [32].

In conclusion, AI is driving a paradigm shift in clinical trial design, moving towards more dynamic, patient-centric, and data-driven approaches. While these advancements offer substantial benefits in optimizing dosage, streamlining patient enrollment, and forecasting outcomes, their successful translation to real-world clinical practice hinges on addressing critical limitations related to data quality, causal inference assumptions, generalizability across diverse populations, interpretability of complex models, and computational feasibility. Continued research focused on these challenges will be crucial for realizing the full transformative potential of AI in accelerating drug development and delivering personalized medicine.

# Advanced Analytics for Treatment Effects and Safety

The landscape of clinical trials is being profoundly reshaped by the integration of advanced artificial intelligence (AI) and machine learning (ML) methodologies. These innovations promise to enhance both the precision of treatment effect analysis and the robustness of proactive safety monitoring throughout the drug development lifecycle. By moving beyond traditional aggregate analyses, AI-driven approaches are enabling a more granular understanding of direct and indirect treatment impacts, facilitating the prediction of complex drug interactions, and identifying heterogeneous patient responses. Simultaneously, automated systems for adverse event detection and adjudication are accelerating signal detection, thereby significantly improving patient safety.

### Precision in Treatment Effect Estimation and Heterogeneous Responses

A critical advancement in clinical analytics involves moving beyond the average treatment effect (ATE) to uncover individual treatment effects (ITEs) and conditional average treatment effects (CATEs). This personalization is paramount for optimizing therapeutic strategies and identifying patient subgroups that stand to benefit most from specific interventions.

**Causal Mediation Analysis** is vital for dissecting how treatments exert their effects. Zenati et al. introduce a Double Machine Learning (DML) algorithm for mediation analysis that accommodates continuous treatments and high-dimensional mediators [33]. This approach employs a kernel-based doubly robust moment function with asymptotic Neyman orthogonality, enabling robust estimation of direct and indirect treatment effects even when nuisance parameters are estimated non-parametrically. This is particularly useful for optimizing drug dosages and identifying biomarkers by understanding the pathways through which interventions influence outcomes. However, its practical adoption in clinical trials is challenged by regularity assumptions, the need for careful bandwidth selection, potential computational costs, and the interpretability of complex underlying ML models [33].

**Heterogeneous Causal Discovery** from observational data is addressed by Adhikari et al. through a novel framework that uses an ensemble of causal structure learning (CSL) algorithms to discover causes and effect modifiers for repeated undesirable health outcomes [34]. This ensemble approach enhances robustness and confidence in causal hypotheses by mitigating the impact of untestable assumptions (e.g., causal sufficiency, faithfulness) inherent in single CSL algorithms. It identifies effect modifiers by analyzing interactions and dependencies within causal graphs, enabling the tailoring of interventions to specific patient subpopulations. While promising for informing inclusion/exclusion criteria and personalizing treatment, its reliance on observational data makes it susceptible to confounding, and the complexity of its computational framework may pose scalability challenges [34].

The development of causal estimators has traditionally been a problem-specific, time-consuming endeavor. Bynum et al. propose **Black Box Causal Inference (BBCI)**, a meta-learning approach that re-frames causal inference as a dataset-level prediction problem [35]. BBCI learns to predict causal effects (ATEs and CATEs) from sampled dataset-effect pairs derived from structural causal models (SCMs), without requiring explicit analytic derivation for each identification setting. This "black-box" nature allows it to generalize across various causal inference problems. However, the method's computational cost during meta-training and the necessity of a well-designed SCM-sampler to accurately represent real-world data-generating processes remain key limitations [35].

Addressing confounding bias, especially in real-world observational data, is a persistent challenge. De Bartolomeis et al. introduce **RAMEN**, an algorithm for doubly robust identification of treatment effects from multiple heterogeneous data sources [36]. RAMEN can estimate treatment effects even in the presence of unobserved confounders and "bad controls" (variables that introduce bias when adjusted for), without needing to explicitly know the underlying causal graph. Its double robustness property ensures identification if either the causal parents of the treatment or the outcome are observed and satisfy an invariance assumption. Despite its robustness, RAMEN requires sufficient heterogeneity across data sources and assumes no observed mediators between treatment and outcome, and its kernel-based methods can be computationally intensive for large datasets [36].

In decentralized healthcare settings, data privacy concerns necessitate federated learning approaches. Yin et al. developed **FED-IPTW**, a federated Inverse Probability Treatment Weighting (IPTW) algorithm for individual treatment effect (ITE) estimation [37]. This method extends IPTW to a federated setting by enforcing both global and local decorrelation between covariates and treatments, thereby mitigating confounding bias in decentralized data. FED-IPTW enables personalized treatment strategies while preserving data privacy, crucial for multi-institutional clinical collaborations. Its effectiveness, however, relies on assumptions like consistency, positivity, and strong ignorability within each client, and performance is sensitive to the accuracy of propensity score estimation. Sharing some statistical information (e.g., means of covariates and treatments) is also a prerequisite, which might still raise privacy concerns in highly restrictive environments [37].

Further advancing ITE estimation, Mehendale et al. propose **KANITE**, a framework leveraging Kolmogorov-Arnold Networks (KANs) for ITE estimation under multiple treatments [38]. KANs, by learning univariate activation functions, offer improved accuracy and interpretability over traditional Multi-Layer Perceptrons (MLPs). KANITE uses Integral Probability Metric (IPM) and Entropy Balancing (EB) architectures to align towards ITE estimation and balance covariates, respectively, reducing confounding bias. While demonstrating improved performance on benchmark datasets, its reliance on the unconfoundedness assumption and the need for further validation on complex clinical data are acknowledged limitations. The interpretability of learned KANs in clinical contexts and scalability for large datasets also require further investigation [38]. These efforts complement other work exploring causal inference with continuous treatments and the integration of causal insights into deep learning for better generalizability.

For **dynamic treatment regimes (DTRs)** and survival outcomes with censored data, Paul and Greiner introduce **CA-TRL** (Censoring-Aware Tree-Based Reinforcement Learning) [39]. This method enhances traditional tree-based reinforcement learning with augmented inverse probability weighting (AIPW) and censoring-aware modifications, providing robust and interpretable decision rules for personalized treatment allocation in settings like epilepsy. However, CA-TRL is currently limited to discrete treatment options and may suffer from residual bias due to unmeasured confounders, given its greedy splitting approach [39]. Related work also investigates dynamic representation balancing for causal survival analysis with time-varying treatments [14].

Finally, for predicting outcomes under hypothetical interventions without requiring full causal graph knowledge, Sauter et al. propose **ACTIVA**, a transformer-based conditional variational autoencoder [40]. ACTIVA learns to predict interventional distributions from observational data and uses amortization for zero-shot generalization to new datasets. This capability could significantly optimize clinical trial design by simulating treatment impacts on surrogate endpoints. Its primary limitation lies in its reliance on the representativeness of training data, as performance can degrade in out-of-distribution scenarios, and further theoretical work is needed to fully understand its generalization properties [40].

### Proactive Safety Monitoring and Adverse Event Detection

Beyond efficacy, AI is transforming how clinical trials manage and predict safety concerns, from drug interactions to adverse events.

**Drug-Drug Interaction (DDI) and Adverse Drug Interaction (ADI) Prediction** is crucial for patient safety. Huang et al. introduce **MADRIGAL**, a multimodal AI model that predicts clinical outcomes of drug combinations, including ADIs, by integrating diverse preclinical data (structural, pathway, cell viability, transcriptomic) [41]. It leverages a transformer bottleneck to unify modalities and handle missing data, outperforming single-modality methods. While powerful for virtual screening and personalized trial designs based on genomics, MADRIGAL's indication-agnostic training data and lack of explicit dose consideration limit its precision for definitive, indication-specific safety assessments [41]. Complementing this, Gil-Sorribes and Molina demonstrate that simpler molecular representations, such as Morgan fingerprints, can effectively predict DDIs and drug-drug affinities (DDAs) with performance comparable to more complex deep learning models [42]. This suggests practical utility for proactive identification of potential adverse drug interactions in trial design, though data quality issues like insufficient chemical diversity and inconsistent labeling remain challenges for robust generalization [42].

**Automating Adverse Event Adjudication** is a significant step towards faster signal detection. Sivarajkumar et al. present a novel framework for automating cardiovascular event adjudication using Large Language Models (LLMs) and a Tree of Thoughts approach, guided by clinical endpoint committee (CEC) guidelines [43]. This system standardizes and accelerates a traditionally manual process, reducing variability and costs. The introduction of the CLEART score evaluates the AI's reasoning, enhancing transparency. While promising, the current accuracy is still lower than human experts, suggesting its role as an assistive tool, and further research is needed to address LLM hallucinations and validate the framework on diverse populations [43].

**Semantic Similarity Measures (SSMs) for Adverse Event Clustering** offer a powerful tool for early safety signal detection in pharmacovigilance. Painter et al. show that information content (IC)-based SSMs (e.g., INTRINSIC-LIN, SOKAL) outperform path-based methods in clustering MedDRA Preferred Terms (PTs) around medically meaningful centroids [44]. This could automate the identification of potential safety signals by grouping similar adverse events, leading to more efficient and comprehensive safety monitoring. However, inherent subjectivity in expert reviews and limitations of MedDRA PTs in reflecting nuanced clinical events pose challenges to the accuracy and generalizability of these clustering outcomes [44].

Beyond specific safety events, **predictive modeling for patient health outcomes and risk** is gaining traction. Redekop et al. demonstrate the capability of LLMs (e.g., GPT-2) to forecast medical events from Electronic Health Records (EHR) data in a zero-shot setting, enabling patient identification, stratification, and proactive adverse event prediction for clinical trials [45]. While advantageous for reducing fine-tuning needs, its generalizability is limited by the training data's scope and potential loss of information from data simplification [45]. Similarly, Albada shows that incorporating readily available waveform data, such as Electrocardiogram (ECG) signals, into prediction models significantly enhances mortality prediction accuracy in ICU settings [46]. This can improve patient stratification in critical care trials and automate real-time risk assessment, although generalizability across diverse patient groups and computational costs require further investigation [46]. Further applications include predicting depression treatment outcomes using passively collected smartphone location data, aiding adaptive trial designs [47]. The multi-view deep learning framework by Khakpour et al. for predicting nanoparticle pharmacokinetics also holds promise, optimizing dosage regimens and informing patient selection in nanomedicine trials [48]. These predictive capabilities are supported by broader research into EHR foundation models [28] and the use of LLMs for specific risk predictions like drug overdose [24].

### Conclusion and Future Outlook

The integration of advanced analytics into clinical trials marks a pivotal shift towards more personalized, efficient, and safer drug development. Innovations in causal inference, such as DML for mediation analysis, heterogeneous causal discovery with ensemble methods, and meta-learning for causal effect estimation, are refining our understanding of treatment impacts beyond simple averages. Simultaneously, AI-driven solutions for DDI prediction, automated adverse event adjudication, and semantic clustering of safety signals are bolstering pharmacovigilance and proactive risk management.

Despite these significant strides, challenges remain. The reliance on observational data often necessitates strong, untestable assumptions (e.g., unconfoundedness, causal sufficiency), and model performance can be sensitive to data quality, representativeness, and underlying biases. Computational intensity, scalability for large, high-dimensional datasets, and ensuring the interpretability of complex "black-box" AI models are ongoing concerns. Moreover, the generalizability of models across diverse patient populations, healthcare systems, and novel clinical settings requires rigorous validation. Future work must focus on developing methods that are more robust to violations of assumptions, inherently interpretable, and seamlessly integrable into existing clinical workflows, while also addressing regulatory frameworks for AI in healthcare. By continuously bridging methodological advancements with practical clinical needs, AI promises to accelerate the delivery of safer and more effective therapies.

# The Role of Generative AI and Secure Data Architectures

Advancements in healthcare research and clinical applications are often hampered by stringent privacy regulations and inherent data scarcity, creating significant barriers to data sharing and collaboration [49]. This challenge is particularly acute in clinical trials, where access to diverse and sufficient datasets is crucial for robust study design, patient stratification, and generalizable outcomes. Generative Artificial Intelligence (AI) and secure data architectures, such as Federated Learning (FL), offer transformative solutions to overcome these limitations, enabling the creation of high-fidelity synthetic data and fostering privacy-preserving multi-institutional collaborations.

### Generative AI for Synthetic Data

Synthetic data, which replicates the statistical properties and insights of real-world datasets without containing identifiable information, presents a promising avenue for augmenting clinical trial data, balancing subgroups, and simulating outcomes [49]. Several novel generative AI frameworks have emerged, each addressing specific challenges in different data modalities:

**Masked Clinical Modelling (MCM)** [49] introduces an attention-based framework, inspired by masked language modeling, for generating high-fidelity synthetic data in healthcare, specifically tailored for survival analysis. The core mechanism of MCM involves dynamically masking selected clinical features within a dataset (ranging from 10% to 95% of features) and then reconstructing these missing values by leveraging the contextual relationships among the unmasked features. This process is optimized using mean squared error loss, notably without requiring auxiliary losses or complex curriculum learning schedules, which simplifies its training [49]. MCM's key contribution lies in its ability to preserve critical clinical insights, such as hazard ratios, and significantly enhance the calibration of downstream survival models, particularly across clinically stratified subgroups [49]. This dual capability of standalone dataset synthesis and conditional augmentation offers versatility for clinical trial applications, such as augmenting datasets for rare events or balancing patient populations. However, MCM's validation was primarily on a single de-identified Chronic Kidney Disease (CKD) EHR dataset, which limits its immediate generalizability to other diseases or large-scale, privacy-sensitive clinical trial settings [49]. The authors prioritize utility over immediate privacy considerations, with future work planned to integrate privacy-preserving mechanisms [49].

**Robustness using Imbalance-Resilient Generative Augmentation (RIGA)** [50] offers a four-phase pipeline specifically designed to mitigate class imbalance in tabular healthcare datasets, a common issue in clinical trials that can impact predictions and generalizability. RIGA's novel approach involves: 1) **Data Transformation**: converting tabular data rows into image-like formats using methods like DeepInsight and t-SNE, enabling the application of image-focused generative models; 2) **Augmentation**: employing conditional Generative Adversarial Networks (cGAN), Vector Quantized Variational Autoencoders (VQ-VAE), or VQ-GAN to generate synthetic images for underrepresented classes; 3) **Classification**: allowing for direct image classification using Convolutional Neural Networks (CNNs) or, crucially, performing a lossless inverse transformation to revert synthetic images back to tabular format for analysis with traditional machine learning algorithms like XGBoost; and 4) **Bayesian Network Learning**: to evaluate and enhance the understanding of feature relationships in the augmented datasets [50]. RIGA’s ability to generate data for underrepresented patient populations can enhance external validity and optimize trial design by simulating diverse scenarios. However, the initial tabular-to-image transformation and inverse process may introduce artifacts or distortions [50]. The model's generalizability is dataset-dependent, requiring careful selection of generative models based on dataset size (VQGAN for larger, VQVAE for smaller), and the interpretability of the generated synthetic data and its impact on clinical trial outcomes requires further investigation [50].

**LLM-TabFlow** [51] introduces a novel approach for generating realistic synthetic tabular data with explicit preservation of complex inter-column logical relationships—a critical, yet often overlooked, aspect for real-world utility in domains like healthcare. The methodology leverages Large Language Model (LLM) reasoning to infer and compress these relationships (hierarchical, mathematical, temporal) from column names and descriptions, followed by a score-based diffusion model to generate synthetic data in a latent space. This compressed synthetic data is then decompressed back into its original tabular form using the relationship-guided mappings [51]. This ensures that the generated data maintains not only statistical fidelity but also logical consistency, making it suitable for complex tasks like clinical trial simulation and adverse event prediction. Despite its superior performance in preserving inter-column relationships and balancing data fidelity, utility, and privacy, LLM-TabFlow's reliance on LLM reasoning raises concerns about potential biases and the risk of exposing sensitive information if column names or descriptions contain private data [51]. Furthermore, its evaluation was based on industrial datasets, necessitating further validation in the clinical trial domain with its unique data characteristics and regulatory constraints [51].

**MedLoRD (Medical Low-Resource Diffusion Model)** [52] addresses the challenges of high-dimensional medical imaging data, particularly the computational resource constraints in healthcare environments. MedLoRD is a latent diffusion model designed to generate high-resolution 3D CT images (up to 512x512x256) using readily available GPUs (24GB VRAM) [52]. It employs a VQ-VAE with perceptual and adversarial loss for initial image compression into a latent space, where a 3D U-Net then denoises the representations. For conditional generation (e.g., based on segmentation masks), a reduced-size ControlNet is trained from scratch [52]. MedLoRD's ability to generate conditional synthetic data can create diverse datasets representing various disease states or patient populations, augmenting training data for AI models in clinical image analysis, and reducing data acquisition costs [52]. Radiological validation confirmed the clinical relevance of the generated images. However, the use of L1 loss during training may lead to lower variance in the generated images, potentially limiting diversity, and traditional metrics like Fréchet Inception Distance (FID) were found to be unreliable for assessing clinical meaningfulness, highlighting the need for more robust evaluation methods [52]. Data memorization also remains a factor for future consideration [52].

These generative AI models directly address the 'data sharing paradox,' where synthetic data, created to overcome privacy barriers, remains underutilized due to ambiguous re-identification risks [53]. By improving the realism, utility, and privacy guarantees of synthetic data, they pave the way for wider adoption in clinical trials. However, the overarching goal of maximizing data utility while maintaining stringent privacy standards necessitates further advancements in secure data sharing paradigms like Federated Learning.

# Ensuring Trust and Transparency in Medical AI

As artificial intelligence (AI) models become increasingly integral to clinical trials, particularly in areas like diagnostics, patient stratification, and data analysis, ensuring their trustworthiness and transparency is paramount. This necessitates robust evaluation frameworks, proactive strategies for bias detection, ethical governance, and methods to enhance AI-generated insights' explainability and factuality. These measures are crucial for fostering confidence among clinicians, researchers, and regulatory bodies.

One critical area is the evaluation of AI models, especially when dealing with the complex, often imbalanced datasets inherent in medical research. Traditional metrics frequently fall short in these scenarios, failing to capture nuanced performance variations across diverse patient cohorts. The Cohort-Attention Evaluation Metrics (CAT) framework addresses these limitations by introducing patient-level assessment, entropy-based distribution weighting, and cohort-weighted sensitivity and specificity [54]. This approach, particularly valuable for longitudinal studies and high-risk conditions like cancer screening, offers a more balanced and fair evaluation. However, the practical application of CAT can be challenging due to its complexity and the need for extensive parameter tuning for specific clinical trial settings [54]. Beyond overall performance, AI models may exhibit hidden performance disparities across patient subgroups. Subgroup discovery techniques provide a means to automatically identify such hidden stratifications in medical imaging, revealing unforeseen differences in model performance that traditional metadata-based analyses might miss [55]. By exposing these hidden groups, the method contributes to more robust validation and generalizability of AI systems in clinical settings, potentially optimizing patient stratification in trials. A limitation here is the absence of ground truth stratification labels in real-world data, making evaluation challenging, and the computational cost of subgroup discovery can be high [55]. These efforts align with broader research in evaluating AI trustworthiness across various dimensions, including factuality, robustness, fairness, and safety [56], and the development of comprehensive benchmarks that reflect real-world clinical scenarios [57, 58, 59].

Proactive bias detection in datasets is another cornerstone of trustworthy medical AI. Latent biases in training data can be amplified by AI models, leading to skewed outcomes or unintended shortcut learning. The Generalized Attribute Utility and Detectability-Induced bias Testing (G-AUDIT) framework offers a modality-agnostic approach to identify such biases [60]. G-AUDIT quantifies the extent to which observed data attributes, including protected attributes (e.g., race, age, sex) and environmental characteristics (e.g., clinical site), are spuriously associated with task labels. This allows researchers to audit datasets used for patient selection or outcome prediction, enabling early mitigation of biases and fostering more generalizable AI models for clinical trials [60]. A key challenge for G-AUDIT is its reliance on comprehensive metadata and the need for domain expertise to accurately specify causal relationships, as incorrect specifications can lead to inaccurate bias detection [60]. Research also highlights the need for diverse linguistic benchmarks to ensure fair deployment across different populations [61].

Enhancing the explainability and factuality of AI-generated medical insights is particularly vital given the increasing role of Large Language Models (LLMs) in healthcare. LLMs, despite their potential, can suffer from factual inaccuracies or 'hallucinations', which are unacceptable in clinical contexts. To address this, the Med-SoCoT approach leverages structured medical reasoning to improve the factuality and comprehensiveness of LLM responses without extensive fine-tuning [62]. This method guides LLMs through a cognitive process inspired by clinical diagnosis, making it suitable for tasks like automated literature review, protocol generation, or adverse event analysis in clinical trials. Similarly, MedReason enhances LLM medical reasoning by grounding it in established knowledge graphs, converting clinical question-answer pairs into verifiable, step-by-step logical chains of reasoning [63]. This reduces errors and improves trustworthiness, paving the way for more accurate patient screening and outcome prediction in trials. For factual evaluation of plain language summaries (PLS) of clinical trial results, the PLAINQAFACT framework provides an automated metric [64]. It is specifically designed to handle 'elaborative explanations'—external content added to PLS for better comprehension—which traditional metrics often miss. This is crucial for ensuring that information disseminated to patients and the public is accurate and consistent [64]. While effective, PLAINQAFACT's reliance on expert-annotated data for training and its primary focus on general biomedical text rather than specific clinical trial documents present limitations [64]. Beyond factuality, integrating uncertainty awareness into LLMs can bolster diagnostic systems [65], and frameworks like ReasoningShield [66] and Med-CoDE [67] are being developed to detect unsafe content in reasoning traces and evaluate medical LLMs through critique-based approaches, respectively. Progress is also being made in multi-modal explainability to support transparent decision-making [68, 69] and in developing smaller, more efficient LLMs with enhanced reasoning skills tailored for medical applications [70, 71].

The discussion of AI autonomy and ethical considerations is fundamental to trusted deployment. While AI tools often serve a supportive role in healthcare, enabling greater AI autonomy under defined delegation criteria can potentially enhance efficiency, particularly for low-risk or standard cases [72]. This approach, outlined with criteria like task type, clinical context, decision criticality, AI confidence, and failure modes, could be adapted for automating aspects of clinical trial management, such as patient screening or safety monitoring within predefined ranges [72]. However, a comprehensive exploration of ethical and regulatory implications, especially concerning patient safety and data privacy, is needed [72]. To streamline the rigorous evaluation required for AI-driven health applications, the Adaptive Precise Boolean rubrics framework offers a scalable method for assessing LLM response quality [73]. By enabling more granular and objective evaluations, it can improve the efficiency of data quality checks and outcome assessments in trials, ultimately accelerating the validation process for AI tools [73]. Despite its promise, the framework's validation is currently based on a relatively small sample and a synthetic user persona, highlighting the need for broader testing [73]. Furthermore, developing benchmarks to assess LLMs' ability to adhere to clinical guidelines [74] and evaluating the ethical reasoning capabilities of LLMs in medical contexts, such as with the MedEthicEval framework [75], are crucial steps towards ensuring ethically responsible AI systems for clinical trials, even with limitations regarding cultural variations and emerging ethical challenges [75].

In conclusion, ensuring trust and transparency in medical AI, particularly within clinical trials, requires a multi-faceted approach. Advancements in robust evaluation metrics like CAT, proactive bias detection frameworks such as G-AUDIT, and sophisticated methods for enhancing LLM factuality and explainability like Med-SoCoT and MedReason are critical. Simultaneously, a careful consideration of AI autonomy, guided by clear delegation criteria and supported by adaptive evaluation frameworks, is necessary. The continuous development of comprehensive benchmarks and an emphasis on ethical reasoning in AI design will be instrumental in fostering confidence, accelerating innovation, and ultimately enabling the safe and effective integration of AI into evidence-based medicine.

# Advancements in Processing Complex Clinical Information

The escalating volume and inherent complexity of clinical data, spanning unstructured notes, multimodal imaging, and temporal patient histories, pose significant challenges for clinical research and decision-making. Innovative artificial intelligence (AI) techniques are emerging to address these issues by enabling efficient extraction, organization, and reasoning over diverse clinical information, ultimately enhancing data quality and accelerating insights for clinical trial design and analysis.

### Efficient Information Extraction and Summarization

A key challenge in leveraging clinical text is the sheer length and detail of documents, which necessitates efficient summarization to quickly distill critical information. To this end, a LongFormer-based model has been proposed for accurate and efficient medical text summarization [76]. This framework specifically addresses the limitations of traditional methods by employing long-range self-attention, thereby better capturing dependencies in extensive medical texts for improved information retention and grammatical accuracy, as evidenced by ROUGE metrics and expert evaluations. However, the model still presents challenges in conciseness, readability, and computational efficiency due to its large parameter size, which could limit its utility in real-time, resource-constrained environments [76]. Extending this, the ConTextual framework demonstrates improved clinical text summarization by integrating a context-preserving token filtering method with a domain-specific knowledge graph, enhancing both linguistic coherence and clinical fidelity [77]. Similarly, methods leveraging Large Language Models (LLMs) for high-fidelity pseudo-label generation can facilitate training robust radiology report classifiers, effectively overcoming annotation bottlenecks [78].

Beyond text, clinical data often includes multimodal information, such as video and audio. The Cross-Modal State-Space Graph Reasoning (CSS-GR) framework offers a novel approach for structured summarization from large-scale, multimodal data by integrating a state-space model with graph-based message passing [79]. This design captures inter- and intra-modal relationships, allowing holistic reasoning over textual and visual streams, which could be critical for analyzing patient interviews or therapy sessions. While promising for improving computational efficiency and interpretability, the framework’s effectiveness needs validation on a broader range of clinical data, such as medical images or sensor data, as its current evaluation is primarily on video summarization datasets [79].

### Structured Data Extraction and Knowledge Graph Construction

Extracting structured information from unstructured clinical narratives is fundamental for downstream tasks like patient recruitment, adverse event detection, and clinical coding. A hierarchically-informed data generation approach, HILGEN, combines domain knowledge from the Unified Medical Language System (UMLS) with synthetic data generated by LLMs to improve biomedical Named Entity Recognition (NER) in few-shot settings [80]. This method is particularly valuable where annotated data is scarce, by using UMLS’s hierarchical structure and LLMs for targeted synthetic example generation. The ensemble approach, combining UMLS and GPT-3.5, showed notable F1 score improvements across various biomedical NER datasets [80]. Further improving NER, an LLM-based prompt ensemble approach can enhance reliability and classification performance for medical entity recognition from Electronic Health Records (EHRs) [81].

For standardized coding, a significant advancement frames ICD coding as an entity linking problem, leveraging LLMs for automated, explainable coding of clinical data [82]. This approach improves data quality by providing explicit textual evidence for each code assignment, enhancing transparency and reproducibility. However, its reliance on pre-detected mentions and limited dataset validation highlights areas for future, end-to-end solutions and real-world clinical trial data validation [82]. Similarly, CDE-Mapper utilizes Retrieval-Augmented Generation (RAG) with LLMs to automate the linking of clinical data elements to controlled vocabularies, addressing data harmonization and interoperability challenges [83].

The ability to achieve high performance with limited, sensitive medical data is also being explored by fine-tuning smaller, locally hosted LLMs on specific medical datasets for tasks like text classification and NER [84]. This approach automates information extraction from clinical notes, improves data quality, and addresses data security concerns by keeping sensitive data local. This aligns with a broader trend towards Small Language Models (SLMs) in healthcare, which offer scalable and resource-efficient solutions for tasks where large models are computationally prohibitive or raise privacy concerns [26, 85, 86].

A holistic understanding of patient information is increasingly facilitated by Patient Journey Knowledge Graphs (PJKGs). A methodology for constructing PJKGs using LLMs has been developed to process both formal clinical documentation and unstructured patient-provider conversations, capturing temporal and causal relationships among clinical encounters, diagnoses, treatments, and outcomes [6]. These PJKGs offer a unified representation of patient trajectories, streamlining patient recruitment and enabling personalized treatment strategies in clinical trials. However, the current evaluation on relatively small datasets and the focus on specific therapeutic areas limit immediate generalizability, and the observed variability in semantic accuracy across different LLMs underscores the need for more robust extraction methods [6]. LLMs are also being applied to automate and enhance medical ontology mapping for RDF knowledge graph construction, promising more accurate and interoperable medical knowledge representations [87].

### Complex Reasoning and Temporal Understanding

Clinical trial processes often require information retrieval systems to follow complex, nuanced instructions. The IFIR benchmark was introduced as the first comprehensive benchmark to evaluate instruction-following information retrieval (IR) in expert domains like healthcare [88]. This benchmark, with its diverse, high-quality examples and LLM-based evaluation, aims to improve the precision of patient matching, literature review, and regulatory compliance by assessing how effectively retrieval systems can interpret and act upon complex instructions [88]. Despite its utility, the current healthcare subset of IFIR may not cover the full spectrum of clinical trial data types, necessitating further validation with real-world datasets [88]. The BRIDGE benchmark further evaluates LLM performance across real-world clinical data sources and multiple languages, revealing significant performance variations and highlighting the potential for open-source models to rival proprietary ones [59].

The longitudinal nature of Electronic Health Records (EHRs) presents a unique challenge for AI models, requiring robust temporal reasoning. The TIMER framework introduces TIMER-Bench, a time-aware benchmark, and TIMER-Instruct, an instruction-tuning methodology, to improve LLMs' ability to reason over temporal dependencies in longitudinal clinical records [89]. This framework is critical for tasks such as patient enrollment, outcome prediction, and adherence analysis in clinical trials by enabling LLMs to understand and synthesize information across different time points. While demonstrating improved performance, the reliance on synthetically generated instruction-response pairs and data from a single academic center may limit generalizability to diverse real-world settings [89]. Research on forecasting from clinical textual time series further emphasizes the importance of time-ordered corpora for temporal tasks, showing that encoder-based models excel in event forecasting while instruction-tuned decoder models show promise in survival analysis [90]. Building on this, DynaGraph offers an end-to-end interpretable contrastive graph model that learns the dynamics of multivariate time-series EHRs, providing automated feature importance analysis and aiding in patient stratification and multi-outcome prediction [91]. Its generalizability, however, might be influenced by dataset specificity and the interpretability of its pseudo-attention mechanism warrants further clinical validation [91].

### Multimodal Clinical Data Analysis

The integration of diverse data modalities, such as images, text, and physiological signals, is crucial for a comprehensive understanding of patient conditions. Open-PMC, a high-quality medical dataset comprising 2.2 million image-text pairs with enriched captions and in-text references, underscores the importance of data quality over sheer volume in advancing medical Vision-Language (VL) AI [92]. This dataset can improve AI models for tasks like identifying patient cohorts based on image characteristics and textual descriptions, though its optimization for radiology images limits immediate applicability to other modalities [92].

In the realm of medical imaging analysis, INVERSEBENCH provides a framework for evaluating diffusion models in scientific inverse problems, including medical imaging [93]. These models can be adapted to impute missing data or enhance image resolution in clinical trial datasets, contributing to more efficient and reliable trial results. However, its current focus on physical sciences inverse problems requires further adaptation for the complexities of clinical trial data [93]. Developments in Multimodal Large Language Models (MLLMs) are particularly significant, with frameworks like Infi-Med introducing resource-efficient approaches and enhanced multimodal reasoning capabilities for complex medical tasks [94]. Surveys on MLLMs in medicine highlight their potential for medical reporting, diagnosis, and treatment by integrating text with imaging or genomic data, yet acknowledge challenges related to computational intensity, data biases, and ethical concerns [95]. Specific applications include speech-driven visual language models for explainable abnormality detection in medical imaging [96], audio-language models for cardiac and respiratory diagnostic reasoning [97], and knowledge-informed multimodal LLMs for ECG question answering [98]. Progress in histopathology also includes expert-level MLLMs using whole slide images for cancer diagnosis by leveraging retrieval-based data generation [99]. Automated video-Electroencephalography (EEG) analysis for epilepsy demonstrates promise for real-time seizure detection and treatment effect estimation using concept-based learning, though challenges remain in dataset diversity and the subjective nature of EEG markup [100]. Improvements in Medical Visual Question Answering (MVQA) consistency through LLM-augmented question sets also contribute to more robust and reliable medical image interpretation [101]. Furthermore, multi-agent frameworks are emerging for improved medical report generation, addressing biases and enhancing comprehensive descriptions of clinically relevant regions [102].

### Human-AI Collaboration and Workflow Automation

The integration of AI into clinical workflows often benefits from human-AI collaboration to leverage both automated capabilities and expert oversight. TAMA, a human-AI collaborative thematic analysis framework, uses multi-agent LLMs for clinical interviews to accelerate qualitative data analysis [103]. By automating thematic analysis, TAMA can reduce the time and resources for identifying key themes from patient feedback, allowing faster decision-making in clinical trials. However, its reliance on specific datasets and expert availability necessitates broader validation [103].

For automating complex data analysis tasks, iStrucInd proposes an interactive structured induction approach, enabling software engineers and LLMs to collaboratively construct scientific assistants [104]. This framework can rapidly develop customized software for clinical trial data cleaning, statistical analysis, and report generation, potentially reducing development time and improving data analysis quality. Practical implementation, however, requires software engineering expertise and careful consideration of formal verification to meet regulatory requirements for clinical trial software [104]. LLMs are also showing potential for automating patient record linkage, enhancing data integration and reducing manual effort [105].

Finally, the TxAgent exemplifies an AI agent designed for therapeutic reasoning by leveraging a "ToolUniverse" of 211 trusted biomedical tools for real-time knowledge retrieval and multi-step reasoning [106]. This agent evaluates drug interactions, contraindications, and tailors treatment strategies, supporting personalized medicine and real-time monitoring in adaptive clinical trials. Its reliance on the ToolUniverse for data completeness and its current lack of multi-modal data support are notable limitations [106]. The application of LLMs for biomedical text classification tasks, such as identifying adverse events from social media or classifying clinical notes, further streamlines patient recruitment and pharmacovigilance, though zero-shot performance variability highlights the need for task-specific optimization and careful model selection [107].

### Conclusion and Future Outlook

The advancements in AI for processing complex clinical information mark a significant step towards more efficient, accurate, and interpretable healthcare. Techniques for efficient text and multimodal summarization, structured data extraction through NER and knowledge graphs, sophisticated instruction-following, and temporal reasoning capabilities are transforming how clinical data is managed and leveraged. Furthermore, the increasing integration of multimodal data and the development of human-AI collaborative tools are poised to streamline clinical research and decision-making.

Despite these promising developments, significant challenges remain. The generalizability of models across diverse patient populations, healthcare systems, and data collection practices requires robust validation beyond academic datasets. Interpretability of complex AI models, particularly in critical clinical contexts, needs further enhancement to foster trust among clinicians. Computational costs and ethical considerations, including data privacy and bias, must be continuously addressed to ensure equitable and safe deployment. Future research will likely focus on developing lightweight, adaptable, and explainable AI systems that seamlessly integrate into existing clinical workflows, ultimately accelerating the discovery of new therapies and improving patient outcomes in a scalable and trustworthy manner.

# Spotlight: Multimodal LLMs for Accelerated Patient Matching

Patient recruitment is a pervasive bottleneck in clinical trial operations, often exacerbated by increasingly complex eligibility criteria and the labor-intensive nature of manual chart reviews [1]. Addressing this challenge, a novel pipeline leverages multimodal Large Language Models (LLMs) to automate and enhance patient matching for clinical trials, demonstrating an 80% improvement in pre-screening time compared to traditional methods [1].

### Advancing Patient Matching with Multimodal LLMs

The pipeline introduced by Callies et al. directly tackles several limitations of prior text-only models, notably their constrained reasoning capabilities, information loss during image-to-text conversion, and the absence of a generic Electronic Health Record (EHR) integration [1]. The core of their methodology involves a three-pronged innovation:

1.  **Vision-Language Models (VLMs):** Unlike methods relying on Optical Character Recognition (OCR), this pipeline directly ingests images of medical records. This `fully visual pipeline` leverages advanced VLMs to interpret medical records without lossy image-to-text conversions, thereby retaining more information, particularly from handwritten notes, tables, charts, and graphs commonly found in EHRs [1]. Related work further underscores the utility of VLMs for clinical data extraction from scanned documents, such as transfusion reaction reports, demonstrating their efficacy in real-world heterogeneous healthcare data environments [108]. The development of large-scale medical multimodal datasets further supports the training of such robust VLMs [109].
2.  **Visual Retrieval and Multimodal Embeddings:** To efficiently navigate extensive patient records, the system employs multimodal embeddings (e.g., VoyageAI 2024's model) to facilitate semantic search. This allows for the retrieval of the most relevant pages or sections from a patient’s medical record based on eligibility criteria or generated retrieval guidelines, a process that is significantly faster than traditional OCR-based methods [1]. This approach aligns with multimodal contrastive learning frameworks that integrate structured EHR data with unstructured clinical notes to enhance contextual understanding for clinical tasks [110].
3.  **Reasoning LLM Paradigm:** The pipeline utilizes advanced reasoning models (e.g., OpenAI's o1) capable of assessing complex eligibility criteria, including logical expressions and arithmetic tasks that simpler chat models might fail at [1]. This emphasis on robust clinical reasoning is a critical area of research, with ongoing efforts to build human-verified clinical reasoning datasets to improve LLM trustworthiness and interpretability [111, 112].

The pipeline operates in two main phases: trial preprocessing and patient-trial matching. During trial preprocessing, an LLM parses eligibility criteria into individual, assessable units, generates a high-level `relevance criterion` for initial filtering, and creates `retrieval guidelines` to direct subsequent information extraction from patient records. Patient preprocessing involves de-identifying (using tools like Google Cloud Data Loss Prevention, a crucial step for privacy, as highlighted by de-identification frameworks like RedactOR [113]) and embedding medical record images into a vector database. For patient-trial matching, a `relevance check` quickly filters irrelevant patients, followed by a detailed `assessment` against each specific eligibility criterion, drawing upon semantically retrieved portions of the patient's record [1].

### Performance and Broader Implications

Validated on the n2c2 2018 dataset, the method achieved a 93% criterion-level accuracy, even when processing text converted to low-resolution images to simulate real-world visual data challenges. In real-world trials involving 485 patients across 30 sites and 36 diverse trials, the pipeline maintained an 87% accuracy. Crucially, it reduced the average patient pre-screening time to under 9 minutes per patient, an 80% improvement over manual chart reviews [1]. This efficiency gain is corroborated by other LLM-powered systems like TrialMatchAI [5] and the Tempus AI TIME Program, which also demonstrate significant acceleration in patient screening and trial enrollment through LLM and Retrieval-Augmented Generation (RAG) integration [114]. The integration of oncology-specific knowledge graphs and multi-agent AI further enhances the accuracy and efficiency of such systems in specialized domains [115]. Furthermore, the ability to map unstructured EHR data to standardized frameworks like mCODE 3.0, as demonstrated by another AI platform, can streamline data abstraction and enhance interoperability for trial eligibility [116].

### Challenges and Future Directions

Despite its robust performance, the pipeline faces inherent challenges. Real-world data variability and incompleteness can undermine accuracy, and the system struggles to replicate the nuanced human decision-making processes, particularly in differentiating between firm and uncertain assessments [1]. Clinical research coordinators often hesitate to definitively exclude patients without further manual verification, highlighting a gap in automated `patient-level recommendations` from aggregated criterion decisions [1]. These limitations resonate with broader challenges in evaluating LLMs for clinical reasoning, as highlighted by benchmarks like LLMEval-Med [57] and ER-REASON [117], which show a significant gap between LLM-generated and clinician-authored reasoning. The need for generalizability across diverse clinical tasks and languages is also emphasized by benchmarks like BRIDGE [59] and MedHELM [58].

Practical deployment also presents considerations, including the computational cost associated with LLM inference, although methods like lightweight models and prompt engineering are being explored to offer more resource-efficient solutions [118, 119]. Continued refinement will need to focus on improving the calibration of assessment certainty, developing more sophisticated methods for patient-level aggregation, and ensuring seamless integration into existing clinical workflows with adequate human oversight to foster trust and address ethical considerations related to patient privacy and data biases [120].

# Conclusion

The collective advancements demonstrate a pivotal shift towards more data-driven, precise, and efficient approaches in clinical trials. Significant progress has been made in automating complex tasks, such as patient eligibility assessments through multimodal LLMs, refining treatment effect estimation via sophisticated causal inference techniques, and bolstering proactive safety surveillance through advanced analytics. Furthermore, the development of robust generative AI models promises to alleviate data scarcity while secure architectures enable privacy-preserving collaborations. However, the effective translation of these innovations into widespread clinical practice remains contingent on addressing shared challenges. Recurring limitations across different methodologies include ensuring generalizability across diverse populations, mitigating inherent biases, managing computational intensity, and enhancing the interpretability of complex models. The ethical deployment of AI, particularly concerning patient data privacy and the integration of human oversight, also remains a critical consideration. Continued research efforts must focus on developing robust, reliable, and inherently transparent AI systems that seamlessly integrate into existing clinical workflows, accelerating the discovery of safer and more personalized therapies while fostering trust.

# References

1. Anatole Callies, Quentin Bodinier, Philippe Ravaud, Kourosh Davarpanah (2025). *Real-world validation of a multimodal LLM-powered pipeline for High-Accuracy Clinical Trial Patient Matching leveraging EHR data*. ArXiv:2503.15374v1. [https://arxiv.org/pdf/2503.15374v1](https://arxiv.org/pdf/2503.15374v1)
2. Muhammad Talha Sharif, Abdul Rehman (2025). *Systematic Literature Review on Clinical Trial Eligibility Matching*. ArXiv:2503.00863v1. [https://arxiv.org/pdf/2503.00863v1](https://arxiv.org/pdf/2503.00863v1)
3. Jie Pan, Seungwon Lee, Cheligeer Cheligeer, Elliot A. Martin, Kiarash Riazi, Hude Quan, Na Li (2025). *Integrating Large Language Models with Human Expertise for Disease Detection in Electronic Health Records*. ArXiv:2504.00053v1. [https://arxiv.org/pdf/2504.00053v1](https://arxiv.org/pdf/2504.00053v1)
4. Zifeng Wang, Hanyin Wang, Benjamin Danek, Ying Li, Christina Mack, Hoifung Poon, Yajuan Wang, Pranav Rajpurkar, Jimeng Sun (2024). *A Perspective for Adapting Generalist AI to Specialized Medical AI Applications and Their Challenges*. ArXiv:2411.00024v3. [https://arxiv.org/pdf/2411.00024v3](https://arxiv.org/pdf/2411.00024v3)
5. Majd Abdallah, S. Nakken, M. Bierkens, Johanna Galvis, Alexis Groppi, S. Karkar, L. Meiqari, Maria A Rujano, Steve Canham, Rodrigo Dienstmann, R. Fijneman, E. Hovig, G. Meijer, Macha Nikolski (2025). *TrialMatchAI: An End-to-End AI-powered Clinical Trial Recommendation System to Streamline Patient-to-Trial Matching*. ArXiv:2505.08508. [https://www.semanticscholar.org/paper/4494f140797ded006edcb40443ad146f22574070](https://www.semanticscholar.org/paper/4494f140797ded006edcb40443ad146f22574070)
6. Hassan S. Al Khatib, Sudip Mittal, Shahram Rahimi, Nina Marhamati, Sean Bozorgzad (2025). *From Patient Consultations to Graphs: Leveraging LLMs for Patient Journey Knowledge Graph Construction*. ArXiv:2503.16533v1. [https://arxiv.org/pdf/2503.16533v1](https://arxiv.org/pdf/2503.16533v1)
7. Joseph Gatto, Parker Seegmiller, Timothy Burdick, Inas S. Khayal, Sarah DeLozier, Sarah M. Preum (2025). *Follow-up Question Generation For Enhanced Patient-Provider Conversations*. ArXiv:2503.17509v1. [https://arxiv.org/pdf/2503.17509v1](https://arxiv.org/pdf/2503.17509v1)
8. Zifeng Wang, Junyi Gao, Benjamin Danek, Brandon Theodorou, Ruba Shaik, Shivashankar Thati, Seunghyun Won, Jimeng Sun (2025). *InformGen: An AI Copilot for Accurate and Compliant Clinical Research Consent Document Generation*. ArXiv:2504.00934v1. [https://arxiv.org/pdf/2504.00934v1](https://arxiv.org/pdf/2504.00934v1)
9. Mathilde Aguiar, Pierre Zweigenbaum, Nona Naderi (2025). *Am I eligible? Natural Language Inference for Clinical Trial Patient Recruitment: the Patient's Point of View*. ArXiv:2503.15718v1. [https://arxiv.org/pdf/2503.15718v1](https://arxiv.org/pdf/2503.15718v1)
10. Xiaoxiao Liu, Qingying Xiao, Junying Chen, Xiangyi Feng, Xiangbo Wu, Bairui Zhang, Xiang Wan, Jian Chang, Guangjun Yu, Yan Hu, Benyou Wang (2025). *Large Language Models for Outpatient Referral: Problem Definition, Benchmarking and Challenges*. ArXiv:2503.08292v1. [https://arxiv.org/pdf/2503.08292v1](https://arxiv.org/pdf/2503.08292v1)
11. Kevin Li, Eric Laber (2025). *Exploiting Concavity Information in Gaussian Process Contextual Bandit Optimization*. ArXiv:2503.10836v1. [https://arxiv.org/pdf/2503.10836v1](https://arxiv.org/pdf/2503.10836v1)
12. Omer Noy Klein, Alihan Hüyük, Ron Shamir, Uri Shalit, Mihaela van der Schaar (2025). *Towards Regulatory-Confirmed Adaptive Clinical Trials: Machine Learning Opportunities and Solutions*. ArXiv:2503.09226v1. [https://arxiv.org/pdf/2503.09226v1](https://arxiv.org/pdf/2503.09226v1)
13. Yoav Wald, Mark Goldstein, Yonathan Efroni, Wouter A. C. van Amsterdam, Rajesh Ranganath (2025). *Time After Time: Deep-Q Effect Estimation for Interventions on When and What to do*. ArXiv:2503.15890v1. [https://arxiv.org/pdf/2503.15890v1](https://arxiv.org/pdf/2503.15890v1)
14. Ayoub Abraich (2025). *TV-SurvCaus: Dynamic Representation Balancing for Causal Survival Analysis*. ArXiv:2505.01785. [https://www.semanticscholar.org/paper/5960c9a92bd364c5ee5c3115766b8a766a4b8605](https://www.semanticscholar.org/paper/5960c9a92bd364c5ee5c3115766b8a766a4b8605)
15. Prateek Jaiswal, Esmaeil Keyvanshokooh, Junyu Cao (2025). *Deconfounded Warm-Start Thompson Sampling with Applications to Precision Medicine*. ArXiv:2505.17283. [https://www.semanticscholar.org/paper/ff505d99d2fb1673f1a41dfe26deeb573ef1a600](https://www.semanticscholar.org/paper/ff505d99d2fb1673f1a41dfe26deeb573ef1a600)
16. Johannes Hruza, Arvid Sjolander, Erin E Gabriel, Samir Bhatt, Michael Sachs (2025). *Evaluation of clinical utility in emulated clinical trials*. ArXiv:2506.03991. [https://www.semanticscholar.org/paper/e51f0d0f6a93bc6f7ac61db163d1ae25b6fc0c92](https://www.semanticscholar.org/paper/e51f0d0f6a93bc6f7ac61db163d1ae25b6fc0c92)
17. Qianyi Xu, Gousia Habib, Dilruk Perera, Mengling Feng (2025). *MedDreamer: Model-Based Reinforcement Learning with Latent Imagination on Complex EHRs for Clinical Decision Support*. ArXiv:2505.19785. [https://www.semanticscholar.org/paper/ab5acad2b6ff5ab93c0fc35b95a7a203ad28caad](https://www.semanticscholar.org/paper/ab5acad2b6ff5ab93c0fc35b95a7a203ad28caad)
18. Jonas Knecht, Anna Zink, Jonathan Kolstad, Maya Petersen (2025). *Deep Causal Behavioral Policy Learning: Applications to Healthcare*. ArXiv:2503.03724v1. [https://arxiv.org/pdf/2503.03724v1](https://arxiv.org/pdf/2503.03724v1)
19. Martin Kuhn, Joscha Grüger, Tobias Geyer, Ralph Bergmann (2025). *Leveraging Taxonomy Similarity for Next Activity Prediction in Patient Treatment*. ArXiv:2503.07638v2. [https://arxiv.org/pdf/2503.07638v2](https://arxiv.org/pdf/2503.07638v2)
20. Rafael R. Oexner, Robin Schmitt, Hyunchan Ahn, Ravi A. Shah, Anna Zoccarato, Konstantinos Theofilatos, Ajay M. Shah (2025). *Comprehensive Benchmarking of Machine Learning Methods for Risk Prediction Modelling from Large-Scale Survival Data: A UK Biobank Study*. ArXiv:2503.08870v1. [https://arxiv.org/pdf/2503.08870v1](https://arxiv.org/pdf/2503.08870v1)
21. Farhana Yeasmin, Shamsul Arefeen, Rafi Muhammad Zakaria, Abid Hasan (2025). *Predictive Modeling of Patient Health Outcomes Using Electronic Health Records and Advanced Machine Learning Algorithms*. ArXiv:10.32996/jcsts.2025.7.2.68. [https://www.semanticscholar.org/paper/52398c6bae5d05ce7ea61d7317617252d44eac16](https://www.semanticscholar.org/paper/52398c6bae5d05ce7ea61d7317617252d44eac16)
22. Yuchen Ma, Jonas Schweisthal, Hengrui Zhang, Stefan Feuerriegel (2025). *A Diffusion-Based Method for Learning the Multi-Outcome Distribution of Medical Treatments*. ArXiv:2506.01533. [https://www.semanticscholar.org/paper/7e821ab0513faf7425663e5d769d5a2cf2130367](https://www.semanticscholar.org/paper/7e821ab0513faf7425663e5d769d5a2cf2130367)
23. Bowen Deng, Chang Xu, Hao Li, Yuhao Huang, Min Hou, Jiang Bian (2025). *TarDiff: Target-Oriented Diffusion Guidance for Synthetic Electronic Health Record Time Series Generation*. ArXiv:10.48550/arXiv.2504.17613. [https://www.semanticscholar.org/paper/63ca8f86de6b2c3299e4fd6fd28e1c24cf040341](https://www.semanticscholar.org/paper/63ca8f86de6b2c3299e4fd6fd28e1c24cf040341)
24. Md Sultan Al Nahian, Chris Delcher, Daniel Harris, Peter Akpunonu, R. Kavuluru (2025). *Large Language Models for Drug Overdose Prediction from Longitudinal Medical Records*. ArXiv:10.48550/arXiv.2504.11792. [https://www.semanticscholar.org/paper/a475b202ecc3b5ec532dcfbad7092fbe3846abf7](https://www.semanticscholar.org/paper/a475b202ecc3b5ec532dcfbad7092fbe3846abf7)
25. Fengze Liu, Haoyu Wang, Joonhyuk Cho, Dan Roth, Andrew W. Lo (2025). *AUTOCT: Automating Interpretable Clinical Trial Prediction with LLM Agents*. ArXiv:2506.04293. [https://www.semanticscholar.org/paper/66f9a84c44e147fdad9d983a0ca52d9284ee17f2](https://www.semanticscholar.org/paper/66f9a84c44e147fdad9d983a0ca52d9284ee17f2)
26. Muskan Garg, Shaina Raza, Shebuti Rayana, Xingyi Liu, Sunghwan Sohn (2025). *The Rise of Small Language Models in Healthcare: A Comprehensive Survey*. ArXiv:10.48550/arXiv.2504.17119. [https://www.semanticscholar.org/paper/d0e6b0a43edec2424005ee900c6d657597bd7d16](https://www.semanticscholar.org/paper/d0e6b0a43edec2424005ee900c6d657597bd7d16)
27. Yihan Lin, Zhirong Bella Yu, Simon Lee (2025). *A Case Study Exploring the Current Landscape of Synthetic Medical Record Generation with Commercial LLMs*. ArXiv:10.48550/arXiv.2504.14657. [https://www.semanticscholar.org/paper/780e184d0e0cec844353f9fd94af58100bd2bc26](https://www.semanticscholar.org/paper/780e184d0e0cec844353f9fd94af58100bd2bc26)
28. Chao Pang, Vincent Jeanselme, Young Sang Choi, Xinzhuo Jiang, Zilin Jing, Aparajita Kashyap, Yuta Kobayashi, Yanwei Li, Florent Pollet, Karthik Natarajan, Shalmali Joshi (2025). *FoMoH: A clinically meaningful foundation model evaluation for structured electronic health records*. ArXiv:2505.16941. [https://www.semanticscholar.org/paper/ae943be2991f4e8d4ca5dc0185747fa1d5915dba](https://www.semanticscholar.org/paper/ae943be2991f4e8d4ca5dc0185747fa1d5915dba)
29. Wan Nor Arifin, Najib Majdi Yaacob (2025). *Sample size determination for machine learning in medical research*. ArXiv:2503.05809v1. [https://arxiv.org/pdf/2503.05809v1](https://arxiv.org/pdf/2503.05809v1)
30. Thomas Monks, Alison Harper, Amy Heather (2025). *Unlocking the Potential of Past Research: Using Generative AI to Reconstruct Healthcare Simulation Models*. ArXiv:2503.21646v1. [https://arxiv.org/pdf/2503.21646v1](https://arxiv.org/pdf/2503.21646v1)
31. L. J. L. L'opez, Shaza Elsharief, Dhiyaa Al Jorf, Firas Darwish, Congbo Ma, Farah E. Shamout (2025). *Uncertainty Quantification for Machine Learning in Healthcare: A Survey*. ArXiv:2505.02874. [https://www.semanticscholar.org/paper/eedb94105a930996f7e49b4c1592d642f901271b](https://www.semanticscholar.org/paper/eedb94105a930996f7e49b4c1592d642f901271b)
32. Wenbin Zhou, Agni Orfanoudaki, Shixiang Zhu (2025). *Conformalized Decision Risk Assessment*. ArXiv:2505.13243. [https://www.semanticscholar.org/paper/870fe61308b81e7c7963940769db44e89d1bb43e](https://www.semanticscholar.org/paper/870fe61308b81e7c7963940769db44e89d1bb43e)
33. Houssam Zenati, Judith Abécassis, Julie Josse, Bertrand Thirion (2025). *Double Debiased Machine Learning for Mediation Analysis with Continuous Treatments*. ArXiv:2503.06156v1. [https://arxiv.org/pdf/2503.06156v1](https://arxiv.org/pdf/2503.06156v1)
34. Shishir Adhikari, Guido Muscioni, Mark Shapiro, Plamen Petrov, Elena Zheleva (2025). *Heterogeneous Causal Discovery of Repeated Undesirable Health Outcomes*. ArXiv:2503.11477v1. [https://arxiv.org/pdf/2503.11477v1](https://arxiv.org/pdf/2503.11477v1)
35. Lucius E. J. Bynum, Aahlad Manas Puli, Diego Herrero-Quevedo, Nhi Nguyen, Carlos Fernandez-Granda, Kyunghyun Cho, Rajesh Ranganath (2025). *Black Box Causal Inference: Effect Estimation via Meta Prediction*. ArXiv:2503.05985v1. [https://arxiv.org/pdf/2503.05985v1](https://arxiv.org/pdf/2503.05985v1)
36. Piersilvio De Bartolomeis, Julia Kostin, Javier Abad, Yixin Wang, Fanny Yang (2025). *Doubly robust identification of treatment effects from multiple environments*. ArXiv:2503.14459v1. [https://arxiv.org/pdf/2503.14459v1](https://arxiv.org/pdf/2503.14459v1)
37. Changchang Yin, Hong-You Chen, Wei-Lun Chao, Ping Zhang (2025). *Federated Inverse Probability Treatment Weighting for Individual Treatment Effect Estimation*. ArXiv:2503.04946v1. [https://arxiv.org/pdf/2503.04946v1](https://arxiv.org/pdf/2503.04946v1)
38. Eshan Mehendale, Abhinav Thorat, Ravi Kolla, Niranjan Pedanekar (2025). *KANITE: Kolmogorov-Arnold Networks for ITE estimation*. ArXiv:2503.13912v1. [https://arxiv.org/pdf/2503.13912v1](https://arxiv.org/pdf/2503.13912v1)
39. Animesh Kumar Paul, Russell Greiner (2025). *Censoring-Aware Tree-Based Reinforcement Learning for Estimating Dynamic Treatment Regimes with Censored Outcomes*. ArXiv:2503.06690v1. [https://arxiv.org/pdf/2503.06690v1](https://arxiv.org/pdf/2503.06690v1)
40. Andreas Sauter, Saber Salehkaleybar, Aske Plaat, Erman Acar (2025). *ACTIVA: Amortized Causal Effect Estimation without Graphs via Transformer-based Variational Autoencoder*. ArXiv:2503.01290v1. [https://arxiv.org/pdf/2503.01290v1](https://arxiv.org/pdf/2503.01290v1)
41. Yepeng Huang, Xiaorui Su, Varun Ullanat, Ivy Liang, Lindsay Clegg, Damilola Olabode, Nicholas Ho, Bino John, Megan Gibbs, Marinka Zitnik (2025). *Multimodal AI predicts clinical outcomes of drug combinations from preclinical data*. ArXiv:2503.02781v1. [https://arxiv.org/pdf/2503.02781v1](https://arxiv.org/pdf/2503.02781v1)
42. Manel Gil-Sorribes, Alexis Molina (2025). *Addressing Model Overcomplexity in Drug-Drug Interaction Prediction With Molecular Fingerprints*. ArXiv:2503.23550v1. [https://arxiv.org/pdf/2503.23550v1](https://arxiv.org/pdf/2503.23550v1)
43. Sonish Sivarajkumar, Kimia Ameri, Chuqin Li, Yanshan Wang, Min Jiang (2025). *Automating Adjudication of Cardiovascular Events Using Large Language Models*. ArXiv:2503.17222v1. [https://arxiv.org/pdf/2503.17222v1](https://arxiv.org/pdf/2503.17222v1)
44. Jeffery L Painter, François Haguinet, Gregory E Powell, Andrew Bate (2025). *Ontology-based Semantic Similarity Measures for Clustering Medical Concepts in Drug Safety*. ArXiv:2503.20737v1. [https://arxiv.org/pdf/2503.20737v1](https://arxiv.org/pdf/2503.20737v1)
45. Ekaterina Redekop, Zichen Wang, Rushikesh Kulkarni, Mara Pleasure, Aaron Chin, Hamid Reza Hassanzadeh, Brian L. Hill, Melika Emami, William Speier, Corey W. Arnold (2025). *Zero-shot Medical Event Prediction Using a Generative Pre-trained Transformer on Electronic Health Records*. ArXiv:2503.05893v1. [https://arxiv.org/pdf/2503.05893v1](https://arxiv.org/pdf/2503.05893v1)
46. Michael Albada (2025). *Predicting Clinical Outcomes with Waveform LSTMs*. ArXiv:2503.10925v1. [https://arxiv.org/pdf/2503.10925v1](https://arxiv.org/pdf/2503.10925v1)
47. Soumyashree Sahoo, Chinmaey Shende, Md. Zakir Hossain, Parit Patel, Yushuo Niu, Xinyu Wang, Shweta Ware, Jinbo Bi, Jayesh Kamath, Alexander Russel, Dongjin Song, Qian Yang, Bing Wang (2025). *Cross-platform Prediction of Depression Treatment Outcome Using Location Sensory Data on Smartphones*. ArXiv:2503.07883v1. [https://arxiv.org/pdf/2503.07883v1](https://arxiv.org/pdf/2503.07883v1)
48. Amirhossein Khakpour, Lucia Florescu, Richard Tilley, Haibo Jiang, K. Swaminathan Iyer, Gustavo Carneiro (2025). *AI-Powered Prediction of Nanoparticle Pharmacokinetics: A Multi-View Learning Approach*. ArXiv:2503.13798v1. [https://arxiv.org/pdf/2503.13798v1](https://arxiv.org/pdf/2503.13798v1)
49. Nicholas I-Hsien Kuo, Blanca Gallego, Louisa Jorm (2025). *Attention-Based Synthetic Data Generation for Calibration-Enhanced Survival Analysis: A Case Study for Chronic Kidney Disease Using Electronic Health Records*. ArXiv:2503.06096v1. [https://arxiv.org/pdf/2503.06096v1](https://arxiv.org/pdf/2503.06096v1)
50. Mahdi Arab Loodaricheh, Neh Majmudar, Anita Raja, Ansaf Salleb-Aouissi (2025). *Handling Uncertainty in Health Data using Generative Algorithms*. ArXiv:2503.03715v1. [https://arxiv.org/pdf/2503.03715v1](https://arxiv.org/pdf/2503.03715v1)
51. Yunbo Long, Liming Xu, Alexandra Brintrup (2025). *LLM-TabFlow: Synthetic Tabular Data Generation with Inter-column Logical Relationship Preservation*. ArXiv:2503.02161v1. [https://arxiv.org/pdf/2503.02161v1](https://arxiv.org/pdf/2503.02161v1)
52. Marvin Seyfarth, Salman Ul Hassan Dar, Isabelle Ayx, Matthias Alexander Fink, Stefan O. Schoenberg, Hans-Ulrich Kauczor, Sandy Engelhardt (2025). *MedLoRD: A Medical Low-Resource Diffusion Model for High-Resolution 3D CT Image Synthesis*. ArXiv:2503.13211v1. [https://arxiv.org/pdf/2503.13211v1](https://arxiv.org/pdf/2503.13211v1)
53. Jim Achterberg, Bram van Dijk, Saif ul Islam, Hafiz Muhammad Waseem, Parisis Gallos, Gregory Epiphaniou, Carsten Maple, Marcel Haas, Marco Spruit (2025). *The Data Sharing Paradox of Synthetic Data in Healthcare*. ArXiv:2503.20847v1. [https://arxiv.org/pdf/2503.20847v1](https://arxiv.org/pdf/2503.20847v1)
54. Longfei Wei, Fang Sheng, Jianfei Zhang (2025). *Cohort-attention Evaluation Metric against Tied Data: Studying Performance of Classification Models in Cancer Detection*. ArXiv:2503.12755v1. [https://arxiv.org/pdf/2503.12755v1](https://arxiv.org/pdf/2503.12755v1)
55. Alceu Bissoto, Trung-Dung Hoang, Tim Flühmann, Susu Sun, Christian F. Baumgartner, Lisa M. Koch (2025). *Subgroup Performance Analysis in Hidden Stratifications*. ArXiv:2503.10382v1. [https://arxiv.org/pdf/2503.10382v1](https://arxiv.org/pdf/2503.10382v1)
56. Yinuo Wang, Robert E. Mercer, Frank Rudzicz, Sudipta Singha Roy, Pengjie Ren, Zhumin Chen, Xindi Wang (2025). *Trustworthy Medical Question Answering: An Evaluation-Centric Survey*. ArXiv:2506.03659. [https://www.semanticscholar.org/paper/cf927d5a0044eb56d203335949067c69c8184a45](https://www.semanticscholar.org/paper/cf927d5a0044eb56d203335949067c69c8184a45)
57. Ming Zhang, Yujiong Shen, Zelin Li, Huayu Sha, Binze Hu, Yuhui Wang, Chenhao Huang, Shichun Liu, Jingqi Tong, Changhao Jiang, Mingxu Chai, Zhiheng Xi, Shihan Dou, Tao Gui, Qi Zhang, Xuanjing Huang (2025). *LLMEval-Med: A Real-world Clinical Benchmark for Medical LLMs with Physician Validation*. ArXiv:2506.04078. [https://www.semanticscholar.org/paper/799dcc2efd788f80770b6e829202642c5ca7e742](https://www.semanticscholar.org/paper/799dcc2efd788f80770b6e829202642c5ca7e742)
58. Suhana Bedi, Hejie Cui, Miguel Fuentes, A. Unell, Michael Wornow, Juan M. Banda, N. Kotecha, Timothy Keyes, Yifan Mai, Mert Oez, Hao Qiu, Shrey Jain, Leonardo Schettini, Mehr Kashyap, J. Fries, Akshay Swaminathan, Philip Chung, Fateme Nateghi, Asad Aali, Ashwin Nayak, Shivam Vedak, Sneha S. Jain, Birju Patel, O. Fayanju, Shreya J. Shah, Ethan Goh, Dong-han Yao, Brian T. Soetikno, E. Reis, S. Gatidis, V. Divi, R. Capasso, Rachnanjali L Saralkar, Chia-Chun Chiang, Jenelle A Jindal, Tho Pham, Faraz Ghoddusi, Steven Lin, Albert S. Chiou, Christy Hong, Mohana Roy, M. Gensheimer, Hinesh Patel, Kevin A Schulman, Dev Dash, Danton Char, Lance Downing, F. Grolleau, K. Black, Bethel R Mieso, Aydin Zahedivash, Wen-wai Yim, Harshita Sharma, Tony Lee, Hannah Kirsch, Jennifer Lee, N. Ambers, Carlene Lugtu, Aditya Sharma, Bilal Mawji, A. Alekseyev, Vicky Zhou, Vikas Kakkar, Jarrod Helzer, Anurang Revri, Y. Bannett, Roxana Daneshjou, Jonathan Chen, Emily Alsentzer, Keith E. Morse, Nirmal Ravi, N. Aghaeepour, Vanessa Kennedy, A. Chaudhari, Thomas Wang, Sanmi Koyejo, M. Lungren, Eric Horvitz, Percy Liang, M. Pfeffer, Nigam H. Shah (2025). *MedHELM: Holistic Evaluation of Large Language Models for Medical Tasks*. ArXiv:2505.23802. [https://www.semanticscholar.org/paper/055f837d7b9cb855708cae3fee9104feb46d0dcb](https://www.semanticscholar.org/paper/055f837d7b9cb855708cae3fee9104feb46d0dcb)
59. Jiageng Wu, Bowen Gu, Ren Zhou, Kevin Xie, Doug Snyder, Yixing Jiang, Valentina Carducci, R. Wyss, R. J. Desai, Emily Alsentzer, L. A. Celi, A. Rodman, Sebastian Schneeweiss, Jonathan H. Chen, Santiago Romero-Brufau, K. J. Lin, Jie Yang (2025). *BRIDGE: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text*. ArXiv:10.48550/arXiv.2504.19467. [https://www.semanticscholar.org/paper/3982dd06568c983e94cd748ddaf123829160ee7e](https://www.semanticscholar.org/paper/3982dd06568c983e94cd748ddaf123829160ee7e)
60. Nathan Drenkow, Mitchell Pavlak, Keith Harrigian, Ayah Zirikly, Adarsh Subbaswamy, Mathias Unberath (2025). *Detecting Dataset Bias in Medical AI: A Generalized and Modality-Agnostic Auditing Framework*. ArXiv:2503.09969v1. [https://arxiv.org/pdf/2503.09969v1](https://arxiv.org/pdf/2503.09969v1)
61. Mouath Abu Daoud, Chaimae Abouzahir, Leen Kharouf, Walid Al-Eisawi, Nizar Habash, Farah E. Shamout (2025). *MedArabiQ: Benchmarking Large Language Models on Arabic Medical Tasks*. ArXiv:2505.03427. [https://www.semanticscholar.org/paper/00873a8228e515b87a0e0690cff8fbc1e71200e9](https://www.semanticscholar.org/paper/00873a8228e515b87a0e0690cff8fbc1e71200e9)
62. Guangfu Guo, Kai Zhang, Bryan Hoo, Yujun Cai, Xiaoqian Lu, Nanyun Peng, Yiwei Wang (2025). *Structured Outputs Enable General-Purpose LLMs to be Medical Experts*. ArXiv:2503.03194v1. [https://arxiv.org/pdf/2503.03194v1](https://arxiv.org/pdf/2503.03194v1)
63. Juncheng Wu, Wenlong Deng, Xingxuan Li, Sheng Liu, Taomian Mi, Yifan Peng, Ziyang Xu, Yi Liu, Hyunjin Cho, Chang-In Choi, Yihan Cao, Hui Ren, Xiang Li, Xiaoxiao Li, Yuyin Zhou (2025). *MedReason: Eliciting Factual Medical Reasoning Steps in LLMs via Knowledge Graphs*. ArXiv:2504.00993v2. [https://arxiv.org/pdf/2504.00993v2](https://arxiv.org/pdf/2504.00993v2)
64. Zhiwen You, Yue Guo (2025). *PlainQAFact: Automatic Factuality Evaluation Metric for Biomedical Plain Language Summaries Generation*. ArXiv:2503.08890v1. [https://arxiv.org/pdf/2503.08890v1](https://arxiv.org/pdf/2503.08890v1)
65. Shuang Zhou, Jiashuo Wang, Zidu Xu, Song Wang, David Brauer, Lindsay Welton, Jacob C. Cogan, Yuen-Hei Chung, Lei Tian, Zaifu Zhan, Yu Hou, Mingquan Lin, Genevieve B. Melton, Rui Zhang (2025). *Uncertainty-Aware Large Language Models for Explainable Disease Diagnosis*. ArXiv:2505.03467. [https://www.semanticscholar.org/paper/099538285ce1f8e42fbed3e108a530c8673e03cd](https://www.semanticscholar.org/paper/099538285ce1f8e42fbed3e108a530c8673e03cd)
66. Changyi Li, Jiayi Wang, Xu Pan, Geng Hong, Min Yang (2025). *ReasoningShield: Content Safety Detection over Reasoning Traces of Large Reasoning Models*. ArXiv:2505.17244. [https://www.semanticscholar.org/paper/4ff2430e21d70cb08a05fdc707a3975f781d3a2a](https://www.semanticscholar.org/paper/4ff2430e21d70cb08a05fdc707a3975f781d3a2a)
67. Mohit Gupta, Akiko Aizawa, R. Shah (2025). *Med-CoDE: Medical Critique based Disagreement Evaluation Framework*. ArXiv:10.48550/arXiv.2504.15330. [https://www.semanticscholar.org/paper/3c1c0364f3e1e7bbe6bcd5da4325888ca2bf3079](https://www.semanticscholar.org/paper/3c1c0364f3e1e7bbe6bcd5da4325888ca2bf3079)
68. Honglong Yang, Shanshan Song, Yi Qin, Lehan Wang, Haonan Wang, Xinpeng Ding, Qixiang Zhang, Bodong Du, Xiaomeng Li (2025). *Multi-Modal Explainable Medical AI Assistant for Trustworthy Human-AI Collaboration*. ArXiv:2505.06898. [https://www.semanticscholar.org/paper/07d266beef338141705430cce2bdd8419ca90250](https://www.semanticscholar.org/paper/07d266beef338141705430cce2bdd8419ca90250)
69. Tianhong Zhou, Yin Xu, Yingtao Zhu, Chuxi Xiao, Haiyang Bian, Lei Wei, Xuegong Zhang (2025). *DrVD-Bench: Do Vision-Language Models Reason Like Human Doctors in Medical Image Diagnosis?*. ArXiv:2505.24173. [https://www.semanticscholar.org/paper/e183dd689fe208bde16f4426984a2958a7ac9ccb](https://www.semanticscholar.org/paper/e183dd689fe208bde16f4426984a2958a7ac9ccb)
70. Hyunjae Kim, Hyeon Hwang, Jiwoo Lee, Sihyeon Park, Dain Kim, Taewhoo Lee, Chanwoong Yoon, Jiwoong Sohn, Jungwoo Park, Olga Reykhart, T. Fetherston, Donghee Choi, Soo Heon Kwak, Qingyu Chen, Jaewoo Kang (2025). *Small language models learn enhanced reasoning skills from medical textbooks*. ArXiv:10.1038/s41746-025-01653-8. [https://www.semanticscholar.org/paper/7445f3d7a16d992029585e93704ec44f0e99e43e](https://www.semanticscholar.org/paper/7445f3d7a16d992029585e93704ec44f0e99e43e)
71. Che Liu, Haozhe Wang, Jiazhen Pan, Zhongwei Wan, Yong Dai, Fangzhen Lin, Wenjia Bai, D. Rueckert, Rossella Arcucci (2025). *Beyond Distillation: Pushing the Limits of Medical LLM Reasoning with Minimalist Rule-Based RL*. ArXiv:2505.17952. [https://www.semanticscholar.org/paper/bb26c61cbe322a4f8cf81e8e461d680a5ff05923](https://www.semanticscholar.org/paper/bb26c61cbe322a4f8cf81e8e461d680a5ff05923)
72. Yan Jia, Harriet Evans, Zoe Porter, Simon Graham, John McDermid, Tom Lawton, David Snead, Ibrahim Habli (2025). *The case for delegated AI autonomy for Human AI teaming in healthcare*. ArXiv:2503.18778v1. [https://arxiv.org/pdf/2503.18778v1](https://arxiv.org/pdf/2503.18778v1)
73. Neil Mallinar, A. Ali Heydari, Xin Liu, Anthony Z. Faranesh, Brent Winslow, Nova Hammerquist, Benjamin Graef, Cathy Speed, Mark Malhotra, Shwetak Patel, Javier L. Prieto, Daniel McDuff, Ahmed A. Metwally (2025). *A Scalable Framework for Evaluating Health Language Models*. ArXiv:2503.23339v2. [https://arxiv.org/pdf/2503.23339v2](https://arxiv.org/pdf/2503.23339v2)
74. Xiaomin Li, Mingye Gao, Yuexing Hao, Taoran Li, Guangya Wan, Zihan Wang, Yijun Wang (2025). *MedGUIDE: Benchmarking Clinical Decision-Making in Large Language Models*. ArXiv:2505.11613. [https://www.semanticscholar.org/paper/3f97c3c28ed58fe20b5d0144a4a03fb0ed24c690](https://www.semanticscholar.org/paper/3f97c3c28ed58fe20b5d0144a4a03fb0ed24c690)
75. Haoan Jin, Jiacheng Shi, Hanhui Xu, Kenny Q. Zhu, Mengyue Wu (2025). *MedEthicEval: Evaluating Large Language Models Based on Chinese Medical Ethics*. ArXiv:2503.02374v1. [https://arxiv.org/pdf/2503.02374v1](https://arxiv.org/pdf/2503.02374v1)
76. Dan Sun, Jacky He, Hanlu Zhang, Zhen Qi, Hongye Zheng, Xiaokai Wang (2025). *A LongFormer-Based Framework for Accurate and Efficient Medical Text Summarization*. ArXiv:2503.06888v1. [https://arxiv.org/pdf/2503.06888v1](https://arxiv.org/pdf/2503.06888v1)
77. Fahmida Liza Piya, Rahmatollah Beheshti (2025). *ConTextual: Improving Clinical Text Summarization in LLMs with Context-preserving Token Filtering and Knowledge Graphs*. ArXiv:10.48550/arXiv.2504.16394. [https://www.semanticscholar.org/paper/36bf667b489fc59ef684913a5f535f4949ca7584](https://www.semanticscholar.org/paper/36bf667b489fc59ef684913a5f535f4949ca7584)
78. Brian Wong, Kaito Tanaka (2025). *High-Fidelity Pseudo-label Generation by Large Language Models for Training Robust Radiology Report Classifiers*. ArXiv:2505.01693. [https://www.semanticscholar.org/paper/6a185f003963b317f6d89802df6f1b0fd9b0d0c](https://www.semanticscholar.org/paper/6a185f003963b317f6d89802df6f1b0fd9b0d0c)
79. Hannah Kim, Sofia Martinez, Jason Lee (2025). *Cross-Modal State-Space Graph Reasoning for Structured Summarization*. ArXiv:2503.20988v1. [https://arxiv.org/pdf/2503.20988v1](https://arxiv.org/pdf/2503.20988v1)
80. Yao Ge, Yuting Guo, Sudeshna Das, Swati Rajwal, Selen Bozkurt, Abeed Sarker (2025). *HILGEN: Hierarchically-Informed Data Generation for Biomedical NER Using Knowledgebases and Large Language Models*. ArXiv:2503.04930v1. [https://arxiv.org/pdf/2503.04930v1](https://arxiv.org/pdf/2503.04930v1)
81. Sajjadul Islam, Ayesha Siddika Nipu, Jiawei Wu, Praveen Madiraju (2025). *LLM-based Prompt Ensemble for Reliable Medical Entity Recognition from EHRs*. ArXiv:2505.08704. [https://www.semanticscholar.org/paper/1f95c6911773246f99117cd583f48f2435f658a6](https://www.semanticscholar.org/paper/1f95c6911773246f99117cd583f48f2435f658a6)
82. Leonor Barreiros, Isabel Coutinho, Gonçalo M. Correia, Bruno Martins (2025). *Explainable ICD Coding via Entity Linking*. ArXiv:2503.20508v1. [https://arxiv.org/pdf/2503.20508v1](https://arxiv.org/pdf/2503.20508v1)
83. Komal Gilani, Marlo Verket, Christof Peters, M. Dumontier, Hans-Peter Brunner-La Rocca, V. Urovi (2025). *CDE-Mapper: Using Retrieval-Augmented Language Models for Linking Clinical Data Elements to Controlled Vocabularies*. ArXiv:2505.04365. [https://www.semanticscholar.org/paper/ecc3051e19f7713350e0950b6cde1f0841ca2d7c](https://www.semanticscholar.org/paper/ecc3051e19f7713350e0950b6cde1f0841ca2d7c)
84. Noah Losch, Lucas Plagwitz, Antonius Büscher, Julian Varghese (2025). *Fine-Tuning LLMs on Small Medical Datasets: Text Classification and Normalization Effectiveness on Cardiology reports and Discharge records*. ArXiv:2503.21349v1. [https://arxiv.org/pdf/2503.21349v1](https://arxiv.org/pdf/2503.21349v1)
85. Mohammad Shoaib Ansari, Mohd Sohail Ali Khan, Shubham Revankar, Aditya Varma, A. S. Mokhade (2025). *Lightweight Clinical Decision Support System using QLoRA-Fine-Tuned LLMs and Retrieval-Augmented Generation*. ArXiv:2505.03406. [https://www.semanticscholar.org/paper/72afb9cbc91c104e3bf1ead3588c6977f173591f](https://www.semanticscholar.org/paper/72afb9cbc91c104e3bf1ead3588c6977f173591f)
86. Jean-Philippe Corbeil, Amin Dada, Jean-Michel Attendu, Asma Ben Abacha, Alessandro Sordoni, Lucas Caccia, Franccois Beaulieu, Thomas Lin, J. Kleesiek, Paul Vozila (2025). *A Modular Approach for Clinical SLMs Driven by Synthetic Data with Pre-Instruction Tuning, Model Merging, and Clinical-Tasks Alignment*. ArXiv:2505.10717. [https://www.semanticscholar.org/paper/c668268d68e646ef9d1a4df35264450d32573ca4](https://www.semanticscholar.org/paper/c668268d68e646ef9d1a4df35264450d32573ca4)
87. A. Mavridis, Stergios Tegos, Christos Anastasiou, Maria Papoutsoglou, G. Meditskos (2025). *Large language models for intelligent RDF knowledge graph construction: results from medical ontology mapping*. ArXiv:10.3389/frai.2025.1546179. [https://www.semanticscholar.org/paper/c9d2616f0b49b9842c34309373f7d2b419f2bbcc](https://www.semanticscholar.org/paper/c9d2616f0b49b9842c34309373f7d2b419f2bbcc)
88. Tingyu Song, Guo Gan, Mingsheng Shang, Yilun Zhao (2025). *IFIR: A Comprehensive Benchmark for Evaluating Instruction-Following in Expert-Domain Information Retrieval*. ArXiv:2503.04644v1. [https://arxiv.org/pdf/2503.04644v1](https://arxiv.org/pdf/2503.04644v1)
89. Hejie Cui, Alyssa Unell, Bowen Chen, Jason Alan Fries, Emily Alsentzer, Sanmi Koyejo, Nigam Shah (2025). *TIMER: Temporal Instruction Modeling and Evaluation for Longitudinal Clinical Records*. ArXiv:2503.04176v1. [https://arxiv.org/pdf/2503.04176v1](https://arxiv.org/pdf/2503.04176v1)
90. Shahriar Noroozizadeh, Sayantan Kumar, Jeremy C. Weiss (2025). *Forecasting from Clinical Textual Time Series: Adaptations of the Encoder and Decoder Language Model Families*. ArXiv:10.48550/arXiv.2504.10340. [https://www.semanticscholar.org/paper/c1130a3634facb2a22edde49adb58ee6f042c585](https://www.semanticscholar.org/paper/c1130a3634facb2a22edde49adb58ee6f042c585)
91. Munib Mesinovic, Soheila Molaei, Peter Watkinson, Tingting Zhu (2025). *DynaGraph: Interpretable Multi-Label Prediction from EHRs via Dynamic Graph Learning and Contrastive Augmentation*. ArXiv:2503.22257v1. [https://arxiv.org/pdf/2503.22257v1](https://arxiv.org/pdf/2503.22257v1)
92. Negin Baghbanzadeh, Adibvafa Fallahpour, Yasaman Parhizkar, Franklin Ogidi, Shuvendu Roy, Sajad Ashkezari, Vahid Reza Khazaie, Michael Colacci, Ali Etemad, Arash Afkanpour, Elham Dolatabadi (2025). *Advancing Medical Representation Learning Through High-Quality Data*. ArXiv:2503.14377v1. [https://arxiv.org/pdf/2503.14377v1](https://arxiv.org/pdf/2503.14377v1)
93. Hongkai Zheng, Wenda Chu, Bingliang Zhang, Zihui Wu, Austin Wang, Berthy T. Feng, Caifeng Zou, Yu Sun, Nikola Kovachki, Zachary E. Ross, Katherine L. Bouman, Yisong Yue (2025). *InverseBench: Benchmarking Plug-and-Play Diffusion Priors for Inverse Problems in Physical Sciences*. ArXiv:2503.11043v1. [https://arxiv.org/pdf/2503.11043v1](https://arxiv.org/pdf/2503.11043v1)
94. Zeyu Liu, Zhitian Hou, Yining Di, Kejing Yang, Zhijie Sang, Congkai Xie, Jingwen Yang, Siyuan Liu, Jialu Wang, Chunming Li, Ming Li, Hongxia Yang (2025). *Infi-Med: Low-Resource Medical MLLMs with Robust Reasoning Evaluation*. ArXiv:2505.23867. [https://www.semanticscholar.org/paper/fd1d271d0cb4aba04aea8a495cfb2f85e03ac310](https://www.semanticscholar.org/paper/fd1d271d0cb4aba04aea8a495cfb2f85e03ac310)
95. Jiarui Ye, Hao Tang (2025). *Multimodal Large Language Models for Medicine: A Comprehensive Survey*. ArXiv:10.48550/arXiv.2504.21051. [https://www.semanticscholar.org/paper/427781f67ea66a168a323a75fad3f6958451bf8d](https://www.semanticscholar.org/paper/427781f67ea66a168a323a75fad3f6958451bf8d)
96. Tan-Hanh Pham, Chris Ngo, Trong-Duong Bui, Quang Minh Luu, Tan-Huong Pham, Truong-Son Hy (2025). *SilVar-Med: A Speech-Driven Visual Language Model for Explainable Abnormality Detection in Medical Imaging*. ArXiv:10.48550/arXiv.2504.10642. [https://www.semanticscholar.org/paper/3229cf59258ee0d804906639585167ce6ef1ab0d](https://www.semanticscholar.org/paper/3229cf59258ee0d804906639585167ce6ef1ab0d)
97. Tsai-Ning Wang, Lin-Lin Chen, Neil Zeghidour, Aaqib Saeed (2025). *CaReAQA: A Cardiac and Respiratory Audio Question Answering Model for Open-Ended Diagnostic Reasoning*. ArXiv:2505.01199. [https://www.semanticscholar.org/paper/26c4333cd8017e72e9ef2cb1fdf5e3931d3f22f6](https://www.semanticscholar.org/paper/26c4333cd8017e72e9ef2cb1fdf5e3931d3f22f6)
98. Hung Manh Pham, Jialu Tang, Aaqib Saeed, Dong Ma (2025). *Q-Heart: ECG Question Answering via Knowledge-Informed Multimodal LLMs*. ArXiv:2505.06296. [https://www.semanticscholar.org/paper/089109b4a7192aae0f24bb3b13675f93b3b3844f](https://www.semanticscholar.org/paper/089109b4a7192aae0f24bb3b13675f93b3b3844f)
99. Sangwook Kim, Soonyoung Lee, Jongseong Jang (2025). *ChatEXAONEPath: An Expert-level Multimodal Large Language Model for Histopathology Using Whole Slide Images*. ArXiv:10.48550/arXiv.2504.13023. [https://www.semanticscholar.org/paper/4afaf013bfaf6fa09e905be17c12b3e628e56e66](https://www.semanticscholar.org/paper/4afaf013bfaf6fa09e905be17c12b3e628e56e66)
100. Valerii A. Zuev, Elena G. Salmagambetova, Stepan N. Djakov, Lev V. Utkin (2025). *Automated Video-EEG Analysis in Epilepsy Studies: Advances and Challenges*. ArXiv:2503.19949v1. [https://arxiv.org/pdf/2503.19949v1](https://arxiv.org/pdf/2503.19949v1)
101. Yongpei Ma, Pengyu Wang, Adam Dunn, Usman Naseem, Jinman Kim (2025). *Bridging the Semantic Gaps: Improving Medical VQA Consistency with LLM-Augmented Question Sets*. ArXiv:10.48550/arXiv.2504.11777. [https://www.semanticscholar.org/paper/3353071ae316f2886d5663bc460d7f4490cba15a](https://www.semanticscholar.org/paper/3353071ae316f2886d5663bc460d7f4490cba15a)
102. Pengyu Wang, Shuchang Ye, Usman Naseem, Jinman Kim (2025). *MRGAgents: A Multi-Agent Framework for Improved Medical Report Generation with Med-LVLMs*. ArXiv:2505.18530. [https://www.semanticscholar.org/paper/0b31b97f2fd7722833b124032733b913dc29cbb3](https://www.semanticscholar.org/paper/0b31b97f2fd7722833b124032733b913dc29cbb3)
103. Huimin Xu, Seungjun Yi, Terence Lim, Jiawei Xu, Andrew Well, Carlos Mery, Aidong Zhang, Yuji Zhang, Heng Ji, Keshav Pingali, Yan Leng, Ying Ding (2025). *TAMA: A Human-AI Collaborative Thematic Analysis Framework Using Multi-Agent LLMs for Clinical Interviews*. ArXiv:2503.20666v1. [https://arxiv.org/pdf/2503.20666v1](https://arxiv.org/pdf/2503.20666v1)
104. Shraddha Surana, Ashwin Srinivasan (2025). *Engineering Scientific Assistants using Interactive Structured Induction of Programs*. ArXiv:2503.14488v1. [https://arxiv.org/pdf/2503.14488v1](https://arxiv.org/pdf/2503.14488v1)
105. Mohammad Beheshti, Lovedeep Gondara, Iris Zachary (2025). *Leveraging Language Models for Automated Patient Record Linkage*. ArXiv:10.48550/arXiv.2504.15261. [https://www.semanticscholar.org/paper/6c2f5ef88f7aabc3de3101e8ca3f19ba10f152df](https://www.semanticscholar.org/paper/6c2f5ef88f7aabc3de3101e8ca3f19ba10f152df)
106. Shanghua Gao, Richard Zhu, Zhenglun Kong, Ayush Noori, Xiaorui Su, Curtis Ginder, Theodoros Tsiligkaridis, Marinka Zitnik (2025). *TxAgent: An AI Agent for Therapeutic Reasoning Across a Universe of Tools*. ArXiv:2503.10970v1. [https://arxiv.org/pdf/2503.10970v1](https://arxiv.org/pdf/2503.10970v1)
107. Yuting Guo, Abeed Sarker (2025). *Comparing Llama3 and DeepSeekR1 on Biomedical Text Classification Tasks*. ArXiv:2503.15169v1. [https://arxiv.org/pdf/2503.15169v1](https://arxiv.org/pdf/2503.15169v1)
108. Henning Schäfer, C. S. Schmidt, Johannes Wutzkowsky, Kamil Lorek, Lea Reinartz, Johannes Rückert, Christian Temme, Britta Böckmann, Peter A. Horn, Christoph M. Friedrich (2025). *A Multimodal Pipeline for Clinical Data Extraction: Applying Vision-Language Models to Scans of Transfusion Reaction Reports*. ArXiv:10.48550/arXiv.2504.20220. [https://www.semanticscholar.org/paper/2e12a6ebafc995ad11f9a9c0fd2d958b04b04915](https://www.semanticscholar.org/paper/2e12a6ebafc995ad11f9a9c0fd2d958b04b04915)
109. Negin Baghbanzadeh, Sajad Ashkezari, Elham Dolatabadi, Arash Afkanpour (2025). *Open-PMC-18M: A High-Fidelity Large Scale Medical Dataset for Multimodal Representation Learning*. ArXiv:2506.02738. [https://www.semanticscholar.org/paper/a0a00656d181b83ea265d942c529d419c52fd25a](https://www.semanticscholar.org/paper/a0a00656d181b83ea265d942c529d419c52fd25a)
110. Sara Ketabi, D. Ramachandram (2025). *Bridging Electronic Health Records and Clinical Texts: Contrastive Learning for Enhanced Clinical Tasks*. ArXiv:2505.17643. [https://www.semanticscholar.org/paper/7e6cac75f28a8e1b9be883597a56d3bb6da8bb04](https://www.semanticscholar.org/paper/7e6cac75f28a8e1b9be883597a56d3bb6da8bb04)
111. Chao Ding, Mouxiao Bian, Pengcheng Chen, Hongliang Zhang, Tian-Xin Li, Lihao Liu, Jiayuan Chen, Zhuoran Li, Yabei Zhong, Yongqi Liu, Haiqing Huang, Dongming Shan, Junjun He, Jie Xu (2025). *Building a Human-Verified Clinical Reasoning Dataset via a Human LLM Hybrid Pipeline for Trustworthy Medical AI*. ArXiv:2505.06912. [https://www.semanticscholar.org/paper/977586e2442843ba13ee9fe902bd86f7548b56aa](https://www.semanticscholar.org/paper/977586e2442843ba13ee9fe902bd86f7548b56aa)
112. Kevin Wu, Eric Wu, Rahul Thapa, Kevin Wei, Angela Zhang, Arvind Suresh, Jacqueline J. Tao, Min Woo Sun, Alejandro Lozano, James Zou (2025). *MedCaseReasoning: Evaluating and learning diagnostic reasoning from clinical case reports*. ArXiv:2505.11733. [https://www.semanticscholar.org/paper/f43946d590fdf0b91d6d9f0c55a57e4bf5786df4](https://www.semanticscholar.org/paper/f43946d590fdf0b91d6d9f0c55a57e4bf5786df4)
113. Praphul Singh, Charlotte Dzialo, Jangwon Kim, Sumana Srivatsa, Irfan Bulu, Sri Gadde, K. Kenthapadi (2025). *RedactOR: An LLM-Powered Framework for Automatic Clinical Data De-Identification*. ArXiv:2505.18380. [https://www.semanticscholar.org/paper/6a8ff1b5fc096dab785873732509e29f1752fba7](https://www.semanticscholar.org/paper/6a8ff1b5fc096dab785873732509e29f1752fba7)
114. Nathan T. Rich, Sarah Salzman, Gabriel Altay, Kunal Nagpal, Vivek Shetye, Gena A Rangel, Poojan Thakkar, Annie Darmofal, Dan Sun, B. O'Neil, A. Zarzour, John Nemunaitis, James F. Maher, Philip E Lammers, Srilata Gundala, T. Pluard, Viran R. Holden, Arpita Saha, Victoria L. Chiou, C. Osterman (2025). *Impact of large language models on trial-to-patient matching efficiency.*. ArXiv:10.1200/jco.2025.43.16_suppl.e13600. [https://www.semanticscholar.org/paper/00bd7358bdce4c2992599451e2d316f25397bab4](https://www.semanticscholar.org/paper/00bd7358bdce4c2992599451e2d316f25397bab4)
115. Arturo Loaiza-Bonilla, S. Kurnaz, Ertugrul Tuysuz, Oz Huner, Dersu Giritlioğlu, Juan Pablo Noel Meza (2025). *Transforming oncology clinical trial matching through multi-agent AI and an oncology-specific knowledge graph: A prospective evaluation in 3,800 patients.*. ArXiv:10.1200/jco.2025.43.16_suppl.1554. [https://www.semanticscholar.org/paper/dad80f36a1b8fa757552c76ced3b6e43e093c6c2](https://www.semanticscholar.org/paper/dad80f36a1b8fa75752c76ced3b6e43e093c6c2)
116. Yan Leyfman, Arturo Loaiza-Bonilla, Viviana Cortiana, Ertugrul Tuysuz, S. Kurnaz, Oz Huner, Dersu Giritlioğlu, Juan Pablo Noel Meza, C. Culcuoglu (2025). *Performance evaluation of an AI-powered system for clinical trial eligibility using mCODE data standards.*. ArXiv:10.1200/jco.2025.43.16_suppl.e13621. [https://www.semanticscholar.org/paper/51ce73e5731db9c8906b84f54412fa6bc3750464](https://www.semanticscholar.org/paper/51ce73e5731db9c8906b84f54412fa6bc3750464)
117. Nikita Mehandru, Niloufar Golchini, David Bamman, Travis Zack, Melanie F. Molina, Ahmed Alaa (2025). *ER-REASON: A Benchmark Dataset for LLM-Based Clinical Reasoning in the Emergency Room*. ArXiv:2505.22919. [https://www.semanticscholar.org/paper/55d73c928f98506b4388035886382f9a9d8dd98d](https://www.semanticscholar.org/paper/55d73c928f98506b4388035886382f9a9d8dd98d)
118. Johannes Moll, Louisa Fay, Asfandyar Azhar, Sophie Ostmeier, Tim Lueth, S. Gatidis, Curtis P. Langlotz, Jean-Benoit Delbrouck (2025). *Structuring Radiology Reports: Challenging LLMs with Lightweight Models*. ArXiv:2506.00200. [https://www.semanticscholar.org/paper/3d7fc1824d6e6fde1b68c48015c9e3870ffd03db](https://www.semanticscholar.org/paper/3d7fc1824d6e6fde1b68c48015c9e3870ffd03db)
119. Chayan Mondal, Duc-Son Pham, Ashu Gupta, Tele Tan, Tom Gedeon (2025). *Leveraging Prompt Engineering with Lightweight Large Language Models to Label and Extract Clinical Information from Radiology Reports*. ArXiv:10.1145/3701716.3717808. [https://www.semanticscholar.org/paper/335cd141c6f07bf3ce43eb058ace99c0d0448cac](https://www.semanticscholar.org/paper/335cd141c6f07bf3ce43eb058ace99c0d0448cac)
120. Faisal Abdullah, Althobaiti (2025). *A Survey on Using Large Language Models in Healthcare*. ArXiv:10.7753/ijsea1406.1001. [https://www.semanticscholar.org/paper/a4730fd88d2249de1bed9a0f1a9a7641b1caba8d](https://www.semanticscholar.org/paper/a4730fd88d2249de1bed9a0f1a9a7641b1caba8d)
