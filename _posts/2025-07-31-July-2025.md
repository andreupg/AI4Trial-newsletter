---
title: July 2025
date: 2025-07-31
categories: [Newsletters]
tags: [ai, clinical-trials, data-management, federated-learning, personalized-medicine]
description: This issue explores recent breakthroughs in leveraging AI to enhance precision protocol design, personalize treatment strategies, streamline data operations, optimize clinical trial management, and address ethical considerations for trial outcomes.
---
# Introduction

Artificial intelligence (AI) is fundamentally reshaping clinical research, enabling advancements across the entire lifecycle of clinical trials. This issue explores recent breakthroughs in leveraging AI to enhance the precision of protocol design and personalize treatment strategies by identifying patient subgroups and dynamically modeling treatment effects. It also details innovations in streamlining data operations, improving interoperability, and ensuring data quality through automated standardization, sophisticated information extraction, and the responsible generation of synthetic data. Furthermore, the contributions address the optimization of clinical trial operations and monitoring, particularly through privacy-preserving collaborative frameworks and real-time oversight. Finally, a dedicated focus is placed on advanced analytics and ethical considerations for trial outcomes, emphasizing fairness, robust causal inference, and the development of trustworthy, interpretable AI tools. These developments collectively advance the efficiency, rigor, and patient-centricity of medical innovation.

# AI for Precision Protocol Design and Personalized Treatment Strategies

Artificial intelligence (AI) is rapidly transforming the landscape of clinical trials, fundamentally revolutionizing protocol design, patient selection, and treatment optimization. These advancements enable more precise identification of patient subgroups, dynamic modeling of treatment effects, and robust estimation of individualized treatment effects (ITEs) from diverse data sources, ultimately leading to more efficient, targeted, and successful trial designs.

Key to this transformation is the development of sophisticated methods for **identifying patient subgroups and estimating individualized treatment effects**. Traditional methods often struggle with the heterogeneity of treatment responses. To address this, novel algorithms are emerging, such as the one for identifying interpretable subgroups with elevated treatment effects using rule sets, which can optimize inclusion/exclusion criteria for clinical trials and provide actionable insights into *why* certain patient characteristics predict better responses [1](https://arxiv.org/pdf/2507.09494v1). Complementing this, Deep Disentangled Representation Networks (DDRN) [2](https://arxiv.org/pdf/2507.06650v1) enhance the accuracy of ITE estimation from observational data by decomposing patient characteristics to isolate confounding factors, supporting personalized medicine and optimizing real-world evidence (RWE) utilization. The Consistent Labeling Across Group Assignments (CLAGA) algorithm further refines Conditional Average Treatment Effect (CATE) estimation by ensuring consistent learning across treatment and control groups, thereby reducing variance and improving reliability [3](https://arxiv.org/pdf/2507.04332v1). For scenarios where randomized controlled trial (RCT) data are limited, the QR-learner robustly estimates CATEs by leveraging external data, even when misaligned, to improve precision and statistical power [4](https://arxiv.org/pdf/2507.03681v1). Deep learning models, such as ONTRAMs, also predict functional outcomes and ITEs by integrating clinical and imaging data, contributing to more precise outcome prediction and patient selection, particularly in complex conditions like Large Vessel Occlusion (LVO) stroke [5](https://arxiv.org/pdf/2507.03046v1). The Self-Balancing Neural Network (Sbnet) offers a one-step approach for estimating Average Treatment Effects (ATEs) in observational studies by integrating propensity score estimation directly into the neural network architecture, potentially reducing reliance on costly RCTs [6](https://arxiv.org/pdf/2507.12818v1). Furthermore, Targeted Deep Architectures (TDA) enable deep neural networks to perform rigorous estimation of causal parameters like treatment effects and survival curves, embedding debiasing mechanisms directly within the architecture for scalable and theoretically grounded causal analyses [7](https://arxiv.org/pdf/2507.12435v1). For survival data with high-dimensional covariates, Horseshoe Forests provide a Bayesian tree ensemble model to estimate heterogeneous treatment effects, improving the identification of patient subgroups benefiting most from specific treatments over time [8](https://arxiv.org/pdf/2507.22004v2). Addressing challenges with incomplete patient information, Large Language Model (LLM)-driven frameworks are being developed to improve treatment effect estimations when dealing with textual data, mitigating biases caused by inference-time text confounding [9](https://arxiv.org/pdf/2507.02843v1).

Beyond static effect estimation, AI is crucial for **dynamic modeling and adaptive strategies**. The field is moving beyond static summary metrics like ATE to model treatment effects as dynamic functions of both dose and time. This allows for the extraction of granular, clinically actionable insights such as optimal timing for peak effect and duration of therapeutic benefit, which can profoundly improve trial design by informing dosage selection and outcome measurement points [10](https://arxiv.org/pdf/2507.07271v2). In terms of trial execution, novel protocols are being developed to efficiently verify the quality of adaptive treatment allocation strategies. By drawing parallels with multi-armed bandit problems, these protocols can assess whether a given strategy is "near-optimal" using significantly fewer patient observations than required to learn the optimal strategy from scratch, accelerating trial phases and potentially lowering costs [11](https://arxiv.org/pdf/2507.10567v1).

AI also provides powerful tools for leveraging **real-world evidence and generating synthetic data** for 'in silico' testing. The Structural Difference-in-Differences with Machine Learning (S-DIDML) framework integrates traditional DID methods with ML to address high-dimensional confounding variables in observational panel data. This approach retains causal interpretability while leveraging ML for flexible estimation, crucial for optimizing RWE analysis and identifying heterogeneous treatment effects [12](https://arxiv.org/pdf/2507.15899v1). Furthermore, synthetic data generation offers a powerful avenue for pre-trial validation and simulation. Methodologies leveraging LLMs can automate and enhance the development of Synthea disease modules, accelerating the creation of complex, realistic synthetic patient data for simulating trial populations and testing protocols [13](https://arxiv.org/pdf/2507.21123v1). Similarly, RawMed advances the generation of synthetic Electronic Health Records (EHRs) by preserving the raw, multi-table, time-series nature of the data with minimal preprocessing, enabling the creation of highly realistic, privacy-preserving synthetic datasets for trial design, AI model development, and data sharing [14](https://arxiv.org/pdf/2507.06996v1). The Limit Inferior Leaf Interval (LILI) clustering algorithm refines causal forest methods to mitigate bias and improve ATE prediction accuracy, particularly for observational data, by establishing connections between individual causal trees [15](https://arxiv.org/pdf/2507.03271v1).

In conclusion, these AI-driven breakthroughs are poised to transform clinical trials by enabling more precise patient stratification, dynamic treatment modeling, robust individualized effect estimation, and efficient in silico validation. By enhancing the rigor and efficiency of trial design and execution, AI facilitates the development of more targeted and effective treatment strategies, ultimately benefiting patient care.

# Streamlining Data Operations, Interoperability, and Quality

Efficient and reliable data management is the bedrock of successful clinical trials, influencing everything from patient recruitment to the validity of study outcomes. Artificial intelligence, particularly through the advancements in Large Language Models (LLMs), is poised to fundamentally transform how clinical data is handled, from raw collection and standardization to quality assurance and secure sharing. These innovations promise to significantly reduce manual effort, accelerate data flow, and enhance the overall integrity and interoperability of clinical trial data.

A significant challenge in clinical data management is the heterogeneity of data sources and formats, which hinders seamless exchange and analysis. LLMs are now being leveraged to automate data standardization into interoperable formats like HL7 FHIR. For structured clinical data, a semi-automated pipeline has been developed using LLMs (GPT-4o and Llama 3.2) alongside Retrieval Augmented Generation (RAG) and semantic clustering to map tabular data to FHIR resources [16](https://arxiv.org/pdf/2507.03067v1). This approach aims to streamline data integration, although it necessitates manual validation to mitigate "hallucinations" and is currently limited to FHIR, not encompassing other standards like OMOP. Extending this to unstructured notes, the Infherno framework employs LLM agents, code execution, and healthcare terminology tools (e.g., SNOMED CT) to synthesize FHIR resources directly from free-form clinical text [17](https://arxiv.org/pdf/2507.12261v1). This automates data extraction and standardization from sources like patient records, crucial for retrospective analysis and real-world evidence. While promising for efficiency and scalability, Infherno's reliance on commercial LLMs and synthetic data for evaluation highlights the need for further validation on real-world, diverse clinical notes and with open-weight models, also considering potential licensing for terminology servers. Related research further explores LLMs for extracting medication information [18](https://www.semanticscholar.org/paper/129c1a9848d0c784647cbee5d5dec545b41b4543) and structuring posology instructions [19](https://www.semanticscholar.org/paper/f7ffe1247a7cb53b3f532a18a91a0feb39dd49de).

Beyond standardization, LLMs significantly enhance information extraction and data annotation from complex, unstructured clinical notes. AI RAG tools have demonstrated the capability to accelerate information extraction and data annotation tasks by up to tenfold, while also improving accuracy, particularly in interactive human-AI workflows [20](https://arxiv.org/pdf/2507.21360v1). This acceleration can directly impact clinical trial timelines by streamlining the processing of patient records and literature. The Language Model Chain (LMC) algorithm offers another advancement, chaining multiple LMs with candidate answer validation to iteratively refine predictions, notably reducing hallucinations and increasing speed and accuracy in tasks like extracting patient dates of birth from medical documents [21](https://arxiv.org/pdf/2507.22921v1). This multi-stage approach also helps manage computational costs. Furthermore, generative LLMs like GPT-3.5 and GPT-4.5 are being deployed for complex multi-label classification, such as identifying suicidality-related factors from psychiatric EHRs, enabling more precise patient phenotyping for recruitment and large-scale observational studies [22](https://arxiv.org/pdf/2507.17009v1). However, challenges remain, including conflation errors between similar concepts and lower performance on rare labels.

The utility of LLMs in data extraction extends to various clinical contexts. Agentic RAG frameworks improve radiology question answering by enabling LLMs to decompose complex questions and iteratively retrieve evidence [23](https://www.semanticscholar.org/paper/0165a739c5318fe754eca9a8274b82c383ca14a3). LLMs are also being evaluated for hierarchical clinical document classification for ICD-10 codes, showing promise as assistants to human coders, though not yet for full automation [24](https://www.semanticscholar.org/paper/567c594b0b34f6bbd3a26d338298f5426035db5c). Studies emphasize that customized prompts are more effective than basic prompting for data extraction in meta-analyses, indicating that optimizing LLM interaction is key [25](https://www.semanticscholar.org/paper/386cffe6471e59afc7c05ff03cc97e282b820c17). Open-source LLMs are demonstrating effectiveness in clinical information extraction in resource-constrained settings and non-English languages [26](https://www.semanticscholar.org/paper/f2bb97e0e1dd74f6b201596295072c50ce289b57), [27](https://www.semanticscholar.org/paper/390d0bc69a4d5a4b64b52434f124dcee477cbc75), [28](https://www.semanticscholar.org/paper/bad7f17c394fdc8fba0c2d97faf6aeded39dba40). Critical to these processes is robust preprocessing, with Sentence Boundary Detection (SBD) proving crucial for improving the quality and interpretability of downstream Natural Language Processing (NLP) tasks in healthcare [29](https://www.semanticscholar.org/paper/7ece401a2ea238c16b1e411e94810c89a95dad8a).

Ensuring the quality and reliability of clinical data is paramount. The Medical Data Pecking Tool (MDPT) offers an automated approach to evaluate EHR data quality by adapting unit testing and coverage principles from software engineering [30](https://arxiv.org/pdf/2507.02628v1). By using LLMs to generate context-sensitive tests, MDPT can identify inconsistencies and potential biases early in the trial process, improving data reliability and supporting more accurate AI models. However, its effectiveness can be limited by reliance on general population benchmarks and the potential for faulty AI-generated tests. For time-series physiological data, common in Intensive Care Units (ICUs), a novel framework quantifies the confidence of imputed data points, enabling "selective imputation" where only highly reliable values are used [31](https://arxiv.org/pdf/2507.09353v1). This prevents error propagation from low-confidence imputations, leading to more trustworthy data for analysis and predictive modeling in trials, though computational cost remains a consideration. The broader context of EHR data quality reveals persistent challenges like granularity and heterogeneous coding schemes, underscoring the need for advanced solutions [32](https://www.semanticscholar.org/paper/10f5262287b571873f23fb3b903d878a69c41d98).

Finally, the generation of high-fidelity synthetic clinical data and text emerges as a critical advancement for privacy preservation, data augmentation, and accelerating corpus building. A systematic review highlights the potential of synthetic clinical text, particularly using transformer architectures, to address data sparsity and privacy concerns in NLP tasks for clinical trials [33](https://arxiv.org/pdf/2507.18451v1). This can significantly reduce the manual effort, time, and legal complexities associated with data preparation and transfer. Synthetic data can also be used to generate longitudinal progress notes, improving narrative coherence across fragmented documentation [34](https://www.semanticscholar.org/paper/79816b9f2643f55c0891291c6299e22f95676aa5). Despite these benefits, challenges persist in ensuring true privacy (re-identification risks), maintaining text quality (misspellings, coherence), and standardizing evaluation metrics [33](https://arxiv.org/pdf/2507.18451v1), [35](https://www.semanticscholar.org/paper/a13e9071351d38d02e8b06ef6491b3010f3eb7a8).

In summary, AI and LLMs are rapidly transforming clinical trial data operations, offering solutions for automated standardization, efficient information extraction, robust quality evaluation, intelligent imputation, and privacy-preserving synthetic data generation. While these technologies promise to accelerate research and reduce costs, their successful integration demands careful consideration of limitations such as potential hallucinations, the need for human validation and oversight, and the ongoing development of reliable evaluation metrics. The "human-in-the-loop" paradigm remains crucial, leveraging AI as a powerful assistant rather than a full replacement, ultimately fostering a more efficient, accurate, and interoperable clinical trial ecosystem.

# Optimizing Clinical Trial Operations and Monitoring through Advanced AI

Clinical trials, the cornerstone of medical advancement, are inherently complex and resource-intensive, often facing challenges related to data silos, patient privacy, and the need for real-time oversight. The integration of artificial intelligence (AI) and machine learning (ML) is rapidly transforming these operations, promising enhanced efficiency, data quality, and patient-centric management. This section explores key AI innovations that address these challenges, from robust privacy-preserving collaboration frameworks to intelligent monitoring and decision support systems.

## Privacy-Preserving Collaboration and Data Utilization

One of the most significant hurdles in multi-center clinical trials is the inability to centralize sensitive patient data due to stringent privacy regulations such as HIPAA and GDPR. Federated Learning (FL) has emerged as a critical paradigm to enable collaborative model training without compromising data sovereignty.

HuSCF-GAN [36](https://arxiv.org/pdf/2507.12979v1) proposes a novel distributed generative AI approach for heterogeneous multi-domain environments. This framework, combining KLD-weighted Clustered Federated Learning and Heterogeneous U-Shaped split learning, enables decentralized training of Generative Adversarial Networks (GANs) across diverse devices and data distributions. Its core contribution lies in allowing the utilization of distributed datasets for tasks like synthetic data generation or training AI diagnostic tools without sharing raw patient data or labels, ensuring privacy while leveraging underutilized computational resources. However, its multi-stage complexity, reliance on an intermediary server, and the current focus on simulations present practical implementation challenges in dynamic clinical settings [36](https://arxiv.org/pdf/2507.12979v1).

Enhancing communication efficiency within FL is paramount, especially when dealing with large medical datasets. Server-side caching strategies, including FIFO, LRU, and Priority-Based methods, can significantly reduce bandwidth usage and improve memory efficiency by selectively transmitting only the most "significant" model updates [37](https://arxiv.org/pdf/2507.17772v1). While effective in reducing communication overhead, the definition of "significance" may require more clinically relevant metrics, and real-world deployment needs to address diverse data modalities and regulatory compliance [37](https://arxiv.org/pdf/2507.17772v1). Similarly, the viscous-retained democracy (FedVRD) protocol aims to minimize data transfer costs by selecting a subset of clients with the most useful model weights at each step, while also enhancing adversarial robustness [38](https://arxiv.org/pdf/2507.02710v1). However, its reliance on theoretical analysis and simulations, alongside potentially higher costs due to an increased number of clients, calls for further empirical validation on real-world clinical datasets [38](https://arxiv.org/pdf/2507.02710v1). Communication efficiency for LLM fine-tuning in FL settings is also addressed by methods like GradualDiff-Fed, which transmits only the difference in model weights, drastically reducing overhead while maintaining performance comparable to centralized training [39](https://www.semanticscholar.org/paper/24810d3c1a76b91a028aa51298fbdb4bf7248efa).

Beyond basic FL, advancements are optimizing LLM and Vision-Language Model (VLM) training for medical applications. CLUES focuses on collaborative high-quality data selection for LLM fine-tuning in privacy-constrained settings. By analyzing the "influence" of individual data points on training dynamics without direct sharing, CLUES can identify and leverage higher-quality data from distributed silos, optimizing LLM fine-tuning for clinical research tasks like predictive modeling or insight generation from medical literature [40](https://arxiv.org/pdf/2507.03004v1). This is crucial given the growing recognition that data quality, not just quantity, is vital for LLM performance [40](https://arxiv.org/pdf/2507.03004v1). Practical applications of FL also include automating ICD code assignment from clinical notes, demonstrating that privacy-preserving model training using pre-trained embeddings and lightweight classifiers can achieve performance comparable to centralized training [41](https://arxiv.org/pdf/2507.03122v1). However, reliance on static embeddings and simplified FL assumptions are noted limitations [41](https://arxiv.org/pdf/2507.03122v1).

Crucially, research indicates that the choice of local training configurations (e.g., optimizer, learning rate) is often more critical for model performance and convergence in FL than the specific FL algorithm itself [42](https://arxiv.org/pdf/2507.19822v1). This shifts the focus toward standardizing and carefully tuning these local parameters across participating sites, potentially simplifying FL adoption in multi-center clinical studies [42](https://arxiv.org/pdf/2507.19822v1). Other advancements in federated learning for large models include FedNano, which centralizes the LLM on the server while deploying lightweight modules on clients, drastically reducing client-side storage and communication overhead [43](https://www.semanticscholar.org/paper/65362ec53e7d7bc2300748856103003c4b4ed7a3). FedMRG similarly employs low-rank factorization for communication-efficient LLM training in medical report generation, tackling multi-modal data heterogeneity with client-aware contrastive learning and dual-adapter mechanisms [44](https://www.semanticscholar.org/paper/01796c8d6c13522fbd15388b91f2a478f18fd05e). Personalized FL frameworks like pFedMMA [45](https://www.semanticscholar.org/paper/c57556bf1b7df4e2c9954273d49357aaddc5ebf3) and pFedDC [46](https://www.semanticscholar.org/paper/d622ddee0cfa614ac84d85b709ab8bd401d8a687) utilize multi-modal adapters and dual-prompt optimization to balance global generalization with local personalization, crucial for diverse patient populations. Moreover, VGS-ATD offers a robust distributed learning framework for multi-label medical image classification, outperforming centralized and federated learning under heterogeneous and imbalanced conditions and demonstrating resilience to catastrophic forgetting during system expansion [47](https://www.semanticscholar.org/paper/37f8dc06249c67a4766d7e0f974c29e50772d1c7).

## Enhancing Real-time Monitoring and Data Acquisition

Beyond data sharing, AI contributes to optimizing how data is collected and interpreted in real-time within clinical trials, moving towards more granular and efficient patient monitoring.

Continuous, objective tracking of disease progression is vital. Semi-supervised models leveraging in-home sensor data can continuously estimate functional decline scores, such as ALSFRS-R for Amyotrophic Lateral Sclerosis (ALS) patients, between clinical visits [48](https://arxiv.org/pdf/2507.09460v1). This provides more granular and objective data than infrequent clinical assessments, potentially enabling more sensitive detection of treatment effects and personalized progression models. However, the current validation is based on a small cohort, and requires larger, multi-center studies for generalizability, alongside enhanced feature engineering to capture nuanced changes [48](https://arxiv.org/pdf/2507.09460v1).

Optimizing data acquisition itself is another key area. The NOCTA (Non-Greedy Objective Cost-Tradeoff Acquisition) framework intelligently selects which features to collect and when in longitudinal studies, explicitly balancing the cost (time, financial, patient burden) against the informativeness of each data point [49](https://arxiv.org/pdf/2507.12412v1). This can lead to more efficient trial designs, reduced resource expenditure, and minimized patient inconvenience. Its Reinforcement Learning (RL)-free approach offers a practical alternative to complex RL methods, but its performance can be sensitive to data quality and sparsity [49](https://arxiv.org/pdf/2507.12412v1).

For interventional trials, AI is enabling real-time adaptive therapies. Temporal Basis Function Models (TBFMs) provide a highly efficient modeling framework for closed-loop neural stimulation, capable of training in minutes and operating with millisecond latency on standard CPUs [50](https://arxiv.org/pdf/2507.15274v1). This efficiency allows for rapid, personalized adaptation of stimulation protocols for individual patients within a trial, potentially accelerating symptom improvement and trial duration. However, the validation was in non-human primates using optogenetic stimulation, requiring further translation and validation with electrical stimulation in human trials, and accounting for neural plasticity [50](https://arxiv.org/pdf/2507.15274v1).

## AI for Enhanced Safety Surveillance and Clinical Decision Support

AI tools are also proving invaluable in expediting safety surveillance and supporting complex clinical decision-making within trial environments, from adverse event detection to streamlining protocol adherence.

In safety surveillance, Natural Language Processing (NLP) combined with Active Learning (AL) can rapidly detect potential vaccine safety issues from Emergency Department (ED) triage notes [51](https://arxiv.org/pdf/2507.18123v1). AL optimizes the data annotation process by iteratively selecting the most informative data points, building classifiers that provide timely and accurate mechanisms for identifying adverse events post-licensure, which may not have been apparent during initial clinical trials [51](https://arxiv.org/pdf/2507.18123v1). A limitation is the reliance on vaccine-related keywords, potentially missing signals not explicitly linked in notes, and generalizability across jurisdictions [51](https://arxiv.org/pdf/2507.18123v1).

For dynamic patient monitoring, DeltaSHAP offers a novel explainable AI (XAI) algorithm providing real-time, *directional* explanations for evolving patient risk predictions [52](https://arxiv.org/pdf/2507.02342v2). This allows clinicians to understand not just that a patient's risk is changing, but *why* specific physiological parameters are driving that change, enabling more timely and targeted interventions. Its efficiency supports integration into real-time clinical workflows, but it might overlook delayed effects from earlier observations [52](https://arxiv.org/pdf/2507.02342v2).

Large Language Models (LLMs) are central to new decision support systems. The ALIGN framework focuses on personalizing LLMs for decision-making tasks, such as medical triage, by dynamically aligning them to fine-grained attributes through prompt-based methods [53](https://arxiv.org/pdf/2507.09037v1). This allows LLM-based systems to adhere to specific trial protocols, patient preferences, or ethical guidelines, enhancing reliability and responsibility. However, the current framework assumes fixed choices and attributes, and requires linking alignment to concrete clinical outcomes [53](https://arxiv.org/pdf/2507.09037v1). Complementing this, WARPP (Workflow Adherence via Runtime Parallel Personalization) enables LLMs to better adhere to complex, conditional workflows by dynamically tailoring execution paths based on user attributes [54](https://arxiv.org/pdf/2507.19543v1). This could streamline patient recruitment, improve data collection by ensuring protocol adherence, and facilitate more efficient trial management through modular, multi-agent approaches [54](https://arxiv.org/pdf/2507.19543v1). While promising, WARPP was evaluated on synthetic datasets, and its application to highly sensitive clinical data requires stringent privacy and security considerations [54](https://arxiv.org/pdf/2507.19543v1).

To further augment expert decision-making, AInsight provides on-the-fly, contextually relevant insights derived from historical data during conversations through a conversational retrieval-augmented generation (RAG) interface [55](https://arxiv.org/pdf/2507.09100v1). This can provide real-time, evidence-based suggestions to clinical investigators, aiding in protocol adherence, symptom interpretation, and regulatory guidance, fostering transparency and trust. Its effectiveness relies heavily on the quality of the underlying knowledge base, and potential processing latency could impact real-time integration into workflows [55](https://arxiv.org/pdf/2507.09100v1). Building on interactive decision-making, DynamiCare introduces a dynamic multi-agent framework that simulates the iterative nature of clinical diagnosis using structured EHR data [56](https://arxiv.org/pdf/2507.02616v1). This provides a robust platform for developing and benchmarking LLM-powered diagnostic agents and simulating complex patient scenarios, which is critical for validating AI tools in trial participant selection or treatment [56](https://arxiv.org/pdf/2507.02616v1). However, it currently relies only on textual and tabular data, and is intended for research rather than direct clinical deployment due to LLM inaccuracies [56](https://arxiv.org/pdf/2507.02616v1).

AI is also streamlining early trial phases, such as cohort identification. GDC Cohort Copilot is an AI-powered tool that translates natural language descriptions into complex genomic data filters for the Genomic Data Commons (GDC) [57](https://arxiv.org/pdf/2507.02221v2). This significantly improves and automates patient cohort identification for trials requiring specific genomic profiles, bypassing the need for intricate knowledge of the GDC's filtering system. Notably, a locally-served open-source LLM outperformed GPT-4o for this task, suggesting cost-effective and accurate specialized data curation [57](https://arxiv.org/pdf/2507.02221v2). Optimizing the selection and allocation of data sources for domain-specific model specialization, especially for LLMs, is further informed by the establishment of "scaling laws" for data utility, enabling more robust and cost-effective resource allocation decisions in developing clinical AI models [58](https://arxiv.org/pdf/2507.22250v1).

Broader LLM applications for clinical data include Med-PRM, a process reward modeling framework leveraging RAG to verify each reasoning step against medical knowledge bases, improving accuracy and explainability in medical QA [59](https://www.semanticscholar.org/paper/1585c43b9c584854bcb42ce4e56416c6b3bc54f3). ControlMed enables users to control the length of LLM reasoning at inference time, balancing accuracy and computational efficiency for clinical question answering [60](https://www.semanticscholar.org/paper/419d07fa94d16a3bd9383bd9b2c604fc0cbfbdb7). CKD-EHR improves chronic kidney disease (CKD) risk prediction from EHRs through knowledge distillation from a fine-tuned LLM to a lightweight student model, achieving significant inference speedup [61](https://www.semanticscholar.org/paper/ac5402b001e844915775d70b01ef14396ac548db). The development of models like TALE-EHR, which uses a time-aware attention mechanism and LLM-derived embeddings to model EHRs for disease progression forecasting, highlights the importance of explicit temporal modeling for EHR analysis [62](https://www.semanticscholar.org/paper/07efe241f0727684c31c670f015381427bab9916). Furthermore, the evolution of medical VLMs (like those discussed in [63](https://www.semanticscholar.org/paper/b21a2cdc6e9a841d7432b19d57ea8b9164f8f0e4) and [64](https://www.semanticscholar.org/paper/cf89861099246564046ea5c253ff16be00688b88)) and the use of models that fuse time series and natural language data [65](https://www.semanticscholar.org/paper/aad4507629c335db7166857d622cdf331eb4abd3) further demonstrate the depth of multi-modal AI in healthcare.

Efficiency gains also extend to model deployment. Quantization techniques, such as those leveraging Microsoft Olive and Intel Neural Compressor, can achieve significant speed-ups (20x) and memory reductions (70%) for AI models in biomedical ontology alignment, crucial for handling vast and complex clinical research datasets [66](https://arxiv.org/pdf/2507.13742v1). In medical imaging, TANGERINE, a computationally frugal open-source foundation model for low-dose CT scans, achieves state-of-the-art performance for thoracic disease classification with high label efficiency and rapid fine-tuning [67](https://arxiv.org/pdf/2507.01881v2). This addresses radiologist shortages and enables comprehensive respiratory disease management, potentially enriching patient cohorts for preclinical respiratory condition trials [67](https://arxiv.org/pdf/2507.01881v2). Approaches that optimize antibody sequences for favorable developability using guided discrete diffusion models [68](https://arxiv.org/pdf/2507.02670v1) are also critical, streamlining the design of therapeutic antibodies for clinical trials, potentially reducing development costs and improving patient outcomes. Finally, compact LLMs fine-tuned for on-device medical transcription and note generation [69](https://www.semanticscholar.org/paper/85d312f93363144da7d92650abaa55d4f4aca252) highlight a practical path towards privacy-preserving, cost-effective AI in clinical documentation.

## Conclusion and Future Directions

The integration of advanced AI and ML techniques is fundamentally reshaping clinical trial operations and monitoring. From privacy-preserving federated learning that unlocks distributed patient data for collaborative model training, to sophisticated real-time monitoring with sensor-based systems and cost-optimized data acquisition, AI is enhancing efficiency and data quality. Furthermore, LLM-powered tools are revolutionizing safety surveillance, providing explainable decision support, and streamlining complex workflows like patient cohort identification and protocol adherence. These advancements promise more agile, patient-centric, and data-driven clinical trials, accelerating the translation of research into clinical practice.

Despite significant progress, challenges remain. These include ensuring the generalizability of models across diverse patient populations and healthcare systems, addressing regulatory and ethical considerations for AI deployment, and seamlessly integrating these advanced tools into existing clinical workflows. Future work will focus on robust empirical validation in real-world settings, developing more sophisticated mechanisms for handling data heterogeneity and noise, and creating AI systems that are inherently interpretable and trustworthy for clinicians and patients alike. Continued research and interdisciplinary collaboration will be key to fully realizing the transformative potential of AI in optimizing clinical trial management and ultimately improving patient outcomes.

# Advanced Analytics and Ethical Considerations for Trial Outcomes

The landscape of clinical trials is being profoundly reshaped by advanced analytical methodologies, which aim to extract deeper, more reliable, and ethically sound insights from complex patient data, often integrating real-world evidence (RWE). Innovations span areas from ensuring fairness in prognostic models to developing robust causal inference techniques and highly interpretable AI tools, all critical for optimizing trial design, patient stratification, and outcome assessment.

## Enhancing Fairness and Mitigating Algorithmic Bias in Prognosis

A critical challenge in clinical trial analysis is ensuring that predictive models are fair and accurate across diverse patient subgroups, preventing biases that could disproportionately affect certain populations. Traditional survival models, often calibrated only at the population level, risk poor performance for minority subpopulations. To address this, `Suttaket and Kok` introduce **GRADUATE**, a novel model that achieves *multicalibration* by ensuring that predicted probabilities are close to ground-truth probabilities across all defined subpopulations [70](https://arxiv.org/pdf/2507.02807v1). This is achieved by framing multicalibration as a constrained optimization problem, balancing calibration and discrimination during training. By offering more trustworthy predictions for individual patients and subgroups, GRADUATE can lead to more equitable trial analysis and robust prognostic modeling, supporting fair evaluation of treatment effects and informed clinical decisions. However, its practical application hinges on the explicit and clinically relevant definition of subpopulations, requiring sufficient data for each, and involves significant computational overhead and intricate hyperparameter tuning, which could hinder real-time application in dynamic trial management [70](https://arxiv.org/pdf/2507.02807v1).

The pursuit of fairness extends to auditing AI systems for embedded human biases. `Sariola et al.` investigate how "label bias"—discriminatory human decisions inherent in training data—can create an "illusion of fairness" in AI, even when common debiasing interventions are applied [71](https://arxiv.org/pdf/2507.02152v1). Their methodology, leveraging rigorously designed "audit studies" (analogous to controlled experiments in clinical settings) and Individual Treatment Effect (ITE) estimation, provides a pathway to more accurately assess and reduce algorithmic discrimination. This approach is vital for ensuring that AI systems used in patient recruitment, risk stratification, or outcome prediction within clinical trials are genuinely fair, mitigating the impact of historical biases that might otherwise affect patient selection or treatment interpretation [71](https://arxiv.org/pdf/2507.02152v1). Practical application might face challenges due to the complexity of ITE, and the findings' generalizability to different protected attributes and the medical domain requires further validation given its initial focus on age discrimination in hiring [71](https://arxiv.org/pdf/2507.02152v1). Complementing this, FAME (Fairness-Aware Multimodal Embeddings) explicitly weights different data modalities (text, images, codes) to optimize both prediction performance and fairness across patient subgroups in Electronic Health Record (EHR) data, highlighting the importance of balancing these objectives in real-world clinical applications [72](https://www.semanticscholar.org/paper/295587304675a340f9e214db4cd917e50aa1df50).

## Robust Causal Inference and Policy Evaluation

Establishing robust causal relationships and evaluating treatment policies from real-world data are central to advancing clinical evidence. `Bormpoudakis et al.` propose a novel approach for causal inference by using Positive-Unlabeled (PU) learning to construct control groups in observational studies [73](https://arxiv.org/pdf/2507.14528v1). This is particularly relevant when a traditional control arm is unavailable or unethical, such as in analyses of real-world evidence from EHRs. By identifying likely non-treated units from unlabeled data based on known treated units, this method can more reliably estimate treatment effects, optimizing the identification of comparable groups for valid observational studies. However, the method relies on PU learning assumptions like 'Separability' and 'Smoothness', and its effectiveness is sensitive to the quality and quantity of available treated units, potentially requiring data trimming that limits generalizability to the entire population [73](https://arxiv.org/pdf/2507.14528v1).

For developing and evaluating treatment strategies, `Matsson et al.` introduce a pragmatic framework for deriving interpretable treatment policies from observational data using behavior cloning with tree-based models [74](https://arxiv.org/pdf/2507.17056v1). This approach prioritizes interpretability and reliable off-policy evaluation (OPE), addressing key limitations of traditional offline reinforcement learning (RL) in safety-critical domains like healthcare. By learning from frequently chosen actions, the framework captures collective clinical judgment, offering transparent decision-making pathways. While effective, the method's reliance solely on importance sampling for OPE and the potential for unmeasured confounding variables to bias estimates are key limitations [74](https://arxiv.org/pdf/2507.17056v1). Building on OPE, `Mandyam et al.` propose PERRY, which significantly enhances robust policy evaluation by providing statistically valid confidence intervals for estimates derived from historical and synthetically augmented data [75](https://arxiv.org/pdf/2507.20068v1). This is crucial for quantifying uncertainty in high-stakes healthcare decisions, enabling more informed choices about adopting or modifying treatment strategies. The accuracy of these estimates critically depends on the quality of the generative models used for data augmentation, and specific assumptions (e.g., Lipschitz continuity) may not always hold in complex clinical dynamics [75](https://arxiv.org/pdf/2507.20068v1).

The theoretical underpinnings of applying RL to clinical trials are further detailed by `Chi et al.`, emphasizing sample efficiency and theoretical guarantees for various RL algorithms, including offline, online, and robust RL [76](https://arxiv.org/pdf/2507.14444v1). This tutorial provides a foundation for optimizing trial efficiency and personalizing treatment strategies, though it acknowledges the significant gap between idealized theoretical assumptions and the practical complexities of real-world clinical data, particularly concerning safety and interpretability [76](https://arxiv.org/pdf/2507.14444v1). Effective modeling of EHRs, which are central to these approaches, requires addressing data heterogeneity and complex temporal patterns, as highlighted by frameworks like TALE-EHR, which uses a time-aware attention mechanism to capture fine-grained sequence dynamics [62](https://www.semanticscholar.org/paper/07efe241f0727684c31c670f015381427bab9916), building upon the vast resources of datasets like MIMIC [32](https://www.semanticscholar.org/paper/10f5262287b571873f23fb3b903d878a69c41d98).

## Advanced Prognostic Modeling and Biomarker Discovery

AI is also advancing prognostic modeling beyond traditional methods, integrating diverse data types to identify subtle indicators of disease progression and treatment response. `Deng et al.` introduce QuEst, a principled framework that enhances the estimation of quantile-based distributional measures by combining scarce, high-fidelity clinical trial data with abundant, machine learning-imputed data [77](https://arxiv.org/pdf/2507.05220v1). This allows for the estimation of complex measures like tail risks or specific population segments, providing a more nuanced understanding of efficacy and safety profiles. QuEst offers rigorous confidence intervals and can optimize for reduced variance, potentially leading to more precise conclusions with fewer participants [77](https://arxiv.org/pdf/2507.05220v1). However, its performance is highly dependent on the accuracy and representativeness of the imputation model, and its advanced features can introduce significant computational complexity [77](https://arxiv.org/pdf/2507.05220v1).

For proactive risk identification, `Hu et al.` propose a novel language model and sliding window technique to predict serious adverse event (SAE) outcomes solely from pre-trial registrations [78](https://arxiv.org/pdf/2507.22919v1). This capability could refine trial protocols, inform control group selection, and enable regulatory bodies to flag trials for closer monitoring, thereby enhancing participant safety and potentially reducing early terminations. While promising, the prediction accuracy for the *proportion* of SAEs may not yet be sufficient for direct real-world application, and the method's interpretability is a noted limitation [78](https://arxiv.org/pdf/2507.22919v1).

In precision medicine, integrating multi-omics data for patient stratification and outcome prediction is crucial. `Ramos et al.` introduce BioNeuralNet, a Python framework leveraging Graph Neural Networks (GNNs) to learn low-dimensional representations from multi-omics networks [79](https://arxiv.org/pdf/2507.20440v1). These embeddings can be used for downstream tasks like disease prediction and biomarker discovery, optimizing patient selection and treatment response assessment in clinical trials. Limitations include reliance on high-quality network construction, substantial computational resources for large datasets, and the inherent challenge of interpreting GNN embeddings [79](https://arxiv.org/pdf/2507.20440v1). Building on multimodal data, `Liu et al.` propose methods to improve the generalization of multimodal survival prediction models across different cancer types, which is critical for developing broadly applicable prognostic tools [80](https://arxiv.org/pdf/2507.08340v1). Their SDIR and CADE modules aim to balance feature quality across modalities and synthesize target domain distributions, addressing the often-observed poorer generalization of multimodal models compared to unimodal ones in cross-cancer scenarios. However, the fixed-parameter sparsity mask of SDIR and the Gaussian distribution assumption of CADE may limit their adaptability to highly heterogeneous clinical data [80](https://arxiv.org/pdf/2507.08340v1).

Furthermore, `Wang et al.` propose an operator learning framework for personalized Alzheimer's disease (AD) progression modeling based on patient-specific biomarker dynamics [81](https://arxiv.org/pdf/2507.16148v1). By learning disease operators, this "digital twin" paradigm enables individualized predictions and in silico simulations of therapeutic interventions, potentially optimizing trial design and patient stratification for neurodegenerative diseases. This approach, while powerful, requires comprehensive, longitudinal multimodal data and extensive validation for generalizability across diverse patient populations [81](https://arxiv.org/pdf/2507.16148v1). In line with this, OmniBrain integrates various brain data modalities (Magnetic Resonance Imaging (MRI), radiomics, genes, clinical) for robust AD classification, achieving high accuracy and generalizability while offering explainability [82](https://www.semanticscholar.org/paper/eefbcca0602551219be77550c7b93768ee2777dc). `Perkonigg et al.` demonstrate how unsupervised machine learning on liver MRI can create a "tissue vocabulary" to quantify treatment response in diffuse liver diseases like non-alcoholic steatohepatitis (NASH) [83](https://arxiv.org/pdf/2507.12012v1). This offers potential for non-invasive biomarkers, enhanced treatment stratification, and deeper insights into disease mechanisms, though it relies on biopsy data for training and requires careful handling of scanner variability [83](https://arxiv.org/pdf/2507.12012v1). The broader field is seeing advancements in benchmarking foundation models for prognosis prediction in medical imaging [84](https://www.semanticscholar.org/paper/7f82fda3dddec7c5a9b317cbe0eed1aaa190d30b) and time series prediction for cardiovascular health monitoring [85](https://www.semanticscholar.org/paper/95b1e763a2a0020ba4ec6b1fe3f8b2e0a65e761b).

## Interpretability and Trustworthy AI

The complexity of advanced AI models necessitates explainability to foster clinician trust and facilitate regulatory acceptance in clinical trials. Beyond auditing for bias [71](https://arxiv.org/pdf/2507.02152v1) and developing interpretable policies [74](https://arxiv.org/pdf/2507.17056v1), research is exploring how to generate actionable explanations. `Barua Soumma et al.` leverage Large Language Models (LLMs) to generate highly plausible and valid *counterfactual explanations* (CFs) for AI predictions [86](https://arxiv.org/pdf/2507.05541v1). These CFs can be framed as actionable interventions (e.g., "increase deep sleep to X% to reduce stress"), enhancing patient engagement and providing valuable data augmentation, especially in low-data scenarios common in early-phase trials. A limitation is that LLM-generated CFs might require more substantial changes to alter a prediction compared to traditional methods, potentially impacting the "minimal" aspect of the explanation [86](https://arxiv.org/pdf/2507.05541v1).

Automated diagnostic reporting, particularly for complex medical data, is also benefiting from explainable AI. `Mei et al.` introduce SpiroLLM, a multimodal LLM that interprets spirogram time-series data to generate comprehensive, interpretable diagnostic reports for Chronic Obstructive Pulmonary Disease (COPD) [87](https://arxiv.org/pdf/2507.16145v1). This automates report generation, reduces clinical workload, and provides textual rationales for diagnoses, improving trust. However, its generalizability to diverse populations beyond the UK Biobank and its current limitation to COPD diagnosis are areas for further development [87](https://arxiv.org/pdf/2507.16145v1).

The push for transparent AI is widespread, with frameworks like those using SHAP and LIME gaining traction for explaining predictions in liver disease diagnosis [88](https://www.semanticscholar.org/paper/f7b39ab4a6819e23a56b2a2f34a7a10f73974429) and cardiovascular disease detection [89](https://www.semanticscholar.org/paper/4892ed430fbfd390f9725afac97ad61c1f0d14ed). Deep learning models like FIR-LSTM are being developed for explainable risk prediction of conditions like Iatrogenic Withdrawal Syndrome in Pediatric ICUs, using methods like Layer-wise Relevance Propagation to identify key risk factors [90](https://www.semanticscholar.org/paper/f4f7593f5fcda45eedcd126d50dcf5cd38a00e28). Advances in multimodal EHR modeling are also focusing on hierarchical causal models with conformal calibration for clinical risk prediction [91](https://www.semanticscholar.org/paper/7c89aead45151bcf6d21886008f8de975525a47e) and integrating LLMs for robust medical image segmentation via causal reasoning and interactive error correction [92](https://www.semanticscholar.org/paper/373ed211d5cb958339f5b0778848fe86369f13eb). Furthermore, Large Multimodal Models (LMMs) are being explored for interpretable renal health decline forecasting, aiming for clinically meaningful explanations alongside predictive accuracy [93](https://www.semanticscholar.org/paper/77422e45e687acc493a63344f7310a2ac7e76d93).

## Streamlining Operations and Knowledge Transfer

Beyond direct patient outcomes, AI is also optimizing clinical trial operations and information dissemination. `Hofmann et al.` demonstrate the utility of LLMs for simplifying complex scientific text, directly applicable to making clinical trial protocols, results, and informed consent forms more accessible to patients and non-experts [94](https://arxiv.org/pdf/2507.04414v1). This can improve patient recruitment, adherence, and informed decision-making, though its current focus on short sentences limits immediate translation to full, complex trial documents [94](https://arxiv.org/pdf/2507.04414v1).

The broader application of AI, particularly generative AI and LLMs, is accelerating epidemiological research, which shares commonalities with clinical trial processes. `Bann et al.` highlight how AI can enhance literature reviews, data analysis, and even hypothesis generation, potentially streamlining background research, data processing, and reporting of clinical trial findings [95](https://arxiv.org/pdf/2507.15617v1). However, limitations such as AI hallucinations, data access barriers, and the persistent need for human oversight and critical evaluation remain significant challenges for full automation [95](https://arxiv.org/pdf/2507.15617v1). The ability to integrate diverse data sources, including epidemiological, policy, and weather data, also improves the accuracy of infectious disease forecasting [96](https://arxiv.org/pdf/2507.12966v1), which can optimize resource allocation and adaptive trial designs during outbreaks.

LLMs are increasingly explored for structured numerical data prediction, such as diabetes diagnosis, showing promise especially in few-shot settings, although performance variation across prompting strategies and the need for domain-specific fine-tuning persist [97](https://www.semanticscholar.org/paper/191e20b6d46ef09417f2b9b47f95a66edbe3a09e), [98](https://www.semanticscholar.org/paper/0e34ffa55149d33d0d62007776bcc14fcb15429e). In EHR analysis, knowledge distillation frameworks like CKD-EHR enhance efficiency and accuracy for disease risk prediction [61](https://www.semanticscholar.org/paper/ac5402b001e844915775d70b01ef14396ac548db), while new generative pretraining strategies learn to autoregressively generate clinical events from sequential EHR data, potentially bypassing costly task-specific fine-tuning for forecasting [99](https://www.semanticscholar.org/paper/3e9425a41a0bae97d222ef560c9c8ccec47121b7). The effective integration of multimodal EHR data, including textual clinical notes and numerical lab data, through fusion strategies further improves diagnostic accuracy [100](https://www.semanticscholar.org/paper/c3452af91ab1c3dc1f8b21548d9282f026770887), [101](https://www.semanticscholar.org/paper/4f0bcaef9489b90dfb2b9f1fbd1ae3540b686e4d), [102](https://www.semanticscholar.org/paper/15747039833c70a374d43ec49110321eccd2557e), [65](https://www.semanticscholar.org/paper/aad4507629c335db7166857d622cdf331eb4abd3). Efforts are also underway to synthesize raw, multi-table time-series EHR data to overcome privacy concerns and facilitate data sharing, albeit with rigorous evaluation frameworks needed to ensure fidelity and utility [103](https://www.semanticscholar.org/paper/36201ec9b9c77e7206c57642471ca67495ae6a6d).

## Conclusion

The current wave of advanced analytics is profoundly transforming clinical trials, pushing the boundaries of what is possible in deriving reliable, deep, and ethically sound insights from complex health data. From ensuring fairness in survival predictions and constructing robust control groups to advancing prognostic modeling with multimodal data and enabling personalized digital twins, AI is poised to optimize every stage of the clinical trial lifecycle. Crucially, the simultaneous development of explainable AI tools and frameworks for robust policy evaluation with confidence intervals underscores a strong commitment to trustworthiness and transparency. While challenges remain, particularly in bridging theoretical guarantees with practical deployment, ensuring data quality, and managing computational complexity, these innovations are paving the way for more efficient, equitable, and impactful clinical research and patient care.

# Conclusion

The advancements detailed demonstrate AI's comprehensive transformation of clinical trials, fostering more precise, efficient, and ethical research. Innovations in AI enable granular patient stratification and individualized treatment effect estimation, accelerating the development of targeted therapies. Simultaneously, sophisticated data management solutions leverage Large Language Models for automated standardization, enhanced information extraction, and the creation of high-fidelity synthetic data, thereby improving data integrity and facilitating broader data utilization while addressing privacy concerns. Operational efficiency is significantly enhanced through privacy-preserving federated learning, continuous patient monitoring, and intelligent decision support systems that streamline workflows and bolster safety surveillance. Furthermore, advanced analytical methodologies introduce robust causal inference, ensure fairness in prognostic models, and enhance interpretability, deepening insights derived from complex clinical data. While these breakthroughs promise to accelerate medical progress and improve patient outcomes, challenges persist in ensuring model generalizability across diverse populations, integrating AI tools into existing clinical workflows, and establishing comprehensive ethical guidelines. Continued rigorous validation and human oversight remain critical for translating these innovations into impactful clinical practice.

# References

1. Albert Chiu (2025). *An Algorithm for Identifying Interpretable Subgroups With Elevated Treatment Effects*. ArXiv:2507.09494v1. [https://arxiv.org/pdf/2507.09494v1](https://arxiv.org/pdf/2507.09494v1)
2. Hui Meng, Keping Yang, Xuyu Peng, Bo Zheng (2025). *Deep Disentangled Representation Network for Treatment Effect Estimation*. ArXiv:2507.06650v1. [https://arxiv.org/pdf/2507.06650v1](https://arxiv.org/pdf/2507.06650v1)
3. Yi-Fu Fu, Keng-Te Liao, Shou-De Lin (2025). *Consistent Labeling Across Group Assignments: Variance Reduction in Conditional Average Treatment Effect Estimation*. ArXiv:2507.04332v1. [https://arxiv.org/pdf/2507.04332v1](https://arxiv.org/pdf/2507.04332v1)
4. Rickard Karlsson, Piersilvio De Bartolomeis, Issa J. Dahabreh, Jesse H. Krijthe (2025). *Robust estimation of heterogeneous treatment effects in randomized trials leveraging external data*. ArXiv:2507.03681v1. [https://arxiv.org/pdf/2507.03681v1](https://arxiv.org/pdf/2507.03681v1)
5. Lisa Herzog, Pascal Bühler, Ezequiel de la Rosa, Beate Sick, Susanne Wegener (2025). *Outcome prediction and individualized treatment effect estimation in patients with large vessel occlusion stroke*. ArXiv:2507.03046v1. [https://arxiv.org/pdf/2507.03046v1](https://arxiv.org/pdf/2507.03046v1)
6. Atomsa Gemechu Abdisa, Yingchun Zhou, Yuqi Qiu (2025). *Self Balancing Neural Network: A Novel Method to Estimate Average Treatment Effect*. ArXiv:2507.12818v1. [https://arxiv.org/pdf/2507.12818v1](https://arxiv.org/pdf/2507.12818v1)
7. Yi Li, David Mccoy, Nolan Gunter, Kaitlyn Lee, Alejandro Schuler, Mark van der Laan (2025). *Targeted Deep Architectures: A TMLE-Based Framework for Robust Causal Inference in Neural Networks*. ArXiv:2507.12435v1. [https://arxiv.org/pdf/2507.12435v1](https://arxiv.org/pdf/2507.12435v1)
8. Tijn Jacobs, Wessel N. van Wieringen, Stéphanie L. van der Pas (2025). *Horseshoe Forests for High-Dimensional Causal Survival Analysis*. ArXiv:2507.22004v2. [https://arxiv.org/pdf/2507.22004v2](https://arxiv.org/pdf/2507.22004v2)
9. Yuchen Ma, Dennis Frauen, Jonas Schweisthal, Stefan Feuerriegel (2025). *LLM-Driven Treatment Effect Estimation Under Inference Time Text Confounding*. ArXiv:2507.02843v1. [https://arxiv.org/pdf/2507.02843v1](https://arxiv.org/pdf/2507.02843v1)
10. Julianna Piskorz, Krzysztof Kacprzyk, Harry Amad, Mihaela van der Schaar (2025). *Beyond the ATE: Interpretable Modelling of Treatment Effects over Dose and Time*. ArXiv:2507.07271v2. [https://arxiv.org/pdf/2507.07271v2](https://arxiv.org/pdf/2507.07271v2)
11. Miranda Christ, Daniel Reichman, Jonathan Shafer (2025). *Protocols for Verifying Smooth Strategies in Bandits and Games*. ArXiv:2507.10567v1. [https://arxiv.org/pdf/2507.10567v1](https://arxiv.org/pdf/2507.10567v1)
12. Yile Yu, Anzhi Xu, Yi Wang (2025). *Structural DID with ML: Theory, Simulation, and a Roadmap for Applied Research*. ArXiv:2507.15899v1. [https://arxiv.org/pdf/2507.15899v1](https://arxiv.org/pdf/2507.15899v1)
13. Mark A. Kramer, Aanchal Mathur, Caroline E. Adams, Jason A. Walonoski (2025). *Leveraging Generative AI to Enhance Synthea Module Development*. ArXiv:2507.21123v1. [https://arxiv.org/pdf/2507.21123v1](https://arxiv.org/pdf/2507.21123v1)
14. Eunbyeol Cho, Jiyoun Kim, Minjae Lee, Sungjin Park, Edward Choi (2025). *Generating Multi-Table Time Series EHR from Latent Space with Minimal Preprocessing*. ArXiv:2507.06996v1. [https://arxiv.org/pdf/2507.06996v1](https://arxiv.org/pdf/2507.06996v1)
15. Yiran Dong, Di Fan, Chuanhou Gao (2025). *LILI clustering algorithm: Limit Inferior Leaf Interval Integrated into Causal Forest for Causal Interference*. ArXiv:2507.03271v1. [https://arxiv.org/pdf/2507.03271v1](https://arxiv.org/pdf/2507.03271v1)
16. Alvaro Riquelme, Pedro Costa, Catalina Martinez (2025). *Large Language Models for Automating Clinical Data Standardization: HL7 FHIR Use Case*. ArXiv:2507.03067v1. [https://arxiv.org/pdf/2507.03067v1](https://arxiv.org/pdf/2507.03067v1)
17. Johann Frei, Nils Feldhus, Lisa Raithel, Roland Roller, Alexander Meyer, Frank Kramer (2025). *Infherno: End-to-end Agent-based FHIR Resource Synthesis from Free-form Clinical Notes*. ArXiv:2507.12261v1. [https://arxiv.org/pdf/2507.12261v1](https://arxiv.org/pdf/2507.12261v1)
18. Chong Shao, Doug Snyder, Chiran Li, Bowen Gu, Kerry Ngan, Chun-Ting Yang, Jiageng Wu, Richard Wyss, K. J. Lin, Jie Yang (2025). *Scalable Medication Extraction and Discontinuation Identification from Electronic Health Records Using Large Language Models*. ArXiv:10.48550/arXiv.2506.11137. [https://www.semanticscholar.org/paper/129c1a9848d0c784647cbee5d5dec545b41b4543](https://www.semanticscholar.org/paper/129c1a9848d0c784647cbee5d5dec545b41b4543)
19. Natalia Bobkova, L. A. Zanella-Calzada, Anyes Tafoughalt, Raphaël Teboul, François Plesse, Félix Gaschi (2025). *Automatic Posology Structuration : What role for LLMs?*. ArXiv:10.48550/arXiv.2506.19525. [https://www.semanticscholar.org/paper/f7ffe1247a7cb53b3f532a18a91a0feb39dd49de](https://www.semanticscholar.org/paper/f7ffe1247a7cb53b3f532a18a91a0feb39dd49de)
20. Nicholas Botti, Flora Haberkorn, Charlotte Hoopes, Shaun Khan (2025). *Efficacy of AI RAG Tools for Complex Information Extraction and Data Annotation Tasks: A Case Study Using Banks Public Disclosures*. ArXiv:2507.21360v1. [https://arxiv.org/pdf/2507.21360v1](https://arxiv.org/pdf/2507.21360v1)
21. Lee Harris (2025). *Fast and Accurate Contextual Knowledge Extraction Using Cascading Language Model Chains and Candidate Answers*. ArXiv:2507.22921v1. [https://arxiv.org/pdf/2507.22921v1](https://arxiv.org/pdf/2507.22921v1)
22. Ming Huang, Zehan Li, Yan Hu, Wanjing Wang, Andrew Wen, Scott Lane, Salih Selek, Lokesh Shahani, Rodrigo Machado-Vieira, Jair Soares, Hua Xu, Hongfang Liu (2025). *Multi-Label Classification with Generative AI Models in Healthcare: A Case Study of Suicidality and Risk Factors*. ArXiv:2507.17009v1. [https://arxiv.org/pdf/2507.17009v1](https://arxiv.org/pdf/2507.17009v1)
23. Sebastian Wind, Jeta Sopa, Daniel Truhn, Mahshad Lotfinia, Tri-Thien Nguyen, Keno K. Bressem, Lisa Adams, Mirabela Rusu, Harald Kostler, Gerhard Wellein, Andreas Maier, Soroosh Tayebi Arasteh (2025). *Agentic large language models improve retrieval-based radiology question answering*. ArXiv:2508.00743. [https://www.semanticscholar.org/paper/0165a739c5318fe754eca9a8274b82c383ca14a3](https://www.semanticscholar.org/paper/0165a739c5318fe754eca9a8274b82c383ca14a3)
24. Akram Mustafa, Usman Naseem, M. Azghadi (2025). *Evaluating Hierarchical Clinical Document Classification Using Reasoning-Based LLMs*. ArXiv:2507.03001. [https://www.semanticscholar.org/paper/567c594b0b34f6bbd3a26d338298f5426035db5c](https://www.semanticscholar.org/paper/567c594b0b34f6bbd3a26d338298f5426035db5c)
25. Lingbo Li, A. Mathrani, Teo Sušnjak (2025). *What Level of Automation is"Good Enough"? A Benchmark of Large Language Models for Meta-Analysis Data Extraction*. ArXiv:2507.15152. [https://www.semanticscholar.org/paper/386cffe6471e59afc7c05ff03cc97e282b820c17](https://www.semanticscholar.org/paper/386cffe6471e59afc7c05ff03cc97e282b820c17)
26. Luc Builtjes, J. Bosma, M. Prokop, B. V. Ginneken, A. Hering (2025). *Leveraging Open-Source Large Language Models for Clinical Information Extraction in Resource-Constrained Settings*. ArXiv:2507.20859. [https://www.semanticscholar.org/paper/f2bb97e0e1dd74f6b201596295072c50ce289b57](https://www.semanticscholar.org/paper/f2bb97e0e1dd74f6b201596295072c50ce289b57)
27. Adrien Bazoge, Pacome Constant dit Beaufils, Mohammed Hmitouch, Romain Bourcier, Emmanuel Morin, Richard Dufour, B. Daille, P.A. Gourraud, Matilde Karakachoff (2025). *Improving Social Determinants of Health Documentation in French EHRs Using Large Language Models*. ArXiv:2507.03433. [https://www.semanticscholar.org/paper/390d0bc69a4d5a4b64b52434f124dcee477cbc75](https://www.semanticscholar.org/paper/390d0bc69a4d5a4b64b52434f124dcee477cbc75)
28. A. F. Giraldo-Forero, María C. Durango, S. Rúa, E. A. Torres-Silva, Sara Arango-Valencia, J. Florez-Arango, Andrés Orozco-Duque (2025). *Towards Early Maternal Morbidity Risk Identification by Concept Extraction from Clinical Notes in Spanish Using Fine-Tuned Transformer-Based Models*. ArXiv:10.3390/asi8030078. [https://www.semanticscholar.org/paper/bad7f17c394fdc8fba0c2d97faf6aeded39dba40](https://www.semanticscholar.org/paper/bad7f17c394fdc8fba0c2d97faf6aeded39dba40)
29. Livia Lilli, S. Patarnello, N. Capocchiano, C. Masciocchi, Mario Santoro (2025). *Improving Clinical Report Classification with Sentence Boundary Detection*. ArXiv:10.1109/ICHI64645.2025.00030. [https://www.semanticscholar.org/paper/7ece401a2ea238c16b1e411e94810c89a95dad8a](https://www.semanticscholar.org/paper/7ece401a2ea238c16b1e411e94810c89a95dad8a)
30. Irena Girshovitz, Atai Ambus, Moni Shahar, Ran Gilad-Bachrach (2025). *Medical Data Pecking: A Context-Aware Approach for Automated Quality Evaluation of Structured Medical Data*. ArXiv:2507.02628v1. [https://arxiv.org/pdf/2507.02628v1](https://arxiv.org/pdf/2507.02628v1)
31. Addison Weatherhead, Anna Goldenberg (2025). *Impute With Confidence: A Framework for Uncertainty Aware Multivariate Time Series Imputation*. ArXiv:2507.09353v1. [https://arxiv.org/pdf/2507.09353v1](https://arxiv.org/pdf/2507.09353v1)
32. Afifa Khaled, Mohammed Sabir, Rizwan Qureshi, Maria Caruso, V. Guarrasi, Suncheng Xiang, Kevin Zhou (2025). *Leveraging MIMIC Datasets for Better Digital Health: A Review on Open Problems, Progress Highlights, and Future Promises*. ArXiv:10.48550/arXiv.2506.12808. [https://www.semanticscholar.org/paper/10f5262287b571873f23fb3b903d878a69c41d98](https://www.semanticscholar.org/paper/10f5262287b571873f23fb3b903d878a69c41d98)
33. Basel Alshaikhdeeb, Ahmed Abdelmonem Hemedan, Soumyabrata Ghosh, Irina Balaur, Venkata Satagopam (2025). *Generation of Synthetic Clinical Text: A Systematic Review*. ArXiv:2507.18451v1. [https://arxiv.org/pdf/2507.18451v1](https://arxiv.org/pdf/2507.18451v1)
34. Garapati Keerthana, Manik Gupta (2025). *DENSE: Longitudinal Progress Note Generation with Temporal Modeling of Heterogeneous Clinical Notes Across Hospital Visits*. ArXiv:2507.14079. [https://www.semanticscholar.org/paper/79816b9f2643f55c0891291c6299e22f95676aa5](https://www.semanticscholar.org/paper/79816b9f2643f55c0891291c6299e22f95676aa5)
35. Hanshu Rao, Weisi Liu, Haohan Wang, I-Chan Huang, Zhe He, Xiaolei Huang (2025). *A Scoping Review of Synthetic Data Generation for Biomedical Research and Applications*. ArXiv:10.48550/arXiv.2506.16594. [https://www.semanticscholar.org/paper/a13e9071351d38d02e8b06ef6491b3010f3eb7a8](https://www.semanticscholar.org/paper/a13e9071351d38d02e8b06ef6491b3010f3eb7a8)
36. Youssef Tawfilis, Hossam Amer, Minar El-Aasser, Tallal Elshabrawy (2025). *A Distributed Generative AI Approach for Heterogeneous Multi-Domain Environments under Data Sharing constraints*. ArXiv:2507.12979v1. [https://arxiv.org/pdf/2507.12979v1](https://arxiv.org/pdf/2507.12979v1)
37. Ahmad Alhonainy, Praveen Rao (2025). *Caching Techniques for Reducing the Communication Cost of Federated Learning in IoT Environments*. ArXiv:2507.17772v1. [https://arxiv.org/pdf/2507.17772v1](https://arxiv.org/pdf/2507.17772v1)
38. Aditya Vema Reddy Kesari, Krishna Reddy Kesari (2025). *Fluid Democracy in Federated Data Aggregation*. ArXiv:2507.02710v1. [https://arxiv.org/pdf/2507.02710v1](https://arxiv.org/pdf/2507.02710v1)
39. Amir Faiyaz, Tara Salman (2025). *GradualDiff-Fed: A Federated Learning Specialized Framework for Large Language Model*. ArXiv:10.48550/arXiv.2506.19164. [https://www.semanticscholar.org/paper/24810d3c1a76b91a028aa51298fbdb4bf7248efa](https://www.semanticscholar.org/paper/24810d3c1a76b91a028aa51298fbdb4bf7248efa)
40. Wanru Zhao, Hongxiang Fan, Shell Xu Hu, Wangchunshu Zhou, Bofan Chen, Nicholas D. Lane (2025). *CLUES: Collaborative High-Quality Data Selection for LLMs via Training Dynamics*. ArXiv:2507.03004v1. [https://arxiv.org/pdf/2507.03004v1](https://arxiv.org/pdf/2507.03004v1)
41. Binbin Xu, Gérard Dray (2025). *Federated Learning for ICD Classification with Lightweight Models and Pretrained Embeddings*. ArXiv:2507.03122v1. [https://arxiv.org/pdf/2507.03122v1](https://arxiv.org/pdf/2507.03122v1)
42. Youngjoon Lee, Hyukjoon Lee, Jinu Gong, Yang Cao, Joonhyuk Kang (2025). *Debunking Optimization Myths in Federated Learning for Medical Image Classification*. ArXiv:2507.19822v1. [https://arxiv.org/pdf/2507.19822v1](https://arxiv.org/pdf/2507.19822v1)
43. Yao Zhang, Hewei Gao, Haokun Chen, Weiguo Li, Yunpu Ma, Volker Tresp (2025). *FedNano: Toward Lightweight Federated Tuning for Pretrained Multimodal Large Language Models*. ArXiv:10.48550/arXiv.2506.14824. [https://www.semanticscholar.org/paper/65362ec53e7d7bc2300748856103003c4b4ed7a3](https://www.semanticscholar.org/paper/65362ec53e7d7bc2300748856103003c4b4ed7a3)
44. Haoxuan Che, Haibo Jin, Zhengrui Guo, Yi-Mou Lin, Cheng Jin, Hao Chen (2025). *LLM-driven Medical Report Generation via Communication-efficient Heterogeneous Federated Learning*. ArXiv:10.48550/arXiv.2506.17562. [https://www.semanticscholar.org/paper/01796c8d6c13522fbd15388b91f2a478f18fd05e](https://www.semanticscholar.org/paper/01796c8d6c13522fbd15388b91f2a478f18fd05e)
45. Sajjad Ghiasvand, Mahnoosh Alizadeh, Ramtin Pedarsani (2025). *pFedMMA: Personalized Federated Fine-Tuning with Multi-Modal Adapter for Vision-Language Models*. ArXiv:2507.05394. [https://www.semanticscholar.org/paper/c57556bf1b7df4e2c9954273d49357aaddc5ebf3](https://www.semanticscholar.org/paper/c57556bf1b7df4e2c9954273d49357aaddc5ebf3)
46. Yuguang Zhang, Kuangpu Guo, Zhihe Lu, Yunbo Wang, Jian Liang (2025). *Personalized Federated Learning via Dual-Prompt Optimization and Cross Fusion*. ArXiv:10.48550/arXiv.2506.21144. [https://www.semanticscholar.org/paper/d622ddee0cfa614ac84d85b709ab8bd401d8a687](https://www.semanticscholar.org/paper/d622ddee0cfa614ac84d85b709ab8bd401d8a687)
47. Zehui Zhao, Laith Alzubaidi, Haider A.Alwzwazy, Jinglan Zhang, Yuantong Gu (2025). *VGS-ATD: Robust Distributed Learning for Multi-Label Medical Image Classification Under Heterogeneous and Imbalanced Conditions*. ArXiv:2507.18657. [https://www.semanticscholar.org/paper/37f8dc06249c67a4766d7e0f974c29e50772d1c7](https://www.semanticscholar.org/paper/37f8dc06249c67a4766d7e0f974c29e50772d1c7)
48. Noah Marchal, William E. Janes, Mihail Popescu, Xing Song (2025). *Enhancing ALS Progression Tracking with Semi-Supervised ALSFRS-R Scores Estimated from Ambient Home Health Monitoring*. ArXiv:2507.09460v1. [https://arxiv.org/pdf/2507.09460v1](https://arxiv.org/pdf/2507.09460v1)
49. Dzung Dinh, Boqi Chen, Marc Niethammer, Junier Oliva (2025). *NOCTA: Non-Greedy Objective Cost-Tradeoff Acquisition for Longitudinal Data*. ArXiv:2507.12412v1. [https://arxiv.org/pdf/2507.12412v1](https://arxiv.org/pdf/2507.12412v1)
50. Matthew J. Bryan, Felix Schwock, Azadeh Yazdan-Shahmorad, Rajesh P N Rao (2025). *Temporal Basis Function Models for Closed-Loop Neural Stimulation*. ArXiv:2507.15274v1. [https://arxiv.org/pdf/2507.15274v1](https://arxiv.org/pdf/2507.15274v1)
51. Sedigh Khademi, Christopher Palmer, Muhammad Javed, Hazel Clothier, Jim Buttery, Gerardo Luis Dimaguila, Jim Black (2025). *Actively evaluating and learning the distinctions that matter: Vaccine safety signal detection from emergency triage notes*. ArXiv:2507.18123v1. [https://arxiv.org/pdf/2507.18123v1](https://arxiv.org/pdf/2507.18123v1)
52. Changhun Kim, Yechan Mun, Sangchul Hahn, Eunho Yang (2025). *DeltaSHAP: Explaining Prediction Evolutions in Online Patient Monitoring with Shapley Values*. ArXiv:2507.02342v2. [https://arxiv.org/pdf/2507.02342v2](https://arxiv.org/pdf/2507.02342v2)
53. Bharadwaj Ravichandran, David Joy, Paul Elliott, Brian Hu, Jadie Adams, Christopher Funk, Emily Veenhuis, Anthony Hoogs, Arslan Basharat (2025). *ALIGN: Prompt-based Attribute Alignment for Reliable, Responsible, and Personalized LLM-based Decision-Making*. ArXiv:2507.09037v1. [https://arxiv.org/pdf/2507.09037v1](https://arxiv.org/pdf/2507.09037v1)
54. Maria Emilia Mazzolenis, Ruirui Zhang (2025). *Agent WARPP: Workflow Adherence via Runtime Parallel Personalization*. ArXiv:2507.19543v1. [https://arxiv.org/pdf/2507.19543v1](https://arxiv.org/pdf/2507.19543v1)
55. Mohammad Abolnejadian, Shakiba Amirshahi, Matthew Brehmer, Anamaria Crisan (2025). *AInsight: Augmenting Expert Decision-Making with On-the-Fly Insights Grounded in Historical Data*. ArXiv:2507.09100v1. [https://arxiv.org/pdf/2507.09100v1](https://arxiv.org/pdf/2507.09100v1)
56. Tianqi Shang, Weiqing He, Charles Zheng, Lingyao Li, Li Shen, Bingxin Zhao (2025). *DynamiCare: A Dynamic Multi-Agent Framework for Interactive and Open-Ended Medical Decision-Making*. ArXiv:2507.02616v1. [https://arxiv.org/pdf/2507.02616v1](https://arxiv.org/pdf/2507.02616v1)
57. Steven Song, Anirudh Subramanyam, Zhenyu Zhang, Aarti Venkat, Robert L. Grossman (2025). *GDC Cohort Copilot: An AI Copilot for Curating Cohorts from the Genomic Data Commons*. ArXiv:2507.02221v2. [https://arxiv.org/pdf/2507.02221v2](https://arxiv.org/pdf/2507.02221v2)
58. Oleksiy Ostapenko, Charles Guille-Escuret, Luke Kumar, Max Tian, Denis Kocetkov, Gopeshh Subbaraj, Raymond Li, Joel Lamy-Poirier, Sebastien Paquet, Torsten Scholak (2025). *Using Scaling Laws for Data Source Utility Estimation in Domain-Specific Pre-Training*. ArXiv:2507.22250v1. [https://arxiv.org/pdf/2507.22250v1](https://arxiv.org/pdf/2507.22250v1)
59. Jaehoon Yun, Jiwoong Sohn, Jungwoo Park, Hyunjae Kim, Xiangru Tang, Yanjun Shao, Yonghoe Koo, Minhyeok Ko, Qingyu Chen, Mark Gerstein, Michael Moor, Jaewoo Kang (2025). *Med-PRM: Medical Reasoning Models with Stepwise, Guideline-verified Process Rewards*. ArXiv:10.48550/arXiv.2506.11474. [https://www.semanticscholar.org/paper/1585c43b9c584854bcb42ce4e56416c6b3bc54f3](https://www.semanticscholar.org/paper/1585c43b9c584854bcb42ce4e56416c6b3bc54f3)
60. Sung-Min Lee, Siyoon Lee, Juyeon Kim, Kyungmin Roh (2025). *ControlMed: Adding Reasoning Control to Medical Language Model*. ArXiv:2507.22545. [https://www.semanticscholar.org/paper/419d07fa94d16a3bd9383bd9b2c604fc0cbfbdb7](https://www.semanticscholar.org/paper/419d07fa94d16a3bd9383bd9b2c604fc0cbfbdb7)
61. Junke Wang, Hongshun Ling, Li Zhang, Longqian Zhang, Fang Wang, Yuan Gao, Zhi Li (2025). *CKD-EHR:Clinical Knowledge Distillation for Electronic Health Records*. ArXiv:10.48550/arXiv.2506.15118. [https://www.semanticscholar.org/paper/ac5402b001e844915775d70b01ef14396ac548db](https://www.semanticscholar.org/paper/ac5402b001e844915775d70b01ef14396ac548db)
62. Junhan Yu, Zhunyi Feng, Junwei Lu, Tianxi Cai, Doudou Zhou (2025). *Time-Aware Attention for Enhanced Electronic Health Records Modeling*. ArXiv:2507.14847. [https://www.semanticscholar.org/paper/07efe241f0727684c31c670f015381427bab9916](https://www.semanticscholar.org/paper/07efe241f0727684c31c670f015381427bab9916)
63. Haoneng Lin, Cheng Xu, Jing Qin (2025). *Taming Vision-Language Models for Medical Image Analysis: A Comprehensive Review*. ArXiv:10.48550/arXiv.2506.18378. [https://www.semanticscholar.org/paper/b21a2cdc6e9a841d7432b19d57ea8b9164f8f0e4](https://www.semanticscholar.org/paper/b21a2cdc6e9a841d7432b19d57ea8b9164f8f0e4)
64. Xiao Liang, Di Wang, Zhicheng Jiao, Ronghan Li, Pengfei Yang, Quan Wang, Tat-Seng Chua (2025). *Uncertainty-Driven Expert Control: Enhancing the Reliability of Medical Vision-Language Models*. ArXiv:2507.09209. [https://www.semanticscholar.org/paper/cf89861099246564046ea5c253ff16be00688b88](https://www.semanticscholar.org/paper/cf89861099246564046ea5c253ff16be00688b88)
65. Yilin Wang, Peixuan Lei, Jie Song, Yuzhe Hao, Tao Chen, Yuxuan Zhang, Lei Jia, Yuanxiang Li, Zhongyu Wei (2025). *ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset*. ArXiv:10.48550/arXiv.2506.20093. [https://www.semanticscholar.org/paper/aad4507629c335db7166857d622cdf331eb4abd3](https://www.semanticscholar.org/paper/aad4507629c335db7166857d622cdf331eb4abd3)
66. Oussama Bouaggad, Natalia Grabar (2025). *Search-Optimized Quantization in Biomedical Ontology Alignment*. ArXiv:2507.13742v1. [https://arxiv.org/pdf/2507.13742v1](https://arxiv.org/pdf/2507.13742v1)
67. Niccolò McConnell, Pardeep Vasudev, Daisuke Yamada, Daryl Cheng, Mehran Azimbagirad, John McCabe, Shahab Aslani, Ahmed H. Shahin, Yukun Zhou, The SUMMIT Consortium, Andre Altmann, Yipeng Hu, Paul Taylor, Sam M. Janes, Daniel C. Alexander, Joseph Jacob (2025). *A computationally frugal open-source foundation model for thoracic disease detection in lung cancer screening programs*. ArXiv:2507.01881v2. [https://arxiv.org/pdf/2507.01881v2](https://arxiv.org/pdf/2507.01881v2)
68. Siqi Zhao, Joshua Moller, Porfi Quintero-Cadena, Lood van Niekerk (2025). *Guided Generation for Developable Antibodies*. ArXiv:2507.02670v1. [https://arxiv.org/pdf/2507.02670v1](https://arxiv.org/pdf/2507.02670v1)
69. J. Thomas, A. Mudgal, W. Liu, N. Tahiraj, Z. Mohammed, D. Diddi (2025). *Preserving Privacy, Increasing Accessibility, and Reducing Cost: An On-Device Artificial Intelligence Model for Medical Transcription and Note Generation*. ArXiv:10.1101/2025.07.01.25330679. [https://www.semanticscholar.org/paper/85d312f93363144da7d92650abaa55d4f4aca252](https://www.semanticscholar.org/paper/85d312f93363144da7d92650abaa55d4f4aca252)
70. Thiti Suttaket, Stanley Kok (2025). *In-Training Multicalibrated Survival Analysis for Healthcare via Constrained Optimization*. ArXiv:2507.02807v1. [https://arxiv.org/pdf/2507.02807v1](https://arxiv.org/pdf/2507.02807v1)
71. Disa Sariola, Patrick Button, Aron Culotta, Nicholas Mattei (2025). *The Illusion of Fairness: Auditing Fairness Interventions with Audit Studies*. ArXiv:2507.02152v1. [https://arxiv.org/pdf/2507.02152v1](https://arxiv.org/pdf/2507.02152v1)
72. Nikkie Hooman, Zhongjie Wu, Eric C. Larson, Mehak Gupta (2025). *Equitable Electronic Health Record Prediction with FAME: Fairness-Aware Multimodal Embedding*. ArXiv:10.48550/arXiv.2506.13104. [https://www.semanticscholar.org/paper/295587304675a340f9e214db4cd917e50aa1df50](https://www.semanticscholar.org/paper/295587304675a340f9e214db4cd917e50aa1df50)
73. Ilias Tsoumas, Dimitrios Bormpoudakis, Vasileios Sitokonstantinou, Athanasios Askitopoulos, Andreas Kalogeras, Charalampos Kontoes, Ioannis Athanasiadis (2025). *Positive-Unlabeled Learning for Control Group Construction in Observational Causal Inference*. ArXiv:2507.14528v1. [https://arxiv.org/pdf/2507.14528v1](https://arxiv.org/pdf/2507.14528v1)
74. Anton Matsson, Yaochen Rao, Heather J. Litman, Fredrik D. Johansson (2025). *Pragmatic Policy Development via Interpretable Behavior Cloning*. ArXiv:2507.17056v1. [https://arxiv.org/pdf/2507.17056v1](https://arxiv.org/pdf/2507.17056v1)
75. Aishwarya Mandyam, Jason Meng, Ge Gao, Jiankai Sun, Mac Schwager, Barbara E. Engelhardt, Emma Brunskill (2025). *PERRY: Policy Evaluation with Confidence Intervals using Auxiliary Data*. ArXiv:2507.20068v1. [https://arxiv.org/pdf/2507.20068v1](https://arxiv.org/pdf/2507.20068v1)
76. Yuejie Chi, Yuxin Chen, Yuting Wei (2025). *Statistical and Algorithmic Foundations of Reinforcement Learning*. ArXiv:2507.14444v1. [https://arxiv.org/pdf/2507.14444v1](https://arxiv.org/pdf/2507.14444v1)
77. Zhun Deng, Thomas P Zollo, Benjamin Eyre, Amogh Inamdar, David Madras, Richard Zemel (2025). *QuEst: Enhancing Estimates of Quantile-Based Distributional Measures Using Model Predictions*. ArXiv:2507.05220v1. [https://arxiv.org/pdf/2507.05220v1](https://arxiv.org/pdf/2507.05220v1)
78. Qixuan Hu, Xumou Zhang, Jinman Kim, Florence Bourgeois, Adam G. Dunn (2025). *A novel language model for predicting serious adverse event results in clinical trials from their prospective registrations*. ArXiv:2507.22919v1. [https://arxiv.org/pdf/2507.22919v1](https://arxiv.org/pdf/2507.22919v1)
79. Vicente Ramos, Sundous Hussein, Mohamed Abdel-Hafiz, Arunangshu Sarkar, Weixuan Liu, Katerina J. Kechris, Russell P. Bowler, Leslie Lange, Farnoush Banaei-Kashani (2025). *BioNeuralNet: A Graph Neural Network based Multi-Omics Network Data Analysis Tool*. ArXiv:2507.20440v1. [https://arxiv.org/pdf/2507.20440v1](https://arxiv.org/pdf/2507.20440v1)
80. Jia-Xuan Jiang, Jiashuai Liu, Hongtao Wu, Yifeng Wu, Zhong Wang, Qi Bi, Yefeng Zheng (2025). *Single-Domain Generalization for Multimodal Cross-Cancer Prognosis via Dirac Rebalancer and Distribution Entanglement*. ArXiv:2507.08340v1. [https://arxiv.org/pdf/2507.08340v1](https://arxiv.org/pdf/2507.08340v1)
81. Jindong Wang, Yutong Mao, Xiao Liu, Wenrui Hao (2025). *Learning Patient-Specific Spatial Biomarker Dynamics via Operator Learning for Alzheimer's Disease Progression*. ArXiv:2507.16148v1. [https://arxiv.org/pdf/2507.16148v1](https://arxiv.org/pdf/2507.16148v1)
82. Ahmed Sharshar, Yasser Ashraf, Tameem Bakr, Salma Hassan, Hosam Elgendy, Mohammad Yaqub, Mohsen Guizani (2025). *Not Only Grey Matter: OmniBrain for Robust Multimodal Classification of Alzheimer's Disease*. ArXiv:2507.20872. [https://www.semanticscholar.org/paper/eefbcca0602551219be77550c7b93768ee2777dc](https://www.semanticscholar.org/paper/eefbcca0602551219be77550c7b93768ee2777dc)
83. Matthias Perkonigg, Nina Bastati, Ahmed Ba-Ssalamah, Peter Mesenbrink, Alexander Goehler, Miljen Martic, Xiaofei Zhou, Michael Trauner, Georg Langs (2025). *Identifying Signatures of Image Phenotypes to Track Treatment Response in Liver Disease*. ArXiv:2507.12012v1. [https://arxiv.org/pdf/2507.12012v1](https://arxiv.org/pdf/2507.12012v1)
84. Filippo Ruffini, Elena Mulero Ayllon, LinLin Shen, P. Soda, V. Guarrasi (2025). *Benchmarking Foundation Models and Parameter-Efficient Fine-Tuning for Prognosis Prediction in Medical Imaging*. ArXiv:10.48550/arXiv.2506.18434. [https://www.semanticscholar.org/paper/7f82fda3dddec7c5a9b317cbe0eed1aaa190d30b](https://www.semanticscholar.org/paper/7f82fda3dddec7c5a9b317cbe0eed1aaa190d30b)
85. Congsha Ma, Ming Lei (2025). *Time series prediction for monitoring cardiovascular health in autistic patients*. ArXiv:10.3389/fpsyt.2025.1623986. [https://www.semanticscholar.org/paper/95b1e763a2a0020ba4ec6b1fe3f8b2e0a65e761b](https://www.semanticscholar.org/paper/95b1e763a2a0020ba4ec6b1fe3f8b2e0a65e761b)
86. Shovito Barua Soumma, Asiful Arefeen, Stephanie M. Carpenter, Melanie Hingle, Hassan Ghasemzadeh (2025). *SenseCF: LLM-Prompted Counterfactuals for Intervention and Sensor Data Augmentation*. ArXiv:2507.05541v1. [https://arxiv.org/pdf/2507.05541v1](https://arxiv.org/pdf/2507.05541v1)
87. Shuhao Mei, Yongchao Long, Shan Cao, Xiaobo Han, Shijia Geng, Jinbo Sun, Yuxi Zhou, Shenda Hong (2025). *SpiroLLM: Finetuning Pretrained LLMs to Understand Spirogram Time Series with Clinical Validation in COPD Reporting*. ArXiv:2507.16145v1. [https://arxiv.org/pdf/2507.16145v1](https://arxiv.org/pdf/2507.16145v1)
88. Md Zakir Hossain, Md Munsur Khan, Imran Ahmad, Fahmida Yasmin, Mohammad Sujaur Rahman (2025). *Transparent and Explainable AI for Liver Disease Diagnosis Using SHAP and LIME*. ArXiv:10.1109/ICERA66156.2025.11087306. [https://www.semanticscholar.org/paper/f7b39ab4a6819e23a56b2a2f34a7a10f73974429](https://www.semanticscholar.org/paper/f7b39ab4a6819e23a56b2a2f34a7a10f73974429)
89. Saeed Al Gharib, J. Charafeddine, F. Dornaika, Samir Haddad (2025). *Hybrid Learning Framework for Explainable Cardiovascular Disease Detection*. ArXiv:10.1109/ACCESS.2025.3591241. [https://www.semanticscholar.org/paper/4892ed430fbfd390f9725afac97ad61c1f0d14ed](https://www.semanticscholar.org/paper/4892ed430fbfd390f9725afac97ad61c1f0d14ed)
90. Liqing Zhang, Haoqiu Song, Anita Patel, Murray Pollack, Layne Watson (2025). *FIR-LSTM: An Explainable Deep Learning Framework for Predicting Iatrogenic Withdrawal Syndrome in Pediatric Intensive Care Units*. ArXiv:10.21203/rs.3.rs-6787167/v1. [https://www.semanticscholar.org/paper/f4f7593f5fcda45eedcd126d50dcf5cd38a00e28](https://www.semanticscholar.org/paper/f4f7593f5fcda45eedcd126d50dcf5cd38a00e28)
91. Xin Zhang, Qiyu Wei, Yingjie Zhu, Fanyi Wu, Sophia Ananiadou (2025). *THCM-CAL: Temporal-Hierarchical Causal Modelling with Conformal Calibration for Clinical Risk Prediction*. ArXiv:10.48550/arXiv.2506.17844. [https://www.semanticscholar.org/paper/7c89aead45151bcf6d21886008f8de975525a47e](https://www.semanticscholar.org/paper/7c89aead45151bcf6d21886008f8de975525a47e)
92. Tao Tang, Shijie Xu, Yiting Wu, Zhixiang Lu (2025). *Causal-SAM-LLM: Large Language Models as Causal Reasoners for Robust Medical Segmentation*. ArXiv:2507.03585. [https://www.semanticscholar.org/paper/373ed211d5cb958339f5b0778848fe86369f13eb](https://www.semanticscholar.org/paper/373ed211d5cb958339f5b0778848fe86369f13eb)
93. Peng-Yi Wu, Pei-Cing Huang, Ting-Yu Chen, Chan-Tung Ku, Ming-Yen Lin, Yihuang Kang (2025). *Towards Interpretable Renal Health Decline Forecasting via Multi-LMM Collaborative Reasoning Framework*. ArXiv:2507.22464. [https://www.semanticscholar.org/paper/77422e45e687acc493a63344f7310a2ac7e76d93](https://www.semanticscholar.org/paper/77422e45e687acc493a63344f7310a2ac7e76d93)
94. Nico Hofmann, Julian Dauenhauer, Nils Ole Dietzler, Idehen Daniel Idahor, Christin Katharina Kreutz (2025). *THM@SimpleText 2025 -- Task 1.1: Revisiting Text Simplification based on Complex Terms for Non-Experts*. ArXiv:2507.04414v1. [https://arxiv.org/pdf/2507.04414v1](https://arxiv.org/pdf/2507.04414v1)
95. David Bann, Ed Lowther, Liam Wright, Yevgeniya Kovalchuk (2025). *Why can't Epidemiology be automated (yet)?*. ArXiv:2507.15617v1. [https://arxiv.org/pdf/2507.15617v1](https://arxiv.org/pdf/2507.15617v1)
96. Zacharias Komodromos, Kleanthis Malialis, Panayiotis Kolios (2025). *Investigating Forecasting Models for Pandemic Infections Using Heterogeneous Data Sources: A 2-year Study with COVID-19*. ArXiv:2507.12966v1. [https://arxiv.org/pdf/2507.12966v1](https://arxiv.org/pdf/2507.12966v1)
97. Shadman Sakib, Oishy Fatema Akhand, Ajwad Abrar (2025). *From Chat to Checkup: Can Large Language Models Assist in Diabetes Prediction?*. ArXiv:10.48550/arXiv.2506.14949. [https://www.semanticscholar.org/paper/191e20b6d46ef09417f2b9b47f95a66edbe3a09e](https://www.semanticscholar.org/paper/191e20b6d46ef09417f2b9b47f95a66edbe3a09e)
98. Sophie Kearney, Shu Yang, Zixuan Wen, Bojian Hou, D. Duong-Tran, Tianlong Chen, Jason H. Moore, Marylyn D. Ritchie, Li Shen (2025). *Enabling Few-Shot Alzheimer's Disease Diagnosis on Tabular Biomarker Data with LLMs*. ArXiv:2507.23227. [https://www.semanticscholar.org/paper/0e34ffa55149d33d0d62007776bcc14fcb15429e](https://www.semanticscholar.org/paper/0e34ffa55149d33d0d62007776bcc14fcb15429e)
99. H. Rajamohan, Xiang Gao, Weicheng Zhu, Shih-Lun Huang, Long Chen, K. Cho, Cem M. Deniz, Narges Razavian (2025). *Foundation Models for Clinical Records at Health System Scale*. ArXiv:2507.00574. [https://www.semanticscholar.org/paper/3e9425a41a0bae97d222ef560c9c8ccec47121b7](https://www.semanticscholar.org/paper/3e9425a41a0bae97d222ef560c9c8ccec47121b7)
100. Asma Sadia Khan, Fariba Tasnia Khan, Tanjim Mahmud, Salman Karim Khan, Rishita Chakma, Nahed Sharmen, Mohammad Shahadat Hossain, Karl Andersson (2025). *Prostate Cancer Classification Using Multimodal Feature Fusion and Explainable AI*. ArXiv:2507.20714. [https://www.semanticscholar.org/paper/c3452af91ab1c3dc1f8b21548d9282f026770887](https://www.semanticscholar.org/paper/c3452af91ab1c3dc1f8b21548d9282f026770887)
101. Paul Minchella, L. Verlingue, St'ephane Chr'etien, R'emi Vaucher, Guillaume Metzler (2025). *SigBERT: Combining Narrative Medical Reports and Rough Path Signature Theory for Survival Risk Estimation in Oncology*. ArXiv:2507.22941. [https://www.semanticscholar.org/paper/4f0bcaef9489b90dfb2b9f1fbd1ae3540b686e4d](https://www.semanticscholar.org/paper/4f0bcaef9489b90dfb2b9f1fbd1ae3540b686e4d)
102. Pir Noman Ahmad, Inam Ullah, Nagwa M. Salim, Sushil Kumar Singh, Weiwei Jiang, M. Al-Khasawneh, Y. Daradkeh (2025). *Deep Neural Network-Based Feature Encoding for Automated Health Monitoring Using Large AI Models in Online Communication Systems*. ArXiv:10.1145/3744754. [https://www.semanticscholar.org/paper/15747039833c70a374d43ec49110321eccd2557e](https://www.semanticscholar.org/paper/15747039833c70a374d43ec49110321eccd2557e)
103. Eunbyeol Cho, Jiyoun Kim, M. Lee, Sungjin Park, Edward Choi (2025). *Generating Multi-Table Time Series EHR from Latent Space with Minimal Preprocessing*. ArXiv:2507.06996. [https://www.semanticscholar.org/paper/36201ec9b9c77e7206c57642471ca67495ae6a6d](https://www.semanticscholar.org/paper/36201ec9b9c77e7206c57642471ca67495ae6a6d)