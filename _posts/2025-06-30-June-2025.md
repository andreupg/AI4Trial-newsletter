---
title: June 2025
date: 2025-06-30
categories: [Newsletters]
tags: [AI in Clinical Trials, LLMs, Causal Inference, Predictive Analytics, Healthcare AI]
description: This issue explores how AI is reshaping clinical trials through advancements in protocol design, patient cohort identification, causal inference, intelligent monitoring, and data infrastructure. It highlights the impact of large language models on trial workflows and discusses key challenges like data quality, interpretability, and ethical considerations.
---

# Introduction

The landscape of clinical trials is undergoing a fundamental transformation driven by advancements in artificial intelligence. This exploration details how AI is reshaping critical stages of therapeutic development, from optimizing initial protocol design and refining patient cohort identification to enabling advanced causal inference for robust analysis and implementing intelligent monitoring during ongoing studies. It also delves into innovations in data infrastructure and management, alongside the profound impact of large language models on streamlining diverse trial workflows. The collective aim of these innovations is to accelerate the delivery of safe and effective treatments, enhance precision medicine, improve the generalizability of findings, and address inherent complexities in biomedical research.

# Spotlight: AI's Role in Revolutionizing Clinical Trial Paradigms

Clinical trials, the cornerstone of medical progress, face escalating costs, prolonged timelines, and challenges in ensuring generalizability to diverse patient populations [1](#ref-1). These persistent issues underscore a critical need for innovation to accelerate the delivery of safe and effective treatments. Artificial intelligence (AI) is emerging as a transformative force, promising to fundamentally reshape the clinical trial landscape by enhancing decision-making, improving efficiency, and driving the shift towards personalized medicine. This section outlines the overarching visions and foundational shifts AI introduces, setting the stage for specific applications in subsequent discussions.

### Accelerating and De-risking Development Through Predictive Intelligence

AI offers the potential to significantly streamline the drug and vaccine development lifecycle, optimizing resource allocation and accelerating time-to-market. A collaborative manifesto highlights AI's capacity to improve decision-making, enabling earlier termination of unsafe or ineffective treatments and accelerating the market entry of beneficial medicines [1](#ref-1). In vaccine and immunotherapeutics development, AI and deep learning provide predictive frameworks that support rapid, data-driven decisions, increasing efficiency across the entire process [2](#ref-2). This paradigm shift moves beyond traditional trial-and-error experimentation, integrating computational models and multi-omics data for better disease classification and prediction of immune responses [2](#ref-2). The vision extends to potentially replacing extensive animal preclinical testing with sophisticated computational models, leading to more time- and resource-efficient strategies [2](#ref-2). Such AI-assisted drug development has already demonstrated its ability to drastically reduce candidate identification time from years to months [3](#ref-3), [4](#ref-4), thereby de-risking vaccine and drug programs and improving success rates [5](#ref-5).

### Driving Precision and Personalization in Therapeutic Strategies

A key foundational shift powered by AI is the move towards personalized medicine, tailoring treatments to individual patient characteristics rather than a one-size-fits-all approach [6](#ref-6). AI enables the discovery of novel biomarkers and allows for more refined subgroup analyses, which are crucial for understanding heterogeneous patient responses and optimizing trial design [1](#ref-1). In immunotherapies, AI refines the selection of B- and T-cell antigen/epitope targets, enhancing immune protection and offering deeper insights into immune regulation [2](#ref-2), [7](#ref-7).

The integration of diverse data sources, including genetic and clinical data, imaging, and multi-omics information, is central to this shift [8](#ref-8), [9](#ref-9), [10](#ref-10). AI algorithms analyze these vast datasets to recommend personalized care plans, predict patient outcomes, and optimize treatment strategies across various medical fields, from oncology to orthopaedics [11](#ref-11), [12](#ref-12), [13](#ref-13), [14](#ref-14). This capability allows for a proactive rather than reactive approach to patient care, enhancing clinical efficiency and patient outcomes while potentially mitigating healthcare costs [11](#ref-11).

### Enhancing Generalizability and Real-World Relevance

Traditional randomized controlled trials (RCTs) often exclude a large proportion of real-world patients, limiting the generalizability of their findings [1](#ref-1), [15](#ref-15). AI addresses this by enabling the generalization of trial findings to real-world populations and the creation of "digital twins." Digital twins are computational models designed to simulate individual patient responses, thereby enhancing trial diversity and personalizing treatment plans in silico [1](#ref-1).

Furthermore, AI facilitates the integration of real-world data (RWD) and the generation of synthetic real-world populations, which can complement or even serve as alternatives to traditional RCTs [16](#ref-16), [17](#ref-17). This approach is particularly valuable when real-world data for newly marketed drugs are not yet available, allowing for more robust estimates of real-world effectiveness [16](#ref-16). The integration of RWD and AI also supports modernized regulatory oversight, enabling dynamic trial adaptations and streamlining approval timelines [18](#ref-18). Initiatives are also leveraging AI and digital technologies to decentralize clinical trial infrastructure and improve global accessibility and efficacy, especially in underserved areas [19](#ref-19).

### Navigating the Implementation Frontier: Challenges and Future Directions

While AI presents immense opportunities, its widespread adoption in clinical trials faces significant hurdles. Common limitations include the heavy dependency on high-quality, diverse, and unbiased training data [2](#ref-2), [8](#ref-8), [20](#ref-20). The "black box" problem, where complex AI models lack transparency and interpretability, remains a major concern for regulatory acceptance and trust among clinicians and patients [1](#ref-1), [2](#ref-2), [21](#ref-21), [8](#ref-8), [4](#ref-4).

Regulatory frameworks are often slow to adapt to rapidly evolving AI technologies, necessitating a proactive and productivity-driven approach that incorporates real-world evidence and emerging computational methods [1](#ref-1), [18](#ref-18), [22](#ref-22). Ethical considerations, including algorithmic fairness, data privacy, and accountability for autonomous systems, are paramount and require comprehensive policies and robust governance [1](#ref-1), [2](#ref-2), [3](#ref-3), [23](#ref-23), [4](#ref-4), [24](#ref-24), [20](#ref-20), [25](#ref-25), [26](#ref-26). Furthermore, the significant computational resources and specialized expertise required for implementing advanced AI solutions pose practical challenges, particularly in low-resource settings [2](#ref-2), [27](#ref-27).

Successful integration of AI into clinical trials demands interdisciplinary collaboration among researchers, clinicians, industry leaders, and regulators, alongside the establishment of standardized data frameworks and continuous education [1](#ref-1), [26](#ref-26). By proactively addressing these challenges, AI can fulfill its promise of transforming clinical trials, ultimately leading to more efficient, personalized, and equitable healthcare outcomes.

# Automating and Optimizing Clinical Protocol Design

The efficiency and success of clinical trials are profoundly influenced by their initial design, a complex and resource-intensive process encompassing experimental setup, patient eligibility, and outcome measurement. Artificial intelligence (AI) is increasingly being leveraged to automate and optimize this critical phase, aiming to enhance trial outcomes, reduce costs, and accelerate drug development.

**Advancements in Experimental Design**

Optimizing experimental design involves selecting the most informative interventions to maximize learning while adhering to practical constraints. Bayesian Optimal Experimental Design (BOED) is a powerful paradigm for this purpose, but it often operates under the assumption of a perfectly specified model, which rarely holds true in complex real-world settings like clinical trials. A novel approach addresses this by analyzing generalization error under model misspecification [28](#ref-28). This work introduces the concept of 'error (de-)amplification,' alongside covariate shift, as key contributors to generalization error. To mitigate these effects, a new acquisition function, termed EIG-Adj, is proposed. This function incorporates a Maximum Mean Discrepancy (MMD)-based correction term, which promotes the selection of 'representative' training data—samples that closely reflect the true test distribution—thereby implicitly inducing de-amplification and improving generalization performance even when the underlying model is imperfect [28](#ref-28). The practical challenge lies in the fact that the 'de-amplification' risk is not directly computable as it requires knowledge of the unknown best-fitting approximation of the model, suggesting future work may explore non-parametric models to guide design selection [28](#ref-28).

For combinatorial interventions, where multiple treatments are applied simultaneously, a probabilistic factorial experimental design is introduced. This method allows for the random yet controlled application of treatment combinations, optimizing the study of complex interaction effects in clinical trials by significantly reducing the number of experimental groups needed [29](#ref-29). It adapts dosages across treatments and suggests that an equal dosage is near-optimal for estimating interaction models, thereby making it feasible to study a large number of potential interventions, as seen in drug combination studies [29](#ref-29). Acknowledged limitations include its assumption of a product infection mechanism and the need for extensions to incorporate unit-specific covariates [29](#ref-29).

Further optimizing experimental resource allocation, particularly with multiple candidate treatments, is achieved through adaptive experimental designs (AED). These designs, unlike traditional completely randomized trials (CRTs), can dynamically adjust patient allocation based on accumulating data, leading to superior statistical efficiency [30](#ref-30). For instance, batched arm elimination (BAE) designs can identify the most effective treatment arms more accurately, reducing required sample sizes, accelerating decision-making, and optimizing experimental budgets [30](#ref-30). While beneficial, their theoretical results often assume Gaussian sampling distributions and implementing them requires careful design of batching and elimination rules, adding complexity [30](#ref-30). A multi-metric AED framework further refines this by employing a two-phase structure: an adaptive exploration phase for efficient treatment selection and a validation phase using A/B tests for robust statistical inference, especially valuable when dealing with diverse outcomes and heterogeneous variances. The SHRVar algorithm, based on relative-variance-based sampling and z-value-based elimination, achieves provably low error probabilities and can significantly reduce the number of patients and resources needed for trials [31](#ref-31). However, its primary focus on online experiments suggests that generalization to clinical trials requires careful consideration of the complexities of clinical data and regulatory compliance [31](#ref-31).

**Enhanced A/B Testing and Outcome Prediction**

Advancements in A/B testing methodologies also contribute to optimizing trial design. Off-policy estimators can significantly improve the precision of evaluating intervention effects by exploiting similarities between treatments, thereby reducing the variance of improvement estimates. This allows for achieving the same statistical power with smaller sample sizes, which in turn reduces trial costs and accelerates decision-making for new treatments [32](#ref-32). This approach is most effective when interventions are similar; otherwise, it defaults to standard methods, and its effectiveness with long-term effects needs further adaptation [32](#ref-32). Similarly, a maximum probability-driven two-armed bandit (TAB) process enhances the sensitivity of A/B testing, enabling the detection of even minor average treatment effects. This higher sensitivity allows for more precise value assessments and can lead to reduced sample sizes and shorter experiment durations, contributing to lower overall costs [33](#ref-33). While promising, its direct applicability to the complexities and specific challenges of clinical trials, such as patient heterogeneity and stringent regulatory compliance, requires further adaptation [33](#ref-33).

Automating the prediction of clinical trial outcomes is critical for accelerating drug discovery and reducing R&D costs. The AUTOCT framework integrates Large Language Model (LLM) agents with classical machine learning to autonomously generate, evaluate, and refine tabular features from public data sources like ClinicalTrials.gov and PubMed [34](#ref-34). By using Monte Carlo Tree Search (MCTS) for iterative optimization, AUTOCT provides scalable, transparent, and cost-efficient predictions, mitigating the black-box nature of deep learning and the manual effort of traditional feature engineering [34](#ref-34). Its current reliance on only two data sources and limited exploration of hyperparameter tuning represent areas for further improvement [34](#ref-34).

**Leveraging LLMs for Protocol Generation and Compliance**

The capabilities of LLMs are increasingly being harnessed to enhance various aspects of clinical trial protocol design and execution, particularly in areas requiring complex reasoning and access to vast knowledge bases. Frameworks like RACE-Align improve LLMs by integrating retrieval-augmented generation (RAG) and explicit Chain-of-Thought (CoT) reasoning within a Direct Preference Optimization (DPO) alignment process [35](#ref-35). This approach enhances LLMs' accuracy, domain-specific reasoning, and interpretability, making them highly valuable for developing robust AI assistants for clinical trials [35](#ref-35). Specifically, RACE-Align can fine-tune LLMs to process and synthesize regulatory guidelines and scientific literature for protocol drafting, improve patient-trial matching by providing clear rationales for eligibility, and assist in data analysis by ensuring logically sound and interpretable insights [35](#ref-35). However, its primary validation in the Traditional Chinese Medicine domain implies that direct translation to the highly regulated Western clinical trial context will require significant adaptation and rigorous validation to address domain specificity, data quality, and stringent interpretability standards [35](#ref-35).

Similarly, the RAG+ method enhances LLMs by explicitly incorporating application-aware reasoning, which is crucial for complex tasks like clinical protocol design and patient recruitment [36](#ref-36). By constructing a dual corpus of knowledge and aligned application examples, RAG+ enables LLMs to not only retrieve relevant information but also apply it within structured, goal-oriented reasoning processes [36](#ref-36). This can lead to more efficient protocols and reduced screening failures in patient enrollment. Its modular nature allows for versatile integration into existing workflows, but constructing high-quality application corpora is resource-intensive, and its reliance on LLMs for automated generation may introduce errors [36](#ref-36).

Automating regulatory compliance is another critical area where AI can significantly reduce administrative overhead and accelerate trial initiation. A RAG-based system has been developed to automate standard applicability judgment and cross-jurisdictional reasoning for medical device compliance [37](#ref-37). This system retrieves relevant standards and uses LLMs to infer jurisdiction-specific applicability (e.g., Mandatory, Recommended) with traceable justifications, thereby speeding up pre-market approval processes, minimizing compliance errors, and enhancing transparency for audits [37](#ref-37). However, its effectiveness is highly dependent on the quality and completeness of the regulatory corpus, its generalization is constrained by the scope of the benchmark dataset, and LLM limitations (e.g., hallucinations) necessitate human oversight, particularly given its specific focus on device regulations rather than broader clinical trial protocols [37](#ref-37). These advancements collectively illustrate the transformative potential of AI in streamlining and optimizing the entire clinical protocol design pipeline.

# Advanced Causal Inference for Robust Trial Analysis

Accurately estimating treatment effects is a cornerstone of clinical trials, yet it remains a complex endeavor, particularly when dealing with observational data prone to hidden confounding and high-dimensional complexities. Recent advancements in AI and machine learning are pushing the boundaries of causal inference, offering more robust and unbiased conclusions on treatment efficacy and patient outcomes. This section explores novel methodologies designed to tackle these challenges, from relaxing traditional assumptions to leveraging foundation models and rich, unstructured data.

A fundamental challenge in causal inference is the reliance on strong assumptions such as unconfoundedness (all confounders are observed and accounted for) and overlap (all individuals have a non-zero probability of receiving any treatment). A new framework proposes a general "Identifiability Condition" that characterizes when Average Treatment Effects (ATE) and Average Treatment Effects on the Treated (ATT) can be identified, extending beyond these standard assumptions [38](#ref-38). This condition, rooted in statistical learning theory, provides a unifying perspective, demonstrating that ATE can be identified even in scenarios previously considered intractable, such as Regression Discontinuity Designs or studies with significant violations of overlap [38](#ref-38). This is achieved by ensuring that two different observational studies, if they produce the same observed (censored) distribution, must also yield the same true average treatment effect, or be distinguishable through their covariate distributions or conditional densities [38](#ref-38). This theoretical grounding paves the way for more broadly applicable causal effect estimation in complex observational studies.

The estimation of treatment effects is further complicated by the need to develop and retrain specialized models for each new dataset. Addressing this, CausalFM introduces a novel paradigm using Prior-data Fitted Networks (PFNs) for Bayesian causal inference [39](#ref-39). PFNs are transformer models pre-trained on synthetic data generated from carefully formalized, causality-inspired Bayesian neural network priors based on Structural Causal Models (SCMs) [39](#ref-39). This pre-training allows CausalFM to perform Bayesian inference via "in-context learning" at test time, eliminating the need for retraining on new clinical trial datasets. This flexibility is crucial for real-world application, offering efficient deployment, principled uncertainty quantification, and the ability to automatically adapt to different causal settings (e.g., back-door, front-door, instrumental variable adjustments) based on the data structure [39](#ref-39). Another related work, CausalPFN, also proposes amortized causal effect estimation via in-context learning, achieving superior performance on various ATE/HTE benchmarks [40](#ref-40). This shift towards foundation models for causal inference promises to significantly streamline analysis workflows.

Beyond average effects, understanding the *distribution* of outcomes under counterfactual policies is critical for nuanced clinical decision-making, as it can reveal risks of adverse events or the range of potential efficacy. The Counterfactual Policy Mean Embedding (CPME) framework addresses this by representing the entire counterfactual outcome distribution in a Reproducing Kernel Hilbert Space (RKHS) [41](#ref-41). This nonparametric approach leverages kernel mean embeddings, which map probability distributions to unique elements in an RKHS, thereby preserving all information about the distribution for sufficiently rich kernels [41](#ref-41). CPME introduces both a plug-in and a doubly robust estimator. The doubly robust estimator enjoys improved uniform convergence rates by correcting for bias in both the outcome embedding model and the propensity score model [41](#ref-41). This property ensures consistency if *either* the outcome model or the propensity model is correctly specified, making it more robust to model misspecification than methods relying on only one model. Furthermore, CPME develops a doubly robust kernel test statistic for hypothesis testing, which achieves asymptotic normality, enabling computationally efficient comparisons and confidence interval construction, and even supports sampling from the counterfactual distribution [41](#ref-41). While powerful, CPME's practical application relies on assumptions like selection on observables and strong positivity, and can be sensitive to kernel choice and hyperparameter tuning [41](#ref-41).

A persistent challenge in observational studies for clinical trials is hidden confounding, where unobserved variables bias treatment effect estimates. One innovative solution leverages a small set of outcome-only data from a Randomized Controlled Trial (RCT) to inform Conditional Average Treatment Effect (CATE) estimation from larger observational datasets [42](#ref-42). This method proposes a pseudo-confounder generator and a CATE model that collectively align the learned potential outcomes from observational data with those observed from the unconfounded RCT [42](#ref-42). Specifically, it introduces two balancing techniques: Marginals Balancing (MB) and Projections Balancing (PB). MB uses adversarial training to generate pseudo-confounders and fit a CATE model such that the predicted potential outcomes' distribution from observational data matches the distribution of the true potential outcomes from the RCT data [42](#ref-42). PB aims to ensure that the expectations of the estimated potential outcomes, when transformed by certain functions, align with those from the RCT, providing a unique optimal solution under ideal conditions [42](#ref-42). The combined MB+PB approach aims to reduce the search space for the factual optimization objective, pushing the solution closer to the true conditional potential outcomes [42](#ref-42). This approach is particularly valuable in privacy-sensitive medical applications where full RCT covariate information cannot be shared [42](#ref-42).

Another promising avenue for mitigating hidden confounding involves the use of Large Language Models (LLMs). The ProCI (Progressive Confounder Imputation) framework utilizes LLMs' semantic understanding and world knowledge to iteratively generate, impute, and validate potential confounding variables from both structured and unstructured inputs [43](#ref-43). This capability allows for more accurate assessments of treatment efficacy by identifying and adjusting for biases that might otherwise remain hidden. A "distributional reasoning strategy" is employed to prevent "collapsed outputs," ensuring robust confounder imputation [43](#ref-43). By automating aspects of confounder identification and imputation, ProCI could optimize clinical trial design and analysis, especially when rich textual data is available [43](#ref-43). The effectiveness of LLMs for causal inference is also highlighted by other research that uses them to extract low-dimensional representations from unstructured data for both causal and predictive inference [44](#ref-44), and to address "inference time text confounding" by leveraging LLMs with doubly robust learners [45](#ref-45).

Furthermore, clinical trial data increasingly includes complex, non-tabular modalities such as medical images or free-text clinical notes, which often contain crucial confounding information. A method has been developed to adjust for confounding in such non-tabular data by leveraging latent features extracted from pre-trained neural networks [46](#ref-46). This approach formalizes conditions under which these latent features enable valid adjustment and statistical inference for Average Treatment Effect (ATE) estimation, particularly within the debiased/double machine learning (DML) framework [46](#ref-46). By adapting to the intrinsic sparsity and dimension of the learning problem, neural networks can achieve fast convergence rates even with the high dimensionality and non-identifiability often associated with learned representations [46](#ref-46). This allows for more accurate and less biased ATE estimations, improving conclusions on treatment efficacy. The integration of unstructured data for personalized treatment effect estimation is also explored in other works, which propose plug-in methods and theoretically grounded estimators that leverage structured measurements of confounders during training [47](#ref-47).

In situations where unmeasured confounding is a significant concern and instrumental variables (IVs) are available, a new method called Instrument-Guided Representation Learning (IGRL) offers a solution for high-dimensional and unstructured treatments [48](#ref-48). Unlike traditional approaches that might apply unsupervised dimension reduction (which can introduce omitted variable bias), IGRL explicitly incorporates instrumental variables into the representation learning process [48](#ref-48). This ensures that the learned low-dimensional representation captures the variation in treatment driven by the instrument, thereby preserving the validity of downstream IV analysis and identifying "outcome-improving directions" in the latent space [48](#ref-48). This method is crucial for observational studies or complex treatment designs where traditional IV estimators struggle due to the dimensionality of the treatment. Other related work also explores inference on nonlinear counterfactual functionals under a multiplicative IV model, extending IV methods beyond ATE estimation to identify quantile treatment effects [49](#ref-49). The multiplicative IV model specifically introduces a novel identifying condition based on no multiplicative interaction between the instrument and unmeasured confounder in the treatment model to identify ATT [50](#ref-50). The DML framework can also be powered by Kolmogorov-Arnold Networks (KANs) for distributional IV-LATE estimation, highlighting the profound impact of nuisance function estimator choice on conclusions [51](#ref-51).

Beyond dealing with confounding, optimizing clinical trial design and analysis involves methods for specific randomization schemes and sequential decision-making. For randomized experiments utilizing covariate-adaptive randomization (CAR), such as stratified block randomization, a regression adjustment method enhances the estimation of distributional treatment effects [52](#ref-52). By leveraging off-the-shelf machine learning methods to incorporate additional pre-treatment covariates, this framework improves the precision of estimates and provides a more comprehensive understanding of treatment impact across the entire outcome distribution, rather than just average effects [52](#ref-52). This can reveal heterogeneity in treatment effects, informing personalized strategies and optimizing trial design.

For dynamic treatment regimes (DTRs), which involve sequential, personalized treatment recommendations, two advanced frameworks stand out. SAFER integrates structured Electronic Health Record (EHR) data and clinical notes using a novel transformer-based architecture to provide more reliable and trustworthy DTR modeling [53](#ref-53). A key innovation is the quantification of prediction uncertainty, particularly for deceased patients, using conformal prediction to provide statistical guarantees for safe treatment recommendations [53](#ref-53). This allows clinicians to identify less reliable recommendations and adapt treatment plans, enhancing patient safety and trial efficiency. Similarly, POLAR, a pessimistic model-based policy learning algorithm, optimizes adaptive treatment strategies by addressing limited data coverage and incorporating historical patient information [54](#ref-54). POLAR estimates transition dynamics and quantifies uncertainty for each history-action pair, incorporating a pessimistic penalty into the reward function to discourage actions with high uncertainty [54](#ref-54). This approach, with its statistical and computational guarantees, targets the suboptimality of the learned policy and yields near-optimal, history-aware treatment strategies, crucial for personalized medicine paradigms in longitudinal settings like sepsis treatment [54](#ref-54). These DTR advancements align with broader efforts in policy learning under unobserved confounding, where sensitivity parameters and distributionally robust welfare criteria are used to derive robust policies [55](#ref-55).

In summary, the landscape of causal inference for clinical trials is rapidly evolving with AI-driven solutions. These advancements are moving beyond traditional assumptions, integrating diverse and complex data modalities, and providing robust methods for identifying and mitigating confounding. The focus is increasingly on not just average effects but also on entire outcome distributions, heterogeneous effects, and dynamic, personalized treatment strategies, all while incorporating vital uncertainty quantification and leveraging advanced machine learning paradigms like foundation models and representation learning. These methodological innovations promise to significantly enhance the reliability, efficiency, and safety of clinical trials, ultimately leading to more precise and impactful medical interventions.

# AI for Enhanced Patient Cohort Identification and Stratification

Efficient patient recruitment and precise stratification are paramount for the success of clinical trials, yet these processes frequently face bottlenecks, leading to low accrual rates and prolonged timelines. The inherent heterogeneity of patient populations often complicates the identification of suitable cohorts, impacting trial relevance and the generalizability of findings. Artificial intelligence (AI) is emerging as a transformative force, leveraging advanced data analytics and Large Language Models (LLMs) to revolutionize these critical aspects, ensuring fairness and optimizing trial design.

**AI-Driven Patient Cohort Identification and Matching**

One of the most significant applications of AI in clinical trials is the enhancement of patient-to-trial matching. Traditional matching processes are often trial-specific and manually intensive, leading to significant delays and costs [56](#ref-56). Large Language Models (LLMs) offer a promising solution by acting as knowledge aggregators capable of processing both structured patient data (e.g., diagnoses, lab results) and unstructured clinical notes, alongside complex trial eligibility criteria expressed in natural language [56](#ref-56). This enables LLMs to develop more generalizable matching solutions that can streamline trial design, identify overly restrictive criteria, and facilitate more explainable patient selections. For instance, LLMs can be utilized to infer missing information or identify nuanced patient characteristics that align with complex trial protocols, potentially accelerating recruitment and reducing overall trial costs [56](#ref-56). However, the adoption of LLMs faces challenges including reliance on proprietary models, the need for high-quality annotated datasets, the computational cost of fine-tuning, and issues with non-determinism and the potential for misinformation from unfiltered pre-training data [56](#ref-56). Research efforts are actively addressing these limitations by developing methods to ground LLMs in clinical guidelines to reduce hallucinations and improve temporal analysis of longitudinal EHRs [57](#ref-57). Other work focuses on knowledge distillation from large medical LLMs to more lightweight models, enhancing efficiency for clinical deployment while maintaining diagnostic accuracy [58](#ref-58). Furthermore, new frameworks leverage self-supervised representation learning to build computationally and data-efficient models for categorical EHR data, expanding the utility of LLMs in diverse clinical settings [59](#ref-59). The application of dense passage retrieval (DPR) to cohort retrieval tasks, particularly in unstructured EHR data like echocardiography reports, further demonstrates AI's capacity to efficiently identify specific patient groups for research and clinical practice [60](#ref-60).

**Advanced Analytics for Precise Patient Stratification**

Beyond initial identification, AI is crucial for patient stratification, which involves grouping patients into clinically meaningful subgroups for more targeted interventions and more robust trial outcomes. One approach is **Patient Similarity Computation (PSC)**, which measures similarities among patients based on their historical clinical records. A novel distributed PSC (DPSC) technique leverages both time-series data (e.g., heart rate, blood pressure) and static data (e.g., demographics) to identify similar patients more accurately and quickly [61](#ref-61). This method utilizes Dynamic Time Warping (DTW) for time-series data and adaptive Weight-of-Evidence (aWOE) and Z-score transformations for static data, with distributed computing overcoming DTW's computational burden for big data [61](#ref-61). The use of aWOE also addresses privacy concerns by processing sensitive patient information in a privacy-preserving manner. While currently validated for specific conditions like coronary artery disease and congestive heart failure, this approach holds significant potential for optimizing patient cohort selection in personalized medicine trials [61](#ref-61).

**Temporal Patient Representation Learning** is another critical area, especially given the longitudinal nature of Electronic Health Records (EHRs). The ICU-TSB benchmark has been introduced to evaluate patient stratification methods using EHR data from intensive care units (ICUs) [62](#ref-62). This benchmark facilitates the comparison of various machine learning techniques, including recurrent neural networks like LSTMs and GRUs, in generating patient representations for clustering. The goal is to identify homogeneous trial populations that are more likely to respond similarly to treatment, thereby improving trial efficiency [62](#ref-62). Challenges remain in handling irregularly sampled ICU data and skewed data distributions, yet advancements in time-aware attention mechanisms and hybrid deep learning models for irregular time-series data are showing promising results for enhanced EHR modeling and prognosis prediction [63](#ref-63), [64](#ref-64), [65](#ref-65). Graph-based convolutional transformers are also being developed to model complex intra- and inter-encounter medical event interactions, offering valuable insights for patient risk stratification by identifying temporally and functionally related event clusters [66](#ref-66).

Furthermore, **Domain Generalization** frameworks, such as UdonCare, aim to enhance the transferability of predictive models across different patient populations or healthcare settings [67](#ref-67). UdonCare incorporates medical knowledge, specifically leveraging hierarchical medical ontologies like the International Classification of Diseases, Ninth Revision, Clinical Modification (ICD-9-CM), and an iterative domain discovery process to identify more robust patient cohorts. This approach can improve patient stratification and the generalizability of models for tasks such as mortality prediction, readmission, and drug recommendations, ultimately optimizing resource allocation in clinical trials [67](#ref-67). However, its effectiveness relies heavily on the quality and completeness of EHR data and may require adaptation for different medical ontologies [67](#ref-67).

In addition, advanced algorithms can identify **homogeneous subcohorts** within large, inhomogeneous datasets. A Goemans-Williamson type algorithm, for instance, outputs a linear classifier to identify such subsets, which can be particularly useful in diseases like breast cancer that exhibit high heterogeneity [68](#ref-68). By systematically identifying subcohorts where specific molecular changes (e.g., methylation levels and gene expression) co-occur, this approach refines patient selection for trials, enables personalized treatment strategies, and contributes to biomarker discovery, leading to more focused and potentially more successful trials [68](#ref-68). While promising for linking genomic markers with clinical outcomes, the clinical relevance of these identified associations requires further validation.

**Ensuring Fairness and Mitigating Bias in AI for Trials**

A critical consideration for integrating AI into clinical trials is ensuring fairness and mitigating algorithmic bias. AI models, if not carefully designed and evaluated, can perpetuate or even amplify existing health disparities due to biases in training data or algorithms [69](#ref-69). It is essential to move beyond aggregate performance metrics and conduct detailed subgroup analyses to identify potential biases that might lead to under- or over-treatment for specific patient populations within a trial [69](#ref-69). This approach is vital for improving patient safety and trial equity.

Tools like the `fairmetrics` R package provide a framework for rigorously evaluating group-based fairness criteria, enabling researchers to identify and quantify biases in predictive models used in clinical settings [70](#ref-70). This package offers both point and interval estimates for metrics related to independence, separation, and sufficiency, which is crucial for informed decision-making in developing equitable clinical trial models [70](#ref-70). However, its current scope is primarily limited to binary classification tasks with binary protected attributes. The concept of "Predictive Representativity" further emphasizes the need to audit fairness at the outcome level, quantifying how reliably models generalize fairness across subpopulations and deployment contexts, as demonstrated in skin cancer detection models that underperform for darker skin phototypes despite proportional sampling [71](#ref-71).

To directly address bias, generating **causally fair synthetic data** is gaining traction. The FairCauseSyn framework leverages LLMs to create synthetic data that explicitly preserves causal fairness, mitigating bias related to sensitive attributes like sex or race in clinical trial datasets [72](#ref-72). This framework can augment limited datasets, improve statistical power, and facilitate the design of more equitable clinical trials by identifying and addressing potential biases upfront. Furthermore, it supports privacy-preserving data sharing by generating synthetic data without revealing sensitive patient information, while maintaining statistical properties and causal relationships [72](#ref-72). Despite its promise, concerns remain regarding the "black box" nature of LLM-based generation and the potential for inadvertently amplifying biases if the original data is unrepresentative [72](#ref-72). Other advancements in this area include FairPFN, a tabular foundation model pre-trained on synthetic causal fairness data, designed to identify and mitigate causal effects of protected attributes without requiring prior knowledge of the causal model [73](#ref-73). Methods like Graph-based Fairness-aware Label Correction (GFLC) also contribute by correcting label noise while preserving demographic parity in datasets, enhancing the trustworthiness of machine learning systems [74](#ref-74). These efforts align with broader discussions on ethical considerations in medical laboratory data (MLD) models, emphasizing data quality, privacy, and the need for policy oversight [75](#ref-75).

**Conclusion**

AI is fundamentally reshaping patient cohort identification and stratification in clinical trials by enabling more efficient recruitment, precise patient grouping, and robust bias mitigation. From LLM-assisted matching and advanced patient similarity computations to temporal representation learning and causally fair synthetic data generation, these innovations promise to accelerate trial timelines, optimize resource allocation, and foster more equitable outcomes. However, the successful integration of these AI tools hinges on addressing persistent challenges related to data quality, model interpretability, computational scalability, and the rigorous validation of fairness and generalizability across diverse real-world clinical settings. Continued research and interdisciplinary collaboration are crucial to realizing the full potential of AI in bringing life-saving therapies to patients faster and more fairly.

# Intelligent Monitoring & Predictive Analytics During Trials

Intelligent monitoring and predictive analytics are transforming clinical trials, enabling more dynamic designs, personalized interventions, and proactive management of patient safety and outcomes. By leveraging diverse data modalities from electronic health records (EHRs), wearables, medical imaging, and even real-world social data, artificial intelligence (AI) offers unprecedented capabilities for real-time insights.

A fundamental challenge in clinical trials is the accurate prediction of complex, interdependent outcomes. Traditional methods often focus on single endpoints, overlooking the holistic impact of treatments. The Diffusion-based Interventional, Multi-outcome Estimation (DIME) model [76](#ref-76) addresses this by learning the joint distribution of multiple medical treatment outcomes (e.g., efficacy, adverse events). DIME employs a novel diffusion-based approach that accounts for the fundamental problem of causal inference through causal masking and captures outcome interdependencies using conditional masking and an autoregressive generation process. It can handle mixed-type outcomes (binary, categorical, continuous), moving beyond simple point estimates to provide uncertainty quantification critical for reliable decision-making [76](#ref-76). While DIME demonstrates strong performance on synthetic and medical datasets like MIMIC-III and IST, its full validation in real-world clinical trial settings and interpretability remain areas for further research [76](#ref-76).

Beyond predicting multiple outcomes, forecasting the timing of specific events is crucial, especially in progressive diseases. For Amyotrophic Lateral Sclerosis (ALS), a novel multi-event survival analysis approach predicts the time until patients experience significant functional decline in various domains (e.g., speaking, walking) [77](#ref-77). This method utilizes covariate-based models, outperforming traditional Kaplan-Meier estimators, and crucially, enables individual counterfactual predictions, such as the predicted impact of Riluzole or bulbar-onset on disease progression [77](#ref-77). Such personalized time-to-event predictions can refine patient selection, simulate treatment benefits, and optimize trial designs to account for disease heterogeneity. However, these models often rely on assumptions like conditional independent censoring, which may not fully hold in ALS trials due to high dropout rates potentially linked to disease progression, and typically do not integrate richer data modalities like magnetic resonance imaging (MRI) [77](#ref-77). Related advancements in survival analysis include iSurvJ [78](#ref-78), which improves handling of censored data by representing observations as interval-valued probability distributions and leveraging attention mechanisms with imprecise probability theory. These non-parametric models, especially iSurvJ, consistently outperform traditional methods like the Beran estimator, particularly in high-dimensional and heavily censored data scenarios common in clinical trials [78](#ref-78). However, their scalability to extremely large datasets and comprehensive comparison with other state-of-the-art transformer-based survival models warrant further investigation [78](#ref-78). Related research also highlights `SigBERT` [79](#ref-79) which integrates textual medical reports and rough path signature theory for enhanced survival risk estimation in oncology, and `EAGLE` [80](#ref-80), a framework for multimodal survival prediction using attention-based fusion and comprehensive attribution analysis, critical for interpreting complex predictions.

The foundation for intelligent monitoring often lies in comprehensively modeling patient trajectories from diverse clinical data. EHR2Path [81](#ref-81) demonstrates a scalable method for modeling longitudinal health trajectories by transforming heterogeneous EHR data into a structured format suitable for large language models (LLMs). This allows for simulating patient pathways, forecasting vital signs and lab results, and predicting length-of-stay, thereby aiding patient stratification, trial design, and adverse event prediction [81](#ref-81). A novel summary mechanism efficiently compresses long-term temporal context, addressing the challenge of extensive EHR data [81](#ref-81). However, EHR2Path's reliance on single-center data limits generalizability, and the interpretability of LLM-driven predictions remains a challenge [81](#ref-81). Complementary efforts in EHR modeling include `TALE-EHR` [63](#ref-63), which uses a time-aware attention mechanism and LLM embeddings for disease progression forecasting, and `CKD-EHR` [58](#ref-58), which distills knowledge from large LLMs to lightweight models for efficient and accurate disease risk prediction. The broader landscape of foundation models for clinical records [82](#ref-82) and medical time series [83](#ref-83), [84](#ref-84) further underscores the potential to reduce annotation burdens and improve generalization across clinical institutions.

Beyond structured data, unstructured information and digital biomarkers from wearables are increasingly vital. SensorLM [85](#ref-85) aims to interpret raw wearable sensor data by learning the 'language' of sensors through a hierarchical captioning pipeline and a large-scale dataset. This can automate data interpretation, improve remote patient monitoring, and enhance adherence tracking in decentralized clinical trials by translating physiological and activity patterns into natural language [85](#ref-85). However, SensorLM currently lacks clinical validation and generalizability across diverse devices, and raises important considerations regarding data privacy and regulatory compliance [85](#ref-85). Building on multimodal data, `ModFus-PD` [86](#ref-86) integrates clinical assessment scales and neuroimaging using cross-modal attention and contrastive learning for Parkinson's disease diagnosis, while `COPD-MMDDxNet` [87](#ref-87) fuses CT reports, blood gas, and hematological data for spirometry-free COPD diagnosis. The `CSFM` model [88](#ref-88) is a multi-modal foundation model pretrained on ECGs, PPGs, and clinical text, showing potential for enhanced patient stratification and outcome prediction in cardiovascular trials. `MD-ViSCo` [89](#ref-89) offers a unified framework for multi-directional vital sign waveform conversion, reducing the need for invasive monitoring and facilitating data imputation in clinical trials by generating missing vital signs from available signals [89](#ref-89). Despite its utility, it requires task- or dataset-specific fine-tuning and currently excludes other valuable modalities like clinical notes [89](#ref-89).

Predictive models extend to visual data, such as medical imaging and patient movement. Diffusion models are being explored for simulating patient-specific tumor evolution in response to radiation therapy, mapping pre-treatment images to post-treatment outcomes and predicting spatial tumor drift [90](#ref-90). This can optimize adaptive radiotherapy protocols and inform clinical trial decisions, but current models are limited by small datasets and lack direct temporal modeling [90](#ref-90). Similarly, `GLOMIA-Pro` [91](#ref-91) is a generalizable framework for longitudinal medical image analysis for disease progression prediction, addressing the ordinal nature of disease staging and representation collapse. `LinGuinE` [92](#ref-92) provides a semi-automated method for accurate longitudinal tumor segmentation in lung cancer, significantly improving the assessment of treatment response in trials by tracking tumor volume changes with minimal radiologist input. Its time-point agnostic nature and false-positive reduction enhance efficiency and robustness [92](#ref-92). `SSPINNpose` [93](#ref-93) offers a self-supervised physics-informed neural network for real-time estimation of joint kinematics and kinetics from minimally intrusive IMUs, streamlining motion capture and analysis in trials by reducing the reliance on labor-intensive ground truth data and offering scalability for objective movement assessments [93](#ref-93). A valuable resource for developing and benchmarking models for automatic exercise evaluation and gait analysis in clinical trials is the `GAITEX` dataset [94](#ref-94), which includes multimodal human motion data from impaired gait and rehabilitation exercises.

Advanced AI is also being applied to more nuanced aspects of clinical trial monitoring. `RL-HMM-DDM` [95](#ref-95) offers a framework for joint modeling of decision-making dynamics in behavioral experiments, particularly relevant for understanding cognitive engagement and decision-making strategies in conditions like Major Depressive Disorder. This can identify subgroups responding differently to treatments and provide objective behavioral markers, albeit with assumptions about 'lapsed' states and data requirements [95](#ref-95). For interpreting complex time-series data common in critical care and clinical trials, learnable mask-based approaches offer a more reliable way to understand feature importance over time, enabling better identification of factors influencing patient outcomes and improving monitoring strategies [96](#ref-96). However, these methods require validation for generalizability to diverse clinical endpoints and may incur significant computational costs [96](#ref-96). `THCM-CAL` [97](#ref-97) enhances clinical risk prediction by integrating structured and unstructured EHR data and modeling their causal relationships, providing uncertainty quantification for automated tasks like patient monitoring and adverse event detection [97](#ref-97). The reliance on LLMs for proposition extraction can introduce overhead, and generalizability across coding systems needs further validation [97](#ref-97). `ALINE` [98](#ref-98) proposes a unified framework for amortized Bayesian inference and active data acquisition, which could reduce sample sizes and trial durations by dynamically adjusting data-gathering strategies based on real-time evidence, particularly useful for adaptive trial designs. However, it relies on predefined priors and is currently tailored to fixed input dimensionalities [98](#ref-98). For real-world health data challenges, `Time-IMM` [99](#ref-99) provides a dataset and benchmark for irregular multimodal multivariate time series, critical for robust modeling.

Finally, predictive analytics extend to broader public health and treatment strategy optimization. The `SLSTM` framework [100](#ref-100) forecasts hospitalizations by integrating spatiotemporal features derived from social media data. This can inform optimal patient recruitment and resource allocation in trials, especially during public health emergencies, by anticipating demand on healthcare resources [100](#ref-100). However, the reliance on annually updated social connectedness indices and state-level focus may limit its real-time applicability and granularity [100](#ref-100). `NeuroSTORM` [101](#ref-101) introduces a general-purpose foundation model for fMRI analysis, learning generalizable representations from massive datasets. This offers a reliable and consistent method for analyzing brain imaging data in clinical trials, potentially leading to earlier disease detection, better patient stratification, and more objective assessment of treatment efficacy [101](#ref-101). In oncology, a novel method leverages Signature theory to detect malignant dynamics from very few blood samples [102](#ref-102). This could streamline patient monitoring, reduce the need for invasive procedures, and enable real-time risk assessment for adaptive trial designs, though validation on real-world ctDNA dynamics and comparison with existing methods are needed [102](#ref-102). Lastly, diffusion-based counterfactual augmentation [103](#ref-103) for video scenarios can visually represent how a patient's condition might change under different hypothetical treatments, providing explainable AI for visual progression and aiding synthetic data generation for rare diseases. Its utility relies on accurately defined causal graphs and generalizability to diverse medical video modalities [103](#ref-103).

These advancements highlight a significant shift towards more proactive, data-driven, and patient-centric clinical trials, offering tools for enhanced monitoring, more precise prognostics, and adaptive interventions. Addressing the limitations, particularly regarding generalizability, interpretability, and real-world validation, will be key to their widespread adoption in clinical practice.

# Streamlining Clinical Trial Data Infrastructure and Management

Efficient and reliable data handling forms the bedrock of modern clinical trials, yet it is often fraught with challenges stemming from data quality, heterogeneity, privacy concerns, and the need for robust management infrastructure. AI-driven solutions are emerging as critical tools to address these complexities, ultimately aiming to accelerate multi-center trials and enhance their scientific rigor.

**Addressing Data Quality and Missingness**

Real-world data (RWD), particularly from Electronic Health Records (EHRs), are increasingly leveraged in clinical trials for patient recruitment, outcome monitoring, and real-world evidence generation. However, EHRs frequently suffer from missing values and data heterogeneity, which can introduce bias and reduce statistical power [104](#ref-104), [105](#ref-105). To mitigate this, robust imputation methods are essential. Macomss is a novel imputation framework specifically designed for EHRs that addresses both structured and sporadic missingness, common in integrated, heterogeneous datasets [105](#ref-105). By providing theoretical guarantees and outperforming existing methods in simulations and real-world Duke University Health System (DUHS) datasets, Macomss enhances data utility for integrated analysis, improving patient stratification and reducing bias. While effective for structured and sporadic missingness, its scalability for very large datasets and sensitivity to missingness parameter estimations require further investigation.

Complementing this, a comprehensive benchmark for missing data imputation, IMAGIC-500, offers valuable insights into the performance of various techniques across different missingness scenarios (Missing Completely at Random - MCAR, Missing at Random - MAR, Missing Not at Random - MNAR) [104](#ref-104). This synthetic dataset, derived from World Bank household survey data, enables reproducible evaluation of statistical, traditional machine learning, and deep learning imputation methods. Although IMAGIC-500 provides critical insights into imputation accuracy and computational efficiency, its synthetic nature and limited feature set may not fully capture the complexities of real clinical trial data. The challenge of handling missingness distribution shifts between training and test datasets is further addressed by MIRRAMS, a deep learning framework that uses mutual information-based conditions to extract label-relevant information while remaining invariant to diverse missingness patterns, thereby enhancing robustness to unseen missingness scenarios at test-time [106](#ref-106). Similarly, cross-domain conditional diffusion models offer a solution for time series imputation, specifically tackling high missing rates and domain shifts in temporal dynamics [107](#ref-107).

**Managing Heterogeneous and Multimodal Data**

Clinical trials often involve diverse data modalities, from structured numerical values to unstructured clinical notes, and collected at irregular intervals. Integrating these heterogeneous data sources is crucial for comprehensive patient understanding. Time-IMM introduces a dataset and benchmark library (IMM-TSF) specifically designed for irregular multimodal multivariate time series, reflecting the messy reality of healthcare data with varying sampling rates, asynchronous modalities, and pervasive missingness [108](#ref-108). This explicit modeling of multimodality improves forecasting accuracy, which can enhance clinical trial efficiency by predicting patient responses or optimizing treatment schedules. However, its focus is primarily on forecasting, and direct applications to other trial tasks like anomaly detection or risk assessment require further adaptation.

To semantically link time series data with contextual information, TRACE proposes a multimodal retriever that grounds time-series embeddings in aligned textual context [109](#ref-109). TRACE enables fine-grained channel-level alignment and supports cross-modal retrieval (Text-to-Timeseries and Timeseries-to-Text), enriching downstream models for forecasting and classification. This could be used in clinical trials to retrieve historical patient records based on symptom descriptions or integrate diverse signals from EHRs and wearables. A limitation is its reliance on supervised textual alignment, which might be scarce in some clinical settings. Furthermore, MoCA (Multi-modal Cross-masked Autoencoder) offers a self-supervised learning framework for processing complex, multi-modal time-series data from digital health technologies like wearable sensors [110](#ref-110). By leveraging cross-modality masking, MoCA learns rich representations from unlabeled data, addressing the common problem of scarce labeled datasets in clinical research and showing promise in imputation tasks for mitigating missing sensor data. However, its efficacy across a broader range of clinical data modalities and populations needs further investigation.

The advancement in integrating time series with natural language is also evident in ITFormer, which bridges time-series encoders with frozen large language models (LLMs) for multi-modal Question Answering, capable of extracting, aligning, and fusing temporal and textual features for improved accuracy [111](#ref-111). Other related work focuses on multi-view contrastive learning for robust domain adaptation in medical time series analysis to handle complex temporal dependencies and distribution shifts [112](#ref-112), and MIRA, a medical time series foundation model, which integrates continuous-time positional encoding and a mixture-of-experts layer for accurate forecasting across irregular medical data [113](#ref-113). These innovations collectively enable a more holistic and accurate understanding of patient data.

**Enabling Privacy-Preserving Collaboration**

Multi-center clinical trials require collaborative analysis of sensitive patient data across distributed institutions while preserving privacy. Federated Learning (FL) and synthetic data generation are key paradigms addressing this.

DC-Clustering introduces a "Data Collaboration Clustering" method that enables collaborative clustering of distributed, heterogeneous data without direct sharing of raw patient information [114](#ref-114). This method is particularly adept at handling complex data partitioning where institutions hold different features for different patient subgroups, facilitating comprehensive patient stratification and biomarker identification in a privacy-preserving manner. Its main limitation involves the need for further research into countermeasures against reconstruction attacks and user collusion.

TriCon-SF proposes a novel serial federated learning framework that uses a triple-shuffle mechanism to enhance privacy by breaking deterministic learning patterns and a contribution-aware evaluation for fairness and accountability [115](#ref-115). This approach is designed for heterogeneous healthcare data, enabling robust and generalizable models while reducing communication overhead. While promising for privacy and efficiency, it needs further validation on a broader range of clinical data types and consideration of regulatory compliance for real-world deployment. AdRo-FL further improves FL efficiency and security through informed client selection, enabling faster model training and robust defense against biased selection attacks (BSAs) which could manipulate sensitive clinical trial data [116](#ref-116). Its cluster-oriented and distributed frameworks offer flexibility for diverse institutional setups, though its performance depends on careful parameter tuning and robust security assumptions. Many other FL approaches aim to improve efficiency and robustness under data heterogeneity, such as ShiftEx, a mixture of experts framework for continual adaptation to covariate and label shifts [117](#ref-117), UniVarFL, which uses uniformity and variance regularization to emulate IID-like training [118](#ref-118), and VGS-ATD for robust distributed learning in multi-label medical image classification [119](#ref-119).

The application of FL extends to Large Language Models (LLMs) within clinical contexts. The FlowerTune LLM Leaderboard provides a crucial benchmark for evaluating federated fine-tuning of LLMs across diverse domains, including medical [120](#ref-120). Its insights into base models and fine-tuning strategies can guide the selection of LLMs for tasks like adverse event detection or trial protocol optimization, while analyzing communication costs and VRAM usage for resource optimization. GradualDiff-Fed specifically targets communication efficiency in federated LLM fine-tuning by transmitting only model weight differences, facilitating AI-powered tool development for clinical trial design and patient recruitment under privacy constraints [121](#ref-121). Despite these advancements, privacy risks in LLMs remain; PropInfer demonstrates that even aggregated dataset-level properties (e.g., patient demographics, disease prevalence) can be inferred from fine-tuned LLMs, highlighting a critical vulnerability for sensitive clinical data [122](#ref-122). Similar vulnerabilities, such as membership inference attacks, are also demonstrated against LoRA fine-tuned language models by LoRA-Leak [123](#ref-123). This necessitates robust defenses.

Synthetic data generation offers an alternative to direct data sharing. A method for privately generating continuous-time synthetic trajectories, particularly useful for sensitive time-series data like in healthcare, reduces reliance on extensive individual data by requiring only single time-point contributions [124](#ref-124). This enables realistic, anonymized patient data for trial simulation or model training with strong privacy guarantees, though practical performance on real clinical data needs further validation. To ensure the traceability of synthetic data, TimeWak proposes a temporal chained-hashing watermark for time series data, embedding a watermark directly into the real space of the data [125](#ref-125). This helps verify data sources and prevent misuse, essential for regulatory compliance, despite current limitations with native streaming data support. Other advancements in synthetic data include embedding-based federated data sharing using Differentially Private Conditional VAEs [126](#ref-126), Federated Timeline Synthesis for generative foundation models on EHRs [127](#ref-127), and RawMed, a framework for synthesizing multi-table, time-series EHR data with minimal preprocessing [128](#ref-128). The broader utility and privacy tradeoffs of synthetic image generation are surveyed in [129](#ref-129), and an open-source SDK provides tools for tabular synthetic data generation with differential privacy guarantees [130](#ref-130).

**Ensuring Reproducibility, Governance, and Monitoring**

The integrity and long-term utility of AI in clinical trials depend on robust infrastructure, rigorous validation, and continuous monitoring. A data-centric framework for reproducible machine learning (ML) introduces six formalized artifacts (Dataset, Feature, Workflow, Execution, Asset, Controlled Vocabulary) to ensure that all aspects of ML model development are versioned, traceable, and transparent [131](#ref-131). This lifecycle-aware reproducibility is paramount for regulatory approval and scientific validation in clinical trials, facilitating debugging and collaborative multi-center efforts, although deeper support for reproducible environments like containerization is still needed. Lessons from making an ML pipeline production-ready in healthcare, transitioning from a "Big Ball of Mud" to a microservices architecture, highlight the importance of modularization, design patterns, and Test-Driven Development (TDD) for extensibility, maintainability, and robustness [132](#ref-132). These engineering practices are directly applicable to building reliable AI solutions for patient stratification or adverse event detection. An "Agentic AI framework" aims to automate the entire clinical data pipeline from ingestion to inference using modular, task-specific agents, promising reduced manual intervention and scalability [133](#ref-133).

For evaluating the quality of LLM/ML-extracted clinical data from EHRs, the VALID (Validation of Accuracy for LLM/ML-Extracted Information and Data) framework provides a comprehensive methodology encompassing variable-level performance metrics, automated verification checks, and replication/benchmarking analyses [134](#ref-134). This systematic validation enhances data curation for trial design, patient cohort identification, and real-world evidence generation. However, its dependence on high-quality reference data and resource intensity pose practical challenges.

Post-deployment monitoring of AI models is critical for maintaining reliability and safety, especially in dynamic clinical environments where data shifts can degrade performance. D3M offers a label-efficient monitoring algorithm that detects model failures in deployment without retraining or access to training data, flagging deteriorating shifts in clinical trials when patient data distributions change [135](#ref-135). While effective, its performance can be sensitive to hyperparameter choices. Building on this, a position paper advocates for statistically valid post-deployment monitoring as a standard for clinical AI, framing performance degradation and data shifts as hypothesis testing problems [136](#ref-136). This provides a principled, reproducible foundation for ensuring continued reliability, though practical implementation guidance for diverse clinical data types is needed. Furthermore, FSL-Net automates the detection of feature shifts in datasets, crucial for identifying biases introduced by multi-site data collection or varying technologies, thereby improving data quality and accelerating trial results [137](#ref-137). Finally, incorporating human expertise efficiently is addressed by a Bayesian framework for querying experts for class labels, modeling expert correlation and inferring unobserved labels, which can reduce annotation costs and improve data validation in clinical contexts [138](#ref-138).

**Conclusion**

The landscape of clinical trial data management is rapidly evolving, driven by the imperative for efficiency, data quality, and privacy. The integration of AI-driven solutions addresses critical challenges, from handling missing and heterogeneous data to enabling secure, multi-institutional collaboration through federated learning and synthetic data generation. Innovations in model monitoring, pipeline reproducibility, and expert integration are bolstering the robustness and trustworthiness of AI in clinical research. While significant progress has been made, ongoing research is crucial to address remaining limitations such as scalability, full real-world validation, mitigation of privacy attacks, and the dynamic nature of clinical data, paving the way for truly streamlined and ethically sound clinical trial operations.

# Large Language Models (LLMs) for Enhanced Trial Workflows

Large Language Models (LLMs) are rapidly reshaping the landscape of clinical trials by automating and enhancing a wide array of textual and reasoning-heavy tasks. From streamlining documentation and information retrieval to advancing complex clinical reasoning and communication, LLMs offer unprecedented opportunities for efficiency and insight, while simultaneously necessitating careful consideration of challenges such as hallucination and interpretability.

**Streamlining Documentation and Data Extraction**
A significant application of LLMs in clinical trials lies in automating the extraction and structuring of critical patient data from diverse sources. Extracting medication information and identifying discontinuations from Electronic Health Records (EHRs), traditionally a labor-intensive process, can be significantly accelerated by LLMs. For instance, GPT-4o demonstrated high F1 scores (94.0% for medication extraction, 78.1% for discontinuation) in zero-shot settings, with open-source models like Llama-3.1-70B-Instruct also showing strong performance [139](#ref-139). This automation can improve patient eligibility screening and safety monitoring.

Beyond simple extraction, LLMs are being developed to convert unstructured data into standardized formats crucial for clinical research. One approach involves transforming existing information extraction datasets into Case Report Form (CRF) formats to generate training resources for automated CRF filling systems [140](#ref-140). While challenging for current LLMs, this method could significantly reduce manual data entry and improve data accuracy in trials. Similarly, LLMs show promise in annotating disease from radiology reports, outperforming rule-based algorithms with lightweight models like Llama-3.1 8B and Gemma-3 27B in zero-shot settings across various organ systems [141](#ref-141). This can improve patient identification and progression monitoring.

The development of structured clinical notes from multimodal inputs, such as lesion images and sparse text, is another area where LLMs prove valuable. A weakly supervised multimodal framework can generate SOAP (Subjective, Objective, Assessment, Plan) notes, reducing reliance on extensive manual annotations and streamlining documentation for conditions like skin carcinoma [142](#ref-142). This directly translates to consistent and comprehensive data capture in trials. Furthermore, encoder-based transformer models like BioClinical ModernBERT are being developed to process entire clinical notes, enabling tasks such as patient cohort selection and de-identification of sensitive information due to their long-context processing capabilities [143](#ref-143). The ability of open-source LLMs to perform clinical information extraction in resource-constrained settings, even for languages like Dutch, underscores their potential for widespread adoption where privacy and transparency are paramount [144](#ref-144).

**Enhancing Information Retrieval and Question Answering**
LLMs are also proving instrumental in enhancing the retrieval of clinical information, a cornerstone of evidence-based research and trial design. By optimizing prompts, LLMs can facilitate evidence-grounded clinical question answering (QA) from EHRs, potentially accelerating patient enrollment and improving data quality [145](#ref-145). This approach, demonstrated by the runner-up in the BioNLP 2025 ArchEHR-QA shared task, offers a cost-effective alternative to model fine-tuning. For more complex database interactions, systems like M3 allow researchers to query large clinical databases such as MIMIC-IV using natural language, translating questions into SQL queries. This significantly lowers the technical barrier for clinical researchers, enabling more efficient cohort analyses and rapid hypothesis generation [146](#ref-146).

To bolster the factual accuracy of LLM responses, particularly in medical contexts, Retrieval-Augmented Generation (RAG) frameworks are critical. MIRIAD, a large-scale corpus of medical query-response pairs, improves LLMs' ability to ground responses in high-quality medical knowledge and detect hallucinations, crucial for trustworthy information retrieval in clinical settings [147](#ref-147). MedCite further advances this by generating verifiable citations for LLM-produced medical text, enhancing reliability for tasks like generating inclusion/exclusion criteria or patient-facing summaries [148](#ref-148). The need for advanced RAG is also highlighted by BioMol-MQA, a multimodal QA dataset designed to test LLMs' reasoning over complex drug interactions by integrating information from knowledge graphs, text, and molecular structures [149](#ref-149). This could lead to better drug combination strategies and patient stratification in trials. Benchmarking efforts such as MedThink-Bench [150](#ref-150), MediQAl [151](#ref-151), and HIVMedQA [152](#ref-152) provide crucial evaluation frameworks for LLMs' medical QA capabilities, emphasizing the gap between factual recall and complex reasoning. The eSapiens framework further demonstrates the utility of hybrid RAG pipelines for robust, citation-aware QA in enterprise knowledge processing, including clinical applications [153](#ref-153).

**Advancing Clinical Reasoning and Decision Support**
LLMs are increasingly being tasked with complex clinical reasoning, moving beyond simple information retrieval to support diagnostic processes and treatment planning. Med-REFL focuses on enhancing the quality of intermediate reflection steps in LLM reasoning, crucial for accuracy in high-stakes medical scenarios. By decomposing medical questions into fine-grained reasoning paths and leveraging self-corrected fine-grained reflection, Med-REFL can lead to more accurate and trustworthy reasoning in medical AI applications [154](#ref-154). ReasonMed, a large-scale, multi-agent generated dataset, similarly aims to advance medical reasoning, demonstrating that combining Chain-of-Thought (CoT) reasoning with concise summaries can improve performance in knowledge-intensive medical QA [155](#ref-155). This can aid in automating literature reviews and optimizing patient recruitment.

However, LLMs can exhibit biases, such as belief bias, where conclusions align with prior beliefs regardless of logical validity. BIS Reasoning 1.0, a Japanese dataset, specifically evaluates LLMs' ability to perform logically sound reasoning that contradicts common beliefs, highlighting the need for robust logical integrity in critical applications like healthcare [156](#ref-156). Med-PRM proposes a process reward modeling framework that verifies each reasoning step against established medical knowledge bases, ensuring that AI reasoning is grounded in medical evidence, which could improve trial analysis and patient safety [157](#ref-157).

The integration of LLMs with other AI modalities, particularly for multimodal reasoning, is also gaining traction. The Mentor-Intern Collaborative Search (MICS) strategy, which generates high-quality, step-by-step reasoning data for medical Multimodal LLMs (MLLMs), enhances their diagnostic support capabilities [158](#ref-158). This contributes to more accurate patient assessment and outcome evaluation in trials. Other research also proposes frameworks like MEXA for dynamic multi-expert aggregation across diverse multimodal inputs [159](#ref-159), and MMAT-1M, a million-scale dataset for multimodal agent tuning, supporting CoT, reflection, and dynamic tool usage [160](#ref-160). The concept of "context-switching" in medical AI emphasizes models that dynamically adapt their reasoning to varying clinical contexts, such as patient populations or healthcare settings, without retraining [161](#ref-161). This adaptability can improve trial designs and generalize results to real-world practice. Furthermore, the "Optimization Paradox" highlights that maximizing individual AI component performance may not translate to optimal system-wide performance in multi-agent clinical decision support systems, underscoring the need for holistic system validation in trials [162](#ref-162). Explainable AI frameworks like xHAIM focus on generating comprehensive patient summaries and linking predictions to patient-specific knowledge to provide clinical explanations, transforming AI into an explainable decision support system [163](#ref-163). Reinforcement learning approaches, like CAPO [164](#ref-164) and RARL [165](#ref-165), are being explored to enhance reasoning consistency and generalization in medical VLMs under data and hardware constraints. This aligns with the broader push to integrate clinical reasoning into LLM-based diagnosis via etiology-aware attention steering to enhance diagnostic accuracy and reliability [166](#ref-166). LLMs are also being evaluated for hierarchical clinical document classification, a critical task for ICD-10 coding, though current performance indicates the need for hybrid human-AI approaches [167](#ref-167).

**Facilitating Communication and Workflow Automation**
LLMs are transforming communication and workflow automation within clinical trials. Frameworks like CoDial enable non-technical experts to define and refine dialogue logic for conversational agents by converting expert knowledge into executable conversation logic [168](#ref-168). This allows for the rapid development of chatbots for patient engagement, data collection (e.g., PROs), and clinical site staff support, aligning precisely with trial protocols. C-PATH further demonstrates a conversational AI system for patient assistance and triage, fine-tuned on medical knowledge and dialogue data to provide lay-person-friendly conversations [169](#ref-169).

Beyond text, agentic AI systems are being applied to automate computer vision tasks in clinical trials, reducing the need for manual configuration and expertise in image processing [170](#ref-170). This can accelerate image analysis pipelines, particularly for trials involving large medical imaging datasets. The promise of Vision-Language Models (VLMs) in medical image analysis is substantial, with research exploring their adaptation, training strategies, and application across diverse tasks like 3D radiology VQA [171](#ref-171), [172](#ref-172), [173](#ref-173). Benchmarks like MedErr-CT [174](#ref-174) are specifically designed to identify and correct errors in CT reports using MLLMs. Agentic RAG frameworks are also improving radiology question answering by enabling LLMs to iteratively retrieve targeted clinical evidence [175](#ref-175), and PathChat+ is enhancing multi-modal reasoning for human pathology by evaluating whole-slide images and generating grounded reports [176](#ref-176).

In broader trial management, decentralized multi-agent frameworks like the Intelligent System of Emergent Knowledge (ISEK) propose a coordination fabric for human and AI agents. Its six-phase protocol (Publish, Discover, Recruit, Execute, Settle, Feedback) could streamline trial operations by automating participant identification, data collection, and financial settlements in a censorship-resistant and self-adaptive manner [177](#ref-177). In drug discovery, MolProphecy integrates medicinal chemists' knowledge with molecular property prediction models, accelerating the identification of promising drug candidates for trials by incorporating human-derived reasoning and structural features [178](#ref-178).

Operational efficiency is also being addressed through LLM compression and semantic scheduling. Saliency adaptation frameworks enable on-device deployment of lightweight LLMs for medical AI assistants by pruning irrelevant neurons and using quantization, allowing for real-time data analysis on resource-constrained devices like Raspberry Pi [179](#ref-179). Semantic scheduling for LLM inference prioritizes tasks based on urgency and importance, which could be critical for prioritizing safety alerts or urgent patient data analysis in trials [180](#ref-180). Furthermore, the integration of LLMs with neurophysiological data from Electroencephalography (EEG) and Magnetoencephalography (MEG) holds promise for advancing brain-computer interfaces (BCIs) and automating the generation of natural language reports from brain activity [181](#ref-181), [182](#ref-182). Quantum ensemble methods are even being explored to address small datasets in healthcare, demonstrating potential for improved patient selection in immunotherapy trials [183](#ref-183). The emergence of generalist medical foundation models like Lingshu, which undergoes multi-stage training with reinforcement learning, also aims to unify multimodal medical understanding and reasoning, improving the accuracy and reliability of AI in healthcare [184](#ref-184).

**Addressing Key Challenges for Trustworthy AI**
Despite their immense potential, the safe and trustworthy integration of LLMs into clinical trials hinges on addressing critical limitations. Hallucination, where models generate inaccurate or misleading information, remains a significant barrier. The CHECK framework offers a continuous-learning approach that integrates structured clinical databases with a probabilistic reasoning classifier to detect and mitigate factual and reasoning-based hallucinations. This framework reduced hallucination rates from 31% to 0.3% in Llama3.3-70B-Instruct, demonstrating a scalable solution for trustworthy AI deployment [185](#ref-185). The need for expert-level validation of AI-generated medical text is further highlighted by MedVAL, a self-supervised framework that trains evaluator LMs to assess factual consistency, achieving high F1 scores in alignment with physician judgments [186](#ref-186). Research also rigorously benchmarks open-source LLMs for "honesty, helpfulness, and harmlessness" in medical QA, revealing trade-offs and areas for improvement [187](#ref-187).

Uncertainty estimation is another crucial aspect for high-stakes medical applications. Fine-grained evaluation of uncertainty estimation methods in clinical QA with LLMs across diverse models, specialties, and question types reveals substantial variation, underscoring the importance of model selection and understanding their limitations [188](#ref-188). Techniques like Expert-Controlled Classifier-Free Guidance are being developed to identify unreliable outputs from medical VLMs and refine them without additional training, aligning responses with clinical expertise [189](#ref-189).

Generalizability and bias are persistent concerns. While many advancements are demonstrated on specific datasets (e.g., MIMIC-III, MIMIC-IV), their applicability to diverse patient populations, geographical regions, and clinical settings often requires further validation [140](#ref-140), [142](#ref-142), [162](#ref-162). The development of BioPars for Persian biomedical text mining [190](#ref-190) and MediQAl for French medical QA [151](#ref-151) highlights the need for multilingual adaptation. Federated learning, as demonstrated by FedVLMBench for vision-language models, offers a privacy-preserving solution for collaborative training across institutions, addressing data heterogeneity while maintaining privacy [191](#ref-191). The concept of "context-switching" further aims to make models dynamically adaptable to different populations and workflows without retraining [161](#ref-161).

Computational efficiency and scalability remain practical limitations for deploying complex LLMs in real-world clinical environments. While frameworks like Med-REFL and MICS show promising reasoning improvements, they can be computationally intensive [154](#ref-154), [158](#ref-158). Solutions like LLM compression for on-device deployment [179](#ref-179) and training-free agent distillation (AgentDistill) from large to smaller models using Model-Context-Protocols (MCPs) [192](#ref-192) are crucial for broader adoption by lowering computational requirements. Semantic scheduling [180](#ref-180] and dynamic reasoning strategies like Kwaipilot-AutoThink (KAT) [193](#ref-193) also offer avenues for optimized resource allocation and reduced token usage.

Ultimately, integrating LLMs into clinical trials requires careful consideration of regulatory compliance, ethical implications, and the need for robust human oversight, issues often acknowledged as critical limitations in current research [194](#ref-194), [168](#ref-168), [195](#ref-195).

**Conclusion**
LLMs are poised to revolutionize clinical trial workflows by automating labor-intensive tasks, enhancing information accessibility, and improving clinical reasoning. While significant progress has been made in areas such as documentation, data extraction from unstructured notes, clinical question answering, and multimodal reasoning, critical challenges like ensuring factual accuracy, quantifying uncertainty, and achieving robust generalizability in diverse real-world settings persist. Future research will likely focus on developing more interpretable and reliable models, integrating them seamlessly into existing clinical workflows, and validating their performance through rigorous, real-world clinical trials. This holistic approach, combining technological advancements with careful consideration of human-AI collaboration and ethical guidelines, will be essential for realizing the full potential of LLMs in accelerating medical research and improving patient outcomes.

# Conclusion

The insights from recent developments reveal a convergent effort to integrate AI across the clinical trial continuum, fundamentally redefining its operational and analytical paradigms. Significant progress has been made in leveraging predictive intelligence for accelerated and de-risked development, driving precision through personalized strategies, and enhancing the real-world relevance of findings. Methodological innovations in causal inference offer robust treatment effect estimations by addressing confounding and leveraging diverse data modalities. Similarly, advancements in patient cohort identification and stratification are improving recruitment efficiency and trial relevance, while intelligent monitoring and predictive analytics provide real-time insights for adaptive designs. Underlying these advancements are robust solutions for data infrastructure and management, tackling issues of quality, heterogeneity, and privacy through federated learning and synthetic data. Large language models, in particular, are streamlining documentation, information retrieval, and complex clinical reasoning. Despite these advances, consistent themes emerge regarding challenges in achieving widespread adoption. These include the critical need for high-quality, unbiased data, addressing model interpretability and the 'black box' problem, adapting regulatory frameworks, and mitigating ethical concerns related to algorithmic fairness and privacy. Computational resource demands and ensuring generalizability across diverse clinical settings also remain pertinent. Future progress will depend on continued interdisciplinary collaboration, the establishment of standardized data frameworks, and rigorous validation to ensure the reliability and ethical deployment of AI in transforming clinical trials for more efficient and equitable healthcare outcomes.

# References

1. <a id="ref-1"></a>Mihaela van der Schaar, Richard Peck, Eoin McKinney, Jim Weatherall, Stuart Bailey, Justine Rochon, Chris Anagnostopoulos, Pierre Marquet, Anthony Wood, Nicky Best, Harry Amad, Julianna Piskorz, Krzysztof Kacprzyk, Rafik Salama, Christina Gunther, Francesca Frau, Antoine Pugeat, Ramon Hernandez (2025). *Revolutionizing Clinical Trials: A Manifesto for AI-Driven Transformation*. ArXiv:2506.09102v1. [https://arxiv.org/pdf/2506.09102v1](https://arxiv.org/pdf/2506.09102v1)
2. <a id="ref-2"></a>Elhoucine Elfatimi, Yassir Lekbach, Swayam Prakash, Lbachir BenMohamed (2025). *Artificial Intelligence and Machine Learning in the Development of Vaccines and Immunotherapeutics Yesterday, Today, and Tomorrow*. ArXiv:2506.12185v1. [https://arxiv.org/pdf/2506.12185v1](https://arxiv.org/pdf/2506.12185v1)
3. <a id="ref-3"></a>Sabeen Khaliq, Konstantin Koshechkin (2025). *Innovation management in AI advancement: Revolutionizing health system and biopharma*. ArXiv:10.55976/jdh.42025141429-38. [https://www.semanticscholar.org/paper/11dfa1355492365fe46016dc56a0420306be52d8](https://www.semanticscholar.org/paper/11dfa1355492365fe46016dc56a0420306be52d8)
4. <a id="ref-4"></a>Itohanosa Omolara Osarhiemen, Boluwatife Samuel Awe, M. O. Oyedele, Ufuomanefe Cleopatra Omoemu, Konstantin Koshechkin (2025). *Innovation Management in AI Development: Transforming Healthcare and Biopharma*. ArXiv:10.9734/ajrcos/2025/v18i6713. [https://www.semanticscholar.org/paper/e820dcda3765a27eb2bb31d188d53b52d3476030](https://www.semanticscholar.org/paper/e820dcda3765a27eb2bb31d188d53b52d3476030)
5. <a id="ref-5"></a>Vega Masignani, Ricardo Palacios, Marie-Thérèse Martin, Fabian Tibaldi, V. K. Vadivelu (2025). *De-risking vaccine development: lessons, challenges, and prospects*. ArXiv:10.1038/s41541-025-01211-z. [https://www.semanticscholar.org/paper/0ddced94949a5b6dba7782ad7c18f36f0ea5bf8e](https://www.semanticscholar.org/paper/0ddced94949a5b6dba7782ad7c18f36f0ea5bf8e)
6. <a id="ref-6"></a>Vikas Kaushik, Pankaj Gupta (2025). *The future of personalized medicine in India*. ArXiv:10.36948/ijfmr.2025.v07i03.47618. [https://www.semanticscholar.org/paper/4c9152820b2a56086141ed99270b2e6ccd42df12](https://www.semanticscholar.org/paper/4c9152820b2a56086141ed99270b2e6ccd42df12)
7. <a id="ref-7"></a>Meng Zhu, Andy Tay, Xianlei Li (2025). *Immuno‐Engineering in the AI Era: From Fundamental Research to Clinical Translation*. ArXiv:10.1002/adtp.202500087. [https://www.semanticscholar.org/paper/ccc895e5ebfc31067caad95f6a766c1b4716d947](https://www.semanticscholar.org/paper/ccc895e5ebfc31067caad95f6a766c1b4716d947)
8. <a id="ref-8"></a>D. Kader, Andrew Coppola, Aditya Vijay, A. Fontalis, Fares S. Haddad (2025). *The future of precision orthopaedics: personalized data-driven practice*. ArXiv:10.1302/2633-1462.67.BJO-2025-0056.R1. [https://www.semanticscholar.org/paper/6619b96ba643b5775053065df84fdea4d02e849c](https://www.semanticscholar.org/paper/6619b96ba643b5775053065df84fdea4d02e849c)
9. <a id="ref-9"></a>Ji-Ting Huang, Lei Dai, D. Ma, Zhi-Ming Shao (2025). *Omics datasets can bridge the gap between tumor biology and patient care*. ArXiv:10.1371/journal.pbio.3003279. [https://www.semanticscholar.org/paper/2cfab7170f890508b3ebe0b99608d8910602e523](https://www.semanticscholar.org/paper/2cfab7170f890508b3ebe0b99608d8910602e523)
10. <a id="ref-10"></a>Don Roosan, Saif Nirzhor, Rubayat Khan, Fahmida Hai (2025). *Quantum Gradient Optimized Drug Repurposing Prototype for Omics Data*. ArXiv:10.5220/0013524900003967. [https://www.semanticscholar.org/paper/71e81ed15d11c95d65b598ad7956e323af06b89a](https://www.semanticscholar.org/paper/71e81ed15d11c95d65b598ad7956e323af06b89a)
11. <a id="ref-11"></a>Ramprakash Kalapala (2025). *AUTOMATED CARE PATHWAYS: LEVERAGING AI AND EHR DATA TO PERSONALIZE TREATMENT JOURNEYS*. ArXiv:10.26483/ijarcs.v16i3.7264. [https://www.semanticscholar.org/paper/321f8f38f9a9869cc8f5c63daddee55138aa6abd](https://www.semanticscholar.org/paper/321f8f38f9a9869cc8f5c63daddee55138aa6abd)
12. <a id="ref-12"></a>Irene Sagay, Sandra Oparah, O. Akomolafe, Ajao Ebenezer Taiwo, Tolulope Bolarinwa (2024). *Using AI to Predict Patient Outcomes and Optimize Treatment Plans for Better Healthcare Delivery*. ArXiv:10.54660/ijfei.2024.1.1.146-152. [https://www.semanticscholar.org/paper/bd3a028256927dbf6fe3617f376658d13d52a97a](https://www.semanticscholar.org/paper/bd3a028256927dbf6fe3617f376658d13d52a97a)
13. <a id="ref-13"></a>Artur Quintiliano, A. J. Bentall (2025). *The New Horizon: A Viewpoint of Novel Drugs, Biomarkers, Artificial Intelligence, and Self-Management in Improving Kidney Transplant Outcomes*. ArXiv:10.3390/jcm14145077. [https://www.semanticscholar.org/paper/f9a6ab022d08da2818ee97499cd4f7c0dbdb459f](https://www.semanticscholar.org/paper/f9a6ab022d08da2818ee97499cd4f7c0dbdb459f)
14. <a id="ref-14"></a>Mora Guardamagna, Eduardo Zamorano, Victor Albarrán-Artahona, A. Mesas, J. C. Benítez (2025). *Emerging Techniques of Translational Research in Immuno-Oncology: A Focus on Non-Small Cell Lung Cancer*. ArXiv:10.3390/cancers17132244. [https://www.semanticscholar.org/paper/cde082b79d32006afa6405a49ffc15c064c35437](https://www.semanticscholar.org/paper/cde082b79d32006afa6405a49ffc15c064c35437)
15. <a id="ref-15"></a>Francesca Maria Di Muro, Katerina Dangas, Rebecca F Ortega, B. Vogel, Wayne B Batchelor, Pamela S Douglas, Roxana Mehran (2025). *Preserving and Promoting Clinical Trial Representativeness: A Review of Existing Strategies and the Path Forward.*. ArXiv:10.1001/jamacardio.2025.2421. [https://www.semanticscholar.org/paper/b870a57b4348834ce0a7d5be6f9a4e01917ed373](https://www.semanticscholar.org/paper/b870a57b4348834ce0a7d5be6f9a4e01917ed373)
16. <a id="ref-16"></a>Ignacio Leiva-Escobar, Camilo Scherkl, W. Haefeli, Andreas D. Meid (2025). *Transporting trial results to synthetic real-world populations in order to estimate real-world effectiveness of newly marketed medicines*. ArXiv:10.1136/bmjopen-2024-089218. [https://www.semanticscholar.org/paper/218ca44a8bf8bc3139129e0e51c00cdb78197c4f](https://www.semanticscholar.org/paper/218ca44a8bf8bc3139129e0e51c00cdb78197c4f)
17. <a id="ref-17"></a>Raffaele Bruno (2025). *Use of real-world data as pivotal evidence in veterinary regulatory applications*. ArXiv:10.3389/fvets.2025.1588068. [https://www.semanticscholar.org/paper/587400c8e8d83ddfde17999a706b81c6459ff747](https://www.semanticscholar.org/paper/587400c8e8d83ddfde17999a706b81c6459ff747)
18. <a id="ref-18"></a>David S. Liebeskind, Ashutosh P. Jadhav (2025). *Neurovascular Innovation at the FDA: Pivotal Strategies to Effectively Modernize the Realization of Diagnostic, Drug, and Device Products*. ArXiv:10.1161/svin.125.001806. [https://www.semanticscholar.org/paper/0191f729cf311b365aa0085e8e1530d221b5fe89](https://www.semanticscholar.org/paper/0191f729cf311b365aa0085e8e1530d221b5fe89)
19. <a id="ref-19"></a>S. O'Reilly, Ines Vaz Luis, Virginie Adam, E. Razis, A. Urruticoechea, A. Arahmani, Eva Carrasco, Boon H Chua, J. Bliss, C. Straehle, T. Goulioti, Barbro Lindholm, Gustavo Werustsky, E. Brain, P. Bedard, G. Curigliano, S. Loi, S. Saji, D. Cameron (2025). *Advancing equitable access to innovation in breast cancer*. ArXiv:10.1038/s41523-025-00768-1. [https://www.semanticscholar.org/paper/77c4538da83b0750e5d19ad715ba0dff78cd88ba](https://www.semanticscholar.org/paper/77c4538da83b0750e5d19ad715ba0dff78cd88ba)
20. <a id="ref-20"></a>Aqib Iqbal, Arbaz Haider Khan, Hassan Tanveer, Muhammad Ali Adam, Muhammad Faheem (2025). *Artificial Intelligence in Health Monitoring: A Detailed study of Current Challenges and Promising Solutions to Improve Healthcare*. ArXiv:10.54660/.ijmrge.2025.6.4.1-10. [https://www.semanticscholar.org/paper/8c8f8e91c6da1f42114b9f96eccac31dc57f1d54](https://www.semanticscholar.org/paper/8c8f8e91c6da1f42114b9f96eccac31dc57f1d54)
21. <a id="ref-21"></a>Ankit Nagar, Joga Gobburu, Aloka Chakravarty (2025). *Artificial intelligence in pharmacovigilance: advancing drug safety monitoring and regulatory integration*. ArXiv:10.1177/20420986251361435. [https://www.semanticscholar.org/paper/a68fc7e22744b00ddb5138e913559379ec4425f3](https://www.semanticscholar.org/paper/a68fc7e22744b00ddb5138e913559379ec4425f3)
22. <a id="ref-22"></a>Alberta Spreafico, Rosanna Tarricone, A. D. Stern (2025). *Comprehensive policies for scaling systemic and equitable integration of digital health technologies*. ArXiv:10.1038/s41746-025-01820-x. [https://www.semanticscholar.org/paper/4a21719c71df3de3840780e8a4faf65f55e87c95](https://www.semanticscholar.org/paper/4a21719c71df3de3840780e8a4faf65f55e87c95)
23. <a id="ref-23"></a>David Manne (2025). *AI-Driven Innovation: Transforming Healthcare Leadership and Patient Outcomes.*. ArXiv:10.3233/SHTI250674. [https://www.semanticscholar.org/paper/ff620f88ad97674460797c0d1b31f67738da07a1](https://www.semanticscholar.org/paper/ff620f88ad97674460797c0d1b31f67738da07a1)
24. <a id="ref-24"></a>B. Grant, Mattea L. Welch, Christopher Deutschman, Clare McElcheran, Adam Badzynski, Jennifer A.H. Bell, Andrew Hope, Robert C. Grant, Tran Truong, Kelly Lane, Patti Leake, Divya Sharma, Ian Stedman, M. Lovas, J. Petch, Muammar Kabir, Alejandro Berlin, James A. Anderson, Benjamin Haibe-Kains (2025). *Abstract PR-04: A practical framework for operationalizing responsible and equitable AI in healthcare: Tackling bias, inequity, and implementation challenges*. ArXiv:10.1158/1557-3265.aimachine-pr-04. [https://www.semanticscholar.org/paper/fa032c860536ffa063cb35b2ab95cdb587ab8cf4](https://www.semanticscholar.org/paper/fa032c860536ffa063cb35b2ab95cdb587ab8cf4)
25. <a id="ref-25"></a>Ala'a Alquayt, Ohoud A. Aljuhani, Abdullah F. Alharthi, Rahaf Alqahtani, Anas Khan, Ahmed Al-jedai, Abdulqader Almoeen, Mohammed Alshennawi, H. Badreldin, Abdulrhman Aljouie, Lubna A Alnasser, Abdulmajeed M. Alshehri, Mohammed Y Alzahrani, H. Alhaidal, Raghad Alhajaji, Salman Alotaibi, Esraa Z. Redhwan, Fahad Alharthi, Badr G Alghamdi, Khalid A. Al Sulaiman (2025). *AI-driven healthcare innovations for enhancing clinical services during mass gatherings (Hajj): task force insights and future directions*. ArXiv:10.1186/s12913-025-13045-5. [https://www.semanticscholar.org/paper/fee889513d77b444b82296e0f74d829ae25e2277](https://www.semanticscholar.org/paper/fee889513d77b444b82296e0f74d829ae25e2277)
26. <a id="ref-26"></a>Maurizio Cecconi, Massimiliano Greco, Benjamin Shickel, Derek C. Angus, Heatherlee Bailey, E. Bignami, Thierry Calandra, L. Celi, Sharon Einav, Paul Elbers, Ari Ercole, H. Gómez, Michelle Ng Gong, Matthieu Komorowski, Vincent Liu, Soojin Park, A. Sarwal, Christopher W. Seymour, F. Zampieri, F. Taccone, Jean-Louis Vincent, A. Bihorac (2025). *Implementing Artificial Intelligence in Critical Care Medicine: a consensus of 22*. ArXiv:10.1186/s13054-025-05532-2. [https://www.semanticscholar.org/paper/ba02770a0c94b564fc01a5a657208ca4ec28ff81](https://www.semanticscholar.org/paper/ba02770a0c94b564fc01a5a657208ca4ec28ff81)
27. <a id="ref-27"></a>Syed Raza Abbas, Huiseung Seol, Zeeshan Abbas, S. Lee (2025). *Exploring the Role of Artificial Intelligence in Smart Healthcare: A Capability and Function-Oriented Review*. ArXiv:10.3390/healthcare13141642. [https://www.semanticscholar.org/paper/a293ed770f1a90eb421e2ceecf58eec54e5b4619](https://www.semanticscholar.org/paper/a293ed770f1a90eb421e2ceecf58eec54e5b4619)
28. <a id="ref-28"></a>Roubing Tang, Sabina J. Sloman, Samuel Kaski (2025). *Generalization Analysis for Bayesian Optimal Experiment Design under Model Misspecification*. ArXiv:2506.07805v1. [https://arxiv.org/pdf/2506.07805v1](https://arxiv.org/pdf/2506.07805v1)
29. <a id="ref-29"></a>Divya Shyamal, Jiaqi Zhang, Caroline Uhler (2025). *Probabilistic Factorial Experimental Design for Combinatorial Interventions*. ArXiv:2506.03363v1. [https://arxiv.org/pdf/2506.03363v1](https://arxiv.org/pdf/2506.03363v1)
30. <a id="ref-30"></a>Guido Imbens, Chao Qin, Stefan Wager (2025). *Admissibility of Completely Randomized Trials: A Large-Deviation Approach*. ArXiv:2506.05329v1. [https://arxiv.org/pdf/2506.05329v1](https://arxiv.org/pdf/2506.05329v1)
31. <a id="ref-31"></a>Qining Zhang, Tanner Fiez, Yi Liu, Wenyang Liu (2025). *Multi-Metric Adaptive Experimental Design under Fixed Budget with Validation*. ArXiv:2506.03062v1. [https://arxiv.org/pdf/2506.03062v1](https://arxiv.org/pdf/2506.03062v1)
32. <a id="ref-32"></a>Otmane Sakhi, Alexandre Gilotte, David Rohde (2025). *Practical Improvements of A/B Testing with Off-Policy Estimation*. ArXiv:2506.10677v2. [https://arxiv.org/pdf/2506.10677v2](https://arxiv.org/pdf/2506.10677v2)
33. <a id="ref-33"></a>Yu Zhang, Shanshan Zhao, Bokui Wan, Jinjuan Wang, Xiaodong Yan (2025). *Strategic A/B testing via Maximum Probability-driven Two-armed Bandit*. ArXiv:2506.22536v1. [https://arxiv.org/pdf/2506.22536v1](https://arxiv.org/pdf/2506.22536v1)
34. <a id="ref-34"></a>Fengze Liu, Haoyu Wang, Joonhyuk Cho, Dan Roth, Andrew W. Lo (2025). *AUTOCT: Automating Interpretable Clinical Trial Prediction with LLM Agents*. ArXiv:2506.04293v1. [https://arxiv.org/pdf/2506.04293v1](https://arxiv.org/pdf/2506.04293v1)
35. <a id="ref-35"></a>Qihang Yan, Xinyu Zhang, Luming Guo, Qi Zhang, Feifan Liu (2025). *RACE-Align: Retrieval-Augmented and Chain-of-Thought Enhanced Preference Alignment for Large Language Models*. ArXiv:2506.02726v1. [https://arxiv.org/pdf/2506.02726v1](https://arxiv.org/pdf/2506.02726v1)
36. <a id="ref-36"></a>Yu Wang, Shiwan Zhao, Zhihu Wang, Ming Fan, Yubo Zhang, Xicheng Zhang, Zhengfan Wang, Heyuan Huang, Ting Liu (2025). *RAG+: Enhancing Retrieval-Augmented Generation with Application-Aware Reasoning*. ArXiv:2506.11555v3. [https://arxiv.org/pdf/2506.11555v3](https://arxiv.org/pdf/2506.11555v3)
37. <a id="ref-37"></a>Yu Han, Aaron Ceross, Jeroen H. M. Bergmann (2025). *Standard Applicability Judgment and Cross-jurisdictional Reasoning: A RAG-based Framework for Medical Device Compliance*. ArXiv:2506.18511v1. [https://arxiv.org/pdf/2506.18511v1](https://arxiv.org/pdf/2506.18511v1)
38. <a id="ref-38"></a>Yang Cai, Alkis Kalavasis, Katerina Mamali, Anay Mehrotra, Manolis Zampetakis (2025). *What Makes Treatment Effects Identifiable? Characterizations and Estimators Beyond Unconfoundedness*. ArXiv:2506.04194v2. [https://arxiv.org/pdf/2506.04194v2](https://arxiv.org/pdf/2506.04194v2)
39. <a id="ref-39"></a>Yuchen Ma, Dennis Frauen, Emil Javurek, Stefan Feuerriegel (2025). *Foundation Models for Causal Inference via Prior-Data Fitted Networks*. ArXiv:2506.10914v1. [https://arxiv.org/pdf/2506.10914v1](https://arxiv.org/pdf/2506.10914v1)
40. <a id="ref-40"></a>Vahid Balazadeh, Hamidreza Kamkari, Valentin Thomas, Benson Li, Junwei Ma, Jesse C. Cresswell, Rahul G. Krishnan (2025). *CausalPFN: Amortized Causal Effect Estimation via In-Context Learning*. ArXiv:10.48550/arXiv.2506.07918. [https://www.semanticscholar.org/paper/55586284afcecbd4e86f2a96b957be315a819b00](https://www.semanticscholar.org/paper/55586284afcecbd4e86f2a96b957be315a819b00)
41. <a id="ref-41"></a>Houssam Zenati, Bariscan Bozkurt, Arthur Gretton (2025). *Doubly-Robust Estimation of Counterfactual Policy Mean Embeddings*. ArXiv:2506.02793v1. [https://arxiv.org/pdf/2506.02793v1](https://arxiv.org/pdf/2506.02793v1)
42. <a id="ref-42"></a>Ahmed Aloui, Juncheng Dong, Ali Hasan, Vahid Tarokh (2025). *Conditional Average Treatment Effect Estimation Under Hidden Confounders*. ArXiv:2506.12304v1. [https://arxiv.org/pdf/2506.12304v1](https://arxiv.org/pdf/2506.12304v1)
43. <a id="ref-43"></a>Hao Yang, Haoxuan Li, Luyu Chen, Haoxiang Wang, Xu Chen, Mingming Gong (2025). *Mitigating Hidden Confounding by Progressive Confounder Imputation via Large Language Models*. ArXiv:2507.02928v1. [https://arxiv.org/pdf/2507.02928v1](https://arxiv.org/pdf/2507.02928v1)
44. <a id="ref-44"></a>Kosuke Imai, Kentaro Nakamura (2025). *GenAI-Powered Inference*. ArXiv:2507.03897. [https://www.semanticscholar.org/paper/ef1af4ab6c84c6fb2c3743611e1323d119dbb6d5](https://www.semanticscholar.org/paper/ef1af4ab6c84c6fb2c3743611e1323d119dbb6d5)
45. <a id="ref-45"></a>Yuchen Ma, Dennis Frauen, Jonas Schweisthal, Stefan Feuerriegel (2025). *LLM-Driven Treatment Effect Estimation Under Inference Time Text Confounding*. ArXiv:2507.02843. [https://www.semanticscholar.org/paper/56ab7019651449a908a3230990b292115944faf7](https://www.semanticscholar.org/paper/56ab7019651449a908a3230990b292115944faf7)
46. <a id="ref-46"></a>Rickmer Schulte, David Rügamer, Thomas Nagler (2025). *Adjustment for Confounding using Pre-Trained Representations*. ArXiv:2506.14329v1. [https://arxiv.org/pdf/2506.14329v1](https://arxiv.org/pdf/2506.14329v1)
47. <a id="ref-47"></a>Henri Arno, Thomas Demeester (2025). *Personalized Treatment Effect Estimation from Unstructured Data*. ArXiv:2507.20993. [https://www.semanticscholar.org/paper/72d19edcf6993ac8f817c7bf24eda6537428b660](https://www.semanticscholar.org/paper/72d19edcf6993ac8f817c7bf24eda6537428b660)
48. <a id="ref-48"></a>Shiangyi Lin, Hui Lan, Vasilis Syrgkanis (2025). *Learning Treatment Representations for Downstream Instrumental Variable Regression*. ArXiv:2506.02200v2. [https://arxiv.org/pdf/2506.02200v2](https://arxiv.org/pdf/2506.02200v2)
49. <a id="ref-49"></a>Yonghoon Lee, Mengxin Yu, Jiewen Liu, Chan Park, Yunshu Zhang, James M. Robins, E. Tchetgen (2025). *Inference on Nonlinear Counterfactual Functionals under a Multiplicative IV Model*. ArXiv:2507.15612. [https://www.semanticscholar.org/paper/5e2ffd395f83595aa069aba9323708a168ab66d4](https://www.semanticscholar.org/paper/5e2ffd395f83595aa069aba9323708a168ab66d4)
50. <a id="ref-50"></a>Jiewen Liu, Chan Park, Yonghoon Lee, Yunshu Zhang, Mengxin Yu, James M. Robins, E. Tchetgen (2025). *The Multiplicative Instrumental Variable Model*. ArXiv:2507.09302. [https://www.semanticscholar.org/paper/a66701eb43edbc2c4b88b59624b648e7f4439fbb](https://www.semanticscholar.org/paper/a66701eb43edbc2c4b88b59624b648e7f4439fbb)
51. <a id="ref-51"></a>Charles Shaw (2025). *Rethinking Distributional IVs: KAN-Powered D-IV-LATE&Model Choice*. ArXiv:2506.12765. [https://www.semanticscholar.org/paper/6bc2e42c6cc3868198a04ce89c97bd362a2936af](https://www.semanticscholar.org/paper/6bc2e42c6cc3868198a04ce89c97bd362a2936af)
52. <a id="ref-52"></a>Undral Byambadalai, Tomu Hirata, Tatsushi Oka, Shota Yasui (2025). *On Efficient Estimation of Distributional Treatment Effects under Covariate-Adaptive Randomization*. ArXiv:2506.05945v1. [https://arxiv.org/pdf/2506.05945v1](https://arxiv.org/pdf/2506.05945v1)
53. <a id="ref-53"></a>Yishan Shen, Yuyang Ye, Hui Xiong, Yong Chen (2025). *SAFER: A Calibrated Risk-Aware Multimodal Recommendation Model for Dynamic Treatment Regimes*. ArXiv:2506.06649v1. [https://arxiv.org/pdf/2506.06649v1](https://arxiv.org/pdf/2506.06649v1)
54. <a id="ref-54"></a>Ruijia Zhang, Zhengling Qi, Yue Wu, Xiangyu Zhang, Yanxun Xu (2025). *POLAR: A Pessimistic Model-based Policy Learning Algorithm for Dynamic Treatment Regimes*. ArXiv:2506.20406v1. [https://arxiv.org/pdf/2506.20406v1](https://arxiv.org/pdf/2506.20406v1)
55. <a id="ref-55"></a>Zequn Jin, Gaoqian Xu, Zheng Xi, Yahong Zhou (2025). *Policy Learning under Unobserved Confounding: A Robust and Efficient Approach*. ArXiv:2507.20550. [https://www.semanticscholar.org/paper/4140c13fac569bb58bebfbc5523988f49565422b](https://www.semanticscholar.org/paper/4140c13fac569bb58bebfbc5523988f49565422b)
56. <a id="ref-56"></a>Shrestha Ghosh, Moritz Schneider, Carina Reinicke, Carsten Eickhoff (2025). *Cohort Discovery: A Survey on LLM-Assisted Clinical Trial Recruitment*. ArXiv:2506.15301v1. [https://arxiv.org/pdf/2506.15301v1](https://arxiv.org/pdf/2506.15301v1)
57. <a id="ref-57"></a>Dongchen Li, Jitao Liang, Wei Li, Xiaoyu Wang, Longbing Cao, Kunming University of Science, Engineering, Northeastern University, Shenyang, China, Liaoning Cancer Hospital, Institute, M. University, Sydney, Australia, College of Medicine, Biological Engineering (2025). *CliCARE: Grounding Large Language Models in Clinical Guidelines for Decision Support over Longitudinal Cancer Electronic Health Records*. ArXiv:2507.22533. [https://www.semanticscholar.org/paper/bf6133cf06d9649d71abf94d21090e798b549b4e](https://www.semanticscholar.org/paper/bf6133cf06d9649d71abf94d21090e798b549b4e)
58. <a id="ref-58"></a>Junke Wang, Hongshun Ling, Li Zhang, Longqian Zhang, Fang Wang, Yuan Gao, Zhi Li (2025). *CKD-EHR:Clinical Knowledge Distillation for Electronic Health Records*. ArXiv:10.48550/arXiv.2506.15118. [https://www.semanticscholar.org/paper/ac5402b001e844915775d70b01ef14396ac548db](https://www.semanticscholar.org/paper/ac5402b001e844915775d70b01ef14396ac548db)
59. <a id="ref-59"></a>Yuanyuan Zheng, Adel Bensahla, Mina Bjelogrlic, Jamil Zaghir, Hugues Turbé, Bednarczyk Lydie, C. Gaudet-Blavignac, Julien Ehrsam, Stéphane Marchand-Maillet, Christian Lovis (2025). *A scoping review of self-supervised representation learning for clinical decision making using EHR categorical data*. ArXiv:10.1038/s41746-025-01692-1. [https://www.semanticscholar.org/paper/0a30acfbf3d02ad238b4fd7d012c460161c24f33](https://www.semanticscholar.org/paper/0a30acfbf3d02ad238b4fd7d012c460161c24f33)
60. <a id="ref-60"></a>P. Jadhav (2025). *Cohort Retrieval using Dense Passage Retrieval*. ArXiv:2507.01049. [https://www.semanticscholar.org/paper/eb9a23543c60eae3fd2c000aeeb1fdd4110bafcc](https://www.semanticscholar.org/paper/eb9a23543c60eae3fd2c000aeeb1fdd4110bafcc)
61. <a id="ref-61"></a>Joydeb Kumar Sana, Mohammad M. Masud, M Sohel Rahman, M Saifur Rahman (2025). *Patient Similarity Computation for Clinical Decision Support: An Efficient Use of Data Transformation, Combining Static and Time Series Data*. ArXiv:2506.07092v1. [https://arxiv.org/pdf/2506.07092v1](https://arxiv.org/pdf/2506.07092v1)
62. <a id="ref-62"></a>Dimitrios Proios, Alban Bornet, Anthony Yazdani, Jose F Rodrigues Jr, Douglas Teodoro (2025). *ICU-TSB: A Benchmark for Temporal Patient Representation Learning for Unsupervised Stratification into Patient Cohorts*. ArXiv:2506.06192v1. [https://arxiv.org/pdf/2506.06192v1](https://arxiv.org/pdf/2506.06192v1)
63. <a id="ref-63"></a>Junhan Yu, Zhunyi Feng, Junwei Lu, Tianxi Cai, Doudou Zhou (2025). *Time-Aware Attention for Enhanced Electronic Health Records Modeling*. ArXiv:2507.14847. [https://www.semanticscholar.org/paper/07efe241f0727684c31c670f015381427bab9916](https://www.semanticscholar.org/paper/07efe241f0727684c31c670f015381427bab9916)
64. <a id="ref-64"></a>Mohammad Ahmad Al Olaimat (N/A). *Modeling Electronic Health Records: Interpretable Sequential Approaches for Enhanced Multimodal Embeddings and Future Clinical Outcome Prediction with Time-Aware Irregular Intervals Handling*. ArXiv:10.12794/metadc2443349. [https://www.semanticscholar.org/paper/8c2f437f41e591fa790230b04c889f3f927e657b](https://www.semanticscholar.org/paper/8c2f437f41e591fa790230b04c889f3f927e657b)
65. <a id="ref-65"></a>Shaojie Zhong, Li Rong Wang, Zhuoxuan Zhan, Y. Ng, Xiuyi Fan (2025). *A Hybrid Approach for Irregular-Time Series Prediction using Electronic Health Records: an Intensive Care Unit Mortality Case Study*. ArXiv:10.1145/3743689. [https://www.semanticscholar.org/paper/58cd1dc7c95a9d367b822b5e533728b5e25e6bff](https://www.semanticscholar.org/paper/58cd1dc7c95a9d367b822b5e533728b5e25e6bff)
66. <a id="ref-66"></a>Deyi Li, Zijun Yao, Muxuan Liang, Mei Liu (2025). *DeepJ: Graph Convolutional Transformers with Differentiable Pooling for Patient Trajectory Modeling*. ArXiv:10.48550/arXiv.2506.15809. [https://www.semanticscholar.org/paper/971fb74b2435cafa31f9ea3d609a26c599958af0](https://www.semanticscholar.org/paper/971fb74b2435cafa31f9ea3d609a26c599958af0)
67. <a id="ref-67"></a>Pengfei Hu, Xiaoxue Han, Fei Wang, Yue Ning (2025). *UdonCare: Hierarchy Pruning for Unseen Domain Discovery in Predictive Healthcare*. ArXiv:2506.06977v1. [https://arxiv.org/pdf/2506.06977v1](https://arxiv.org/pdf/2506.06977v1)
68. <a id="ref-68"></a>Pratik Worah (2025). *A Goemans-Williamson type algorithm for identifying subcohorts in clinical trials*. ArXiv:2506.10879v1. [https://arxiv.org/pdf/2506.10879v1](https://arxiv.org/pdf/2506.10879v1)
69. <a id="ref-69"></a>Roland Roller, Michael Hahn, Ajay Madhavan Ravichandran, Bilgin Osmanodja, Florian Oetke, Zeineb Sassi, Aljoscha Burchardt, Klaus Netter, Klemens Budde, Anne Herrmann, Tobias Strapatsas, Peter Dabrock, Sebastian Möller (2025). *One Size Fits None: Rethinking Fairness in Medical AI*. ArXiv:2506.14400v1. [https://arxiv.org/pdf/2506.14400v1](https://arxiv.org/pdf/2506.14400v1)
70. <a id="ref-70"></a>Benjamin Smith, Jianhui Gao, Jessica Gronsbell (2025). *fairmetrics: An R package for group fairness evaluation*. ArXiv:2506.06243v2. [https://arxiv.org/pdf/2506.06243v2](https://arxiv.org/pdf/2506.06243v2)
71. <a id="ref-71"></a>Andrés Morales-Forero, Lili J. Rueda, Ronald Herrera, Samuel Bassetto, Eric Coatanea Polytechnique Montr'eal, Universidad El Bosque, Boehringer Ingelheim International GmbH, Tampere University (2025). *Predictive Representativity: Uncovering Racial Bias in AI-based Skin Cancer Detection*. ArXiv:2507.14176. [https://www.semanticscholar.org/paper/bed85642c221d76c7008f626a258ac9b92bcba00](https://www.semanticscholar.org/paper/bed85642c221d76c7008f626a258ac9b92bcba00)
72. <a id="ref-72"></a>Nitish Nagesh, Ziyu Wang, Amir M. Rahmani (2025). *FairCauseSyn: Towards Causally Fair LLM-Augmented Synthetic Data Generation*. ArXiv:2506.19082v1. [https://arxiv.org/pdf/2506.19082v1](https://arxiv.org/pdf/2506.19082v1)
73. <a id="ref-73"></a>Jake Robertson, Noah Hollmann, Samuel G. Müller, Noor Awad, Frank Hutter (2025). *FairPFN: A Tabular Foundation Model for Causal Fairness*. ArXiv:10.48550/arXiv.2506.07049. [https://www.semanticscholar.org/paper/52bcf71cbba982b7a449f7b4695fe60cde1ae8dd](https://www.semanticscholar.org/paper/52bcf71cbba982b7a449f7b4695fe60cde1ae8dd)
74. <a id="ref-74"></a>Modar Sulaiman, Kallol Roy (2025). *GFLC: Graph-based Fairness-aware Label Correction for Fair Classification*. ArXiv:10.48550/arXiv.2506.15620. [https://www.semanticscholar.org/paper/4ea471f2a0f661c4e2e1e09776dbb8239b2472b2](https://www.semanticscholar.org/paper/4ea471f2a0f661c4e2e1e09776dbb8239b2472b2)
75. <a id="ref-75"></a>Jiaojiao Meng, Moxin Wu, Fangmin Shi, Ying Xie, Hui Wang, You Guo (2025). *Medical laboratory data-based models: opportunities, obstacles, and solutions*. ArXiv:10.1186/s12967-025-06802-x. [https://www.semanticscholar.org/paper/4ffc6d42418a0cabb1e8bd5bf387703f5edce110](https://www.semanticscholar.org/paper/4ffc6d42418a0cabb1e8bd5bf387703f5edce110)
76. <a id="ref-76"></a>Yuchen Ma, Jonas Schweisthal, Hengrui Zhang, Stefan Feuerriegel (2025). *A Diffusion-Based Method for Learning the Multi-Outcome Distribution of Medical Treatments*. ArXiv:2506.01533v1. [https://arxiv.org/pdf/2506.01533v1](https://arxiv.org/pdf/2506.01533v1)
77. <a id="ref-77"></a>Christian Marius Lillelund, Sanjay Kalra, Russell Greiner (2025). *A meaningful prediction of functional decline in amyotrophic lateral sclerosis based on multi-event survival analysis*. ArXiv:2506.02076v1. [https://arxiv.org/pdf/2506.02076v1](https://arxiv.org/pdf/2506.02076v1)
78. <a id="ref-78"></a>Andrei V. Konstantinov, Vlada A. Efremenko, Lev V. Utkin (2025). *Survival Analysis as Imprecise Classification with Trainable Kernels*. ArXiv:2506.10140v1. [https://arxiv.org/pdf/2506.10140v1](https://arxiv.org/pdf/2506.10140v1)
79. <a id="ref-79"></a>Paul Minchella, L. Verlingue, St'ephane Chr'etien, R'emi Vaucher, Guillaume Metzler (2025). *SigBERT: Combining Narrative Medical Reports and Rough Path Signature Theory for Survival Risk Estimation in Oncology*. ArXiv:2507.22941. [https://www.semanticscholar.org/paper/4f0bcaef9489b90dfb2b9f1fbd1ae3540b686e4d](https://www.semanticscholar.org/paper/4f0bcaef9489b90dfb2b9f1fbd1ae3540b686e4d)
80. <a id="ref-80"></a>A. Tripathi, A. Waqas, M. Schabath, Y. Yilmaz, G. Rasool (2025). *EAGLE: Efficient Alignment of Generalized Latent Embeddings for Multimodal Survival Prediction with Interpretable Attribution Analysis*. ArXiv:10.48550/arXiv.2506.22446. [https://www.semanticscholar.org/paper/d6bad0d72df384a52231c0a4e0834ad9fde49008](https://www.semanticscholar.org/paper/d6bad0d72df384a52231c0a4e0834ad9fde49008)
81. <a id="ref-81"></a>Chantal Pellegrini, Ege Özsoy, David Bani-Harouni, Matthias Keicher, Nassir Navab (2025). *From EHRs to Patient Pathways: Scalable Modeling of Longitudinal Health Trajectories with LLMs*. ArXiv:2506.04831v1. [https://arxiv.org/pdf/2506.04831v1](https://arxiv.org/pdf/2506.04831v1)
82. <a id="ref-82"></a>H. Rajamohan, Xiang Gao, Weicheng Zhu, Shih-Lun Huang, Long Chen, K. Cho, Cem M. Deniz, Narges Razavian (2025). *Foundation Models for Clinical Records at Health System Scale*. ArXiv:2507.00574. [https://www.semanticscholar.org/paper/3e9425a41a0bae97d222ef560c9c8ccec47121b7](https://www.semanticscholar.org/paper/3e9425a41a0bae97d222ef560c9c8ccec47121b7)
83. <a id="ref-83"></a>Hao Li, Bowen Deng, Chang Xu, Zhiyuan Feng, Viktor Schlegel, Yu-Hao Huang, Yizheng Sun, Jingyuan Sun, Kailai Yang, Yiyao Yu, Jiang Bian (2025). *MIRA: Medical Time Series Foundation Model for Real-World Health Data*. ArXiv:10.48550/arXiv.2506.07584. [https://www.semanticscholar.org/paper/d64d108fd7fae6535543de8029bc0e40a02526ea](https://www.semanticscholar.org/paper/d64d108fd7fae6535543de8029bc0e40a02526ea)
84. <a id="ref-84"></a>YongKyung Oh, Alex Bui (2025). *Multi-View Contrastive Learning for Robust Domain Adaptation in Medical Time Series Analysis*. ArXiv:10.48550/arXiv.2506.22393. [https://www.semanticscholar.org/paper/76a81acbc41ca05faee964374880a10bbb3b492c](https://www.semanticscholar.org/paper/76a81acbc41ca05faee964374880a10bbb3b492c)
85. <a id="ref-85"></a>Yuwei Zhang, Kumar Ayush, Siyuan Qiao, A. Ali Heydari, Girish Narayanswamy, Maxwell A. Xu, Ahmed A. Metwally, Shawn Xu, Jake Garrison, Xuhai Xu, Tim Althoff, Yun Liu, Pushmeet Kohli, Jiening Zhan, Mark Malhotra, Shwetak Patel, Cecilia Mascolo, Xin Liu, Daniel McDuff, Yuzhe Yang (2025). *SensorLM: Learning the Language of Wearable Sensors*. ArXiv:2506.09108v1. [https://arxiv.org/pdf/2506.09108v1](https://arxiv.org/pdf/2506.09108v1)
86. <a id="ref-86"></a>Xiangze Teng, Xiang Li, Benzheng Wei (2025). *ModFus-PD: synergizing cross-modal attention and contrastive learning for enhanced multimodal diagnosis of Parkinson’s disease*. ArXiv:10.3389/fncom.2025.1604399. [https://www.semanticscholar.org/paper/b766152f37983cc7723d09463fa3edfd1775917e](https://www.semanticscholar.org/paper/b766152f37983cc7723d09463fa3edfd1775917e)
87. <a id="ref-87"></a>Yuanyuan Yi, Lei Shi, Haoran Liu, Mingyu Wang, Min Feng, Yanxia Li (2025). *COPD-MMDDxNet: a multimodal deep learning framework for accurate COPD diagnosis using electronic medical records*. ArXiv:10.3389/fmed.2025.1601736. [https://www.semanticscholar.org/paper/68d94ff61726cbde4c72f002ddde29334276c81e](https://www.semanticscholar.org/paper/68d94ff61726cbde4c72f002ddde29334276c81e)
88. <a id="ref-88"></a>Xiao Gu, Wei Tang, Jinpei Han, Veer Sangha, Fenglin Liu, Shreyank N Gowda, Antonio H. Ribeiro, Patrick Schwab, Kim Branson, Lei Clifton, Antonio Luiz P. Ribeiro, Zhangdaihong Liu, David A. Clifton (2025). *Sensing Cardiac Health Across Scenarios and Devices: A Multi-Modal Foundation Model Pretrained on Heterogeneous Data from 1.7 Million Individuals*. ArXiv:2507.01045v1. [https://arxiv.org/pdf/2507.01045v1](https://arxiv.org/pdf/2507.01045v1)
89. <a id="ref-89"></a>Franck Meyer, Kyunghoon Hur, Edward Choi (2025). *MD-ViSCo: A Unified Model for Multi-Directional Vital Sign Waveform Conversion*. ArXiv:2506.08357v1. [https://arxiv.org/pdf/2506.08357v1](https://arxiv.org/pdf/2506.08357v1)
90. <a id="ref-90"></a>Hao Peng, Steve Jiang, Robert Timmerman (2025). *Exploring Strategies for Personalized Radiation Therapy Part II Predicting Tumor Drift Patterns with Diffusion Models*. ArXiv:2506.17491v1. [https://arxiv.org/pdf/2506.17491v1](https://arxiv.org/pdf/2506.17491v1)
91. <a id="ref-91"></a>Shuaitong Zhang, Yuchen Sun, Yong Ao, Xuehuan Zhang, Ruoshui Yang, Jiantao Xu, Zuwu Ai, Haike Zhang, Xiang Yang, Yao Xu, Kunwei Li, Duanduan Chen (2025). *GLOMIA-Pro: A Generalizable Longitudinal Medical Image Analysis Framework for Disease Progression Prediction*. ArXiv:2507.12500. [https://www.semanticscholar.org/paper/d8c3773a69f00f599b90de32a9a77509ac333137](https://www.semanticscholar.org/paper/d8c3773a69f00f599b90de32a9a77509ac333137)
92. <a id="ref-92"></a>Nadine Garibli, Mayank Patwari, Bence Csiba, Yi Wei, Kostas Sidiropoulos (2025). *LinGuinE: Longitudinal Guidance Estimation for Volumetric Lung Tumour Segmentation*. ArXiv:2506.06092v1. [https://arxiv.org/pdf/2506.06092v1](https://arxiv.org/pdf/2506.06092v1)
93. <a id="ref-93"></a>Markus Gambietz, Eva Dorschky, Altan Akat, Marcel Schöckel, Jörg Miehling, Anne D. Koelewijn (2025). *SSPINNpose: A Self-Supervised PINN for Inertial Pose and Dynamics Estimation*. ArXiv:2506.11786v1. [https://arxiv.org/pdf/2506.11786v1](https://arxiv.org/pdf/2506.11786v1)
94. <a id="ref-94"></a>Andreas Spilz, Heiko Oppel, Jochen Werner, Kathrin Stucke-Straub, Felix Capanni, Michael Munz (2025). *GAITEX: Human motion dataset from impaired gait and rehabilitation exercises of inertial and optical sensor data*. ArXiv:2507.21069v1. [https://arxiv.org/pdf/2507.21069v1](https://arxiv.org/pdf/2507.21069v1)
95. <a id="ref-95"></a>Yuan Bian, Xingche Guo, Yuanjia Wang (2025). *Joint modeling for learning decision-making dynamics in behavioral experiments*. ArXiv:2506.02394v2. [https://arxiv.org/pdf/2506.02394v2](https://arxiv.org/pdf/2506.02394v2)
96. <a id="ref-96"></a>Shashank Yadav, Vignesh Subbian (2025). *Failure Modes of Time Series Interpretability Algorithms for Critical Care Applications and Potential Solutions*. ArXiv:2506.19035v1. [https://arxiv.org/pdf/2506.19035v1](https://arxiv.org/pdf/2506.19035v1)
97. <a id="ref-97"></a>Xin Zhang, Qiyu Wei, Yingjie Zhu, Fanyi Wu, Sophia Ananiadou (2025). *THCM-CAL: Temporal-Hierarchical Causal Modelling with Conformal Calibration for Clinical Risk Prediction*. ArXiv:2506.17844v1. [https://arxiv.org/pdf/2506.17844v1](https://arxiv.org/pdf/2506.17844v1)
98. <a id="ref-98"></a>Daolang Huang, Xinyi Wen, Ayush Bharti, Samuel Kaski, Luigi Acerbi (2025). *ALINE: Joint Amortization for Bayesian Inference and Active Data Acquisition*. ArXiv:2506.07259v1. [https://arxiv.org/pdf/2506.07259v1](https://arxiv.org/pdf/2506.07259v1)
99. <a id="ref-99"></a>Ching Chang, Jeehyun Hwang, Yidan Shi, Haixin Wang, Wen-Chih Peng, Tien-Fu Chen, Wei Wang (2025). *Time-IMM: A Dataset and Benchmark for Irregular Multimodal Multivariate Time Series*. ArXiv:10.48550/arXiv.2506.10412. [https://www.semanticscholar.org/paper/e1ed1134a97ac0cbba8f49c1f4fff1b03936f5fa](https://www.semanticscholar.org/paper/e1ed1134a97ac0cbba8f49c1f4fff1b03936f5fa)
100. <a id="ref-100"></a>Zhongying Wang, Thoai D. Ngo, Hamidreza Zoraghein, Benjamin Lucas, Morteza Karimzadeh (2025). *Integrating Spatiotemporal Features in LSTM for Spatially Informed COVID-19 Hospitalization Forecasting*. ArXiv:2506.05752v2. [https://arxiv.org/pdf/2506.05752v2](https://arxiv.org/pdf/2506.05752v2)
101. <a id="ref-101"></a>Cheng Wang, Yu Jiang, Zhihao Peng, Chenxin Li, Changbae Bang, Lin Zhao, Jinglei Lv, Jorge Sepulcre, Carl Yang, Lifang He, Tianming Liu, Daniel Barron, Quanzheng Li, Randy Hirschtick, Byung-Hoon Kim, Xiang Li, Yixuan Yuan (2025). *Towards a general-purpose foundation model for fMRI analysis*. ArXiv:2506.11167v1. [https://arxiv.org/pdf/2506.11167v1](https://arxiv.org/pdf/2506.11167v1)
102. <a id="ref-102"></a>Rémi Vaucher, Stéphane Chrétien (2025). *Detecting malignant dynamics on very few blood sample using signature coefficients*. ArXiv:2506.09097v1. [https://arxiv.org/pdf/2506.09097v1](https://arxiv.org/pdf/2506.09097v1)
103. <a id="ref-103"></a>Nikos Spyrou, Athanasios Vlontzos, Paraskevas Pegios, Thomas Melistas, Nefeli Gkouti, Yannis Panagakis, Giorgos Papanastasiou, Sotirios A. Tsaftaris (2025). *Causally Steered Diffusion for Automated Video Counterfactual Generation*. ArXiv:2506.14404v1. [https://arxiv.org/pdf/2506.14404v1](https://arxiv.org/pdf/2506.14404v1)
104. <a id="ref-104"></a>Siyi Sun, David Antony Selby, Yunchuan Huang, Sebastian Vollmer, Seth Flaxman, Anisoara Calinescu (2025). *IMAGIC-500: IMputation benchmark on A Generative Imaginary Country (500k samples)*. ArXiv:2506.08844v1. [https://arxiv.org/pdf/2506.08844v1](https://arxiv.org/pdf/2506.08844v1)
105. <a id="ref-105"></a>Jianbin Tan, Yan Zhang, Chuan Hong, T. Tony Cai, Tianxi Cai, Anru R. Zhang (2025). *Integrated Analysis for Electronic Health Records with Structured and Sporadic Missingness*. ArXiv:2506.09208v1. [https://arxiv.org/pdf/2506.09208v1](https://arxiv.org/pdf/2506.09208v1)
106. <a id="ref-106"></a>Ji-Hoon Lee, Minseo Kang, Dongha Kim (2025). *MIRRAMS: Towards Training Models Robust to Missingness Distribution Shifts*. ArXiv:2507.08280. [https://www.semanticscholar.org/paper/35eb794d36670800184d0e47a9694fa8ff4b2540](https://www.semanticscholar.org/paper/35eb794d36670800184d0e47a9694fa8ff4b2540)
107. <a id="ref-107"></a>*Cross-Domain Time Series Imputation with Conditional Diffusion Models*. ArXiv:2506.12412. [https://arxiv.org/abs/2506.12412](https://arxiv.org/abs/2506.12412)
108. <a id="ref-108"></a>Ching Chang, Jeehyun Hwang, Yidan Shi, Haixin Wang, Wen-Chih Peng, Tien-Fu Chen, Wei Wang (2025). *Time-IMM: A Dataset and Benchmark for Irregular Multimodal Multivariate Time Series*. ArXiv:2506.10412v2. [https://arxiv.org/pdf/2506.10412v2](https://arxiv.org/pdf/2506.10412v2)
109. <a id="ref-109"></a>Jialin Chen, Ziyu Zhao, Gaukhar Nurbek, Aosong Feng, Ali Maatouk, Leandros Tassiulas, Yifeng Gao, Rex Ying (2025). *TRACE: Grounding Time Series in Context for Multimodal Embedding and Retrieval*. ArXiv:2506.09114v1. [https://arxiv.org/pdf/2506.09114v1](https://arxiv.org/pdf/2506.09114v1)
110. <a id="ref-110"></a>Howon Ryu, Yuliang Chen, Yacun Wang, Andrea Z. LaCroix, Chongzhi Di, Loki Natarajan, Yu Wang, Jingjing Zou (2025). *MoCA: Multi-modal Cross-masked Autoencoder for Digital Health Measurements*. ArXiv:2506.02260v1. [https://arxiv.org/pdf/2506.02260v1](https://arxiv.org/pdf/2506.02260v1)
111. <a id="ref-111"></a>*ITFormer: Bridging Time-Series Encoders and Frozen LLMs for Multi-modal QA*. ArXiv:2506.20093. [https://arxiv.org/abs/2506.20093](https://arxiv.org/abs/2506.20093)
112. <a id="ref-112"></a>*Multi-View Contrastive Learning for Robust Domain Adaptation in Medical Time Series Analysis*. ArXiv:2506.22393. [https://arxiv.org/abs/2506.22393](https://arxiv.org/abs/2506.22393)
113. <a id="ref-113"></a>*MIRA: Medical Time Series Foundation Model for Real-World Health Data*. ArXiv:2506.07584. [https://arxiv.org/abs/2506.07584](https://arxiv.org/abs/2506.07584)
114. <a id="ref-114"></a>Yuji Kawamata, Kaoru Kamijo, Masateru Kihira, Akihiro Toyoda, Tomoru Nakayama, Akira Imakura, Tetsuya Sakurai, Yukihiko Okada (2025). *A new type of federated clustering: A non-model-sharing approach*. ArXiv:2506.10244v2. [https://arxiv.org/pdf/2506.10244v2](https://arxiv.org/pdf/2506.10244v2)
115. <a id="ref-115"></a>Yuping Yan, Yizhi Wang, Yuanshuai Li, Yaochu Jin (2025). *TriCon-SF: A Triple-Shuffle and Contribution-Aware Serial Federated Learning Framework for Heterogeneous Healthcare Data*. ArXiv:2506.16723v1. [https://arxiv.org/pdf/2506.16723v1](https://arxiv.org/pdf/2506.16723v1)
116. <a id="ref-116"></a>Md. Kamrul Hossain, Walid Aljoby, Anis Elgabli, Ahmed M. Abdelmoniem, Khaled A. Harras (2025). *AdRo-FL: Informed and Secure Client Selection for Federated Learning in the Presence of Adversarial Aggregator*. ArXiv:2506.17805v2. [https://arxiv.org/pdf/2506.17805v2](https://arxiv.org/pdf/2506.17805v2)
117. <a id="ref-117"></a>*ShiftEx: A Continual Federated Learning Framework with Mixture of Experts for Tackling Data Shifts*. ArXiv:2506.18789. [https://arxiv.org/abs/2506.18789](https://arxiv.org/abs/2506.18789)
118. <a id="ref-118"></a>*UniVarFL: A Unified Framework for Variance-Regularized Federated Learning on Non-IID Data*. ArXiv:2506.08167. [https://arxiv.org/abs/2506.08167](https://arxiv.org/abs/2506.08167)
119. <a id="ref-119"></a>Zehui Zhao, Laith Alzubaidi, Haider A.Alwzwazy, Jinglan Zhang, Yuantong Gu (2025). *VGS-ATD: Robust Distributed Learning for Multi-Label Medical Image Classification Under Heterogeneous and Imbalanced Conditions*. ArXiv:2507.18657. [https://www.semanticscholar.org/paper/37f8dc06249c67a4766d7e0f974c29e50772d1c7](https://www.semanticscholar.org/paper/37f8dc06249c67a4766d7e0f974c29e50772d1c7)
120. <a id="ref-120"></a>Yan Gao, Massimo Roberto Scamarcia, Javier Fernandez-Marques, Mohammad Naseri, Chong Shen Ng, Dimitris Stripelis, Zexi Li, Tao Shen, Jiamu Bai, Daoyuan Chen, Zikai Zhang, Rui Hu, InSeo Song, Lee KangYoon, Hong Jia, Ting Dang, Junyan Wang, Zheyuan Liu, Daniel Janes Beutel, Lingjuan Lyu, Nicholas D. Lane (2025). *FlowerTune: A Cross-Domain Benchmark for Federated Fine-Tuning of Large Language Models*. ArXiv:2506.02961v1. [https://arxiv.org/pdf/2506.02961v1](https://arxiv.org/pdf/2506.02961v1)
121. <a id="ref-121"></a>Amir Faiyaz, Tara Salman (2025). *GradualDiff-Fed: A Federated Learning Specialized Framework for Large Language Model*. ArXiv:2506.19164v1. [https://arxiv.org/pdf/2506.19164v1](https://arxiv.org/pdf/2506.19164v1)
122. <a id="ref-122"></a>Pengrun Huang, Chhavi Yadav, Ruihan Wu, Kamalika Chaudhuri (2025). *Can We Infer Confidential Properties of Training Data from LLMs?*. ArXiv:2506.10364v2. [https://arxiv.org/pdf/2506.10364v2](https://arxiv.org/pdf/2506.10364v2)
123. <a id="ref-123"></a>Delong Ran, Xinlei He, Tianshuo Cong, Anyu Wang, Qi Li, Xiaoyun Wang (2025). *LoRA-Leak: Membership Inference Attacks Against LoRA Fine-tuned Language Models*. ArXiv:2507.18302. [https://www.semanticscholar.org/paper/c8ec0dd4fdc569d9f4fd984c637d841b4b1e3704](https://www.semanticscholar.org/paper/c8ec0dd4fdc569d9f4fd984c637d841b4b1e3704)
124. <a id="ref-124"></a>Anming Gu, Edward Chien, Kristjan Greenewald (2025). *Private Continuous-Time Synthetic Trajectory Generation via Mean-Field Langevin Dynamics*. ArXiv:2506.12203v1. [https://arxiv.org/pdf/2506.12203v1](https://arxiv.org/pdf/2506.12203v1)
125. <a id="ref-125"></a>Zhi Wen Soi, Chaoyi Zhu, Fouad Abiad, Aditya Shankar, Jeroen M. Galjaard, Huijuan Wang, Lydia Y. Chen (2025). *TimeWak: Temporal Chained-Hashing Watermark for Time Series Data*. ArXiv:2506.06407v2. [https://arxiv.org/pdf/2506.06407v2](https://arxiv.org/pdf/2506.06407v2)
126. <a id="ref-126"></a>Francesco Di Salvo, Hanh Huyen My Nguyen, Christian Ledig (2025). *Embedding-Based Federated Data Sharing via Differentially Private Conditional VAEs*. ArXiv:2507.02671. [https://www.semanticscholar.org/paper/1658dc08f7049c3010545a971903397d917b8acf](https://www.semanticscholar.org/paper/1658dc08f7049c3010545a971903397d917b8acf)
127. <a id="ref-127"></a>*Federated Timeline Synthesis: A Generative Foundation Model for EHR*. ArXiv:2506.23358. [https://arxiv.org/abs/2506.23358](https://arxiv.org/abs/2506.23358)
128. <a id="ref-128"></a>Eunbyeol Cho, Jiyoun Kim, M. Lee, Sungjin Park, Edward Choi (2025). *Generating Multi-Table Time Series EHR from Latent Space with Minimal Preprocessing*. ArXiv:2507.06996. [https://www.semanticscholar.org/paper/36201ec9b9c77e7206c57642471ca67495ae6a6d](https://www.semanticscholar.org/paper/36201ec9b9c77e7206c57642471ca67495ae6a6d)
129. <a id="ref-129"></a>*A Survey of Synthetic Image Generation*. ArXiv:2506.19360. [https://arxiv.org/abs/2506.19360](https://arxiv.org/abs/2506.19360)
130. <a id="ref-130"></a>Ivona Krchova, Mariana Vargas Vieyra, Mario Scriminaci, Andrey Sidorenko (2025). *Democratizing Tabular Data Access with an Open$\\unicode{x2013}$Source Synthetic$\\unicode{x2013}$Data SDK*. ArXiv:2508.00718. [https://www.semanticscholar.org/paper/4cbe8dc5d7d9397f681aad2a0b67063fbbfdf61d](https://www.semanticscholar.org/paper/4cbe8dc5d7d9397f681aad2a0b67063fbbfdf61d)
131. <a id="ref-131"></a>Zhiwei Li, Carl Kesselman, Tran Huy Nguyen, Benjamin Yixing Xu, Kyle Bolo, Kimberley Yu (2025). *From Data to Decision: Data-Centric Infrastructure for Reproducible ML in Collaborative eScience*. ArXiv:2506.16051v1. [https://arxiv.org/pdf/2506.16051v1](https://arxiv.org/pdf/2506.16051v1)
132. <a id="ref-132"></a>Daniel Angelo Esteves Lawand, Lucas Quaresma Medina Lam, Roberto Oliveira Bolgheroni, Renato Cordeiro Ferreira, Alfredo Goldman, Marcelo Finger (2025). *Making a Pipeline Production-Ready: Challenges and Lessons Learned in the Healthcare Domain*. ArXiv:2506.06946v3. [https://arxiv.org/pdf/2506.06946v3](https://arxiv.org/pdf/2506.06946v3)
133. <a id="ref-133"></a>Soorya Ram Shimgekar, Shayan Vassef, Abhay Goyal, Navin Kumar, Koustuv Saha (2025). *Agentic AI framework for End-to-End Medical Data Inference*. ArXiv:2507.18115. [https://www.semanticscholar.org/paper/e7fc63427f98598db897c6d5384f831f60b84b0c](https://www.semanticscholar.org/paper/e7fc63427f98598db897c6d5384f831f60b84b0c)
134. <a id="ref-134"></a>Melissa Estevez, Nisha Singh, Lauren Dyson, Blythe Adamson, Qianyu Yuan, Megan W. Hildner, Erin Fidyk, Olive Mbah, Farhad Khan, Kathi Seidl-Rathkopf, Aaron B. Cohen (2025). *Ensuring Reliability of Curated EHR-Derived Data: The Validation of Accuracy for LLM/ML-Extracted Information and Data (VALID) Framework*. ArXiv:2506.08231v1. [https://arxiv.org/pdf/2506.08231v1](https://arxiv.org/pdf/2506.08231v1)
135. <a id="ref-135"></a>Viet Nguyen, Changjian Shui, Vijay Giri, Siddarth Arya, Amol Verma, Fahad Razak, Rahul G. Krishnan (2025). *Reliably detecting model failures in deployment without labels*. ArXiv:2506.05047v2. [https://arxiv.org/pdf/2506.05047v2](https://arxiv.org/pdf/2506.05047v2)
136. <a id="ref-136"></a>Pavel Dolin, Weizhi Li, Gautam Dasarathy, Visar Berisha (2025). *Statistically Valid Post-Deployment Monitoring Should Be Standard for AI-Based Digital Health*. ArXiv:2506.05701v1. [https://arxiv.org/pdf/2506.05701v1](https://arxiv.org/pdf/2506.05701v1)
137. <a id="ref-137"></a>Míriam Barrabés, Daniel Mas Montserrat, Kapal Dev, Alexander G. Ioannidis (2025). *Feature Shift Localization Network*. ArXiv:2506.09101v1. [https://arxiv.org/pdf/2506.09101v1](https://arxiv.org/pdf/2506.09101v1)
138. <a id="ref-138"></a>Markelle Kelly, Alex Boyd, Sam Showalter, Mark Steyvers, Padhraic Smyth (2025). *Bayesian Inference for Correlated Human Experts and Classifiers*. ArXiv:2506.05636v1. [https://arxiv.org/pdf/2506.05636v1](https://arxiv.org/pdf/2506.05636v1)
139. <a id="ref-139"></a>Chong Shao, Douglas Snyder, Chiran Li, Bowen Gu, Kerry Ngan, Chun-Ting Yang, Jiageng Wu, Richard Wyss, Kueiyu Joshua Lin, Jie Yang (2025). *Scalable Medication Extraction and Discontinuation Identification from Electronic Health Records Using Large Language Models*. ArXiv:2506.11137v1. [https://arxiv.org/pdf/2506.11137v1](https://arxiv.org/pdf/2506.11137v1)
140. <a id="ref-140"></a>Pietro Ferrazzi, Alberto Lavelli, Bernardo Magnini (2025). *Converting Annotated Clinical Cases into Structured Case Report Forms*. ArXiv:2506.11666v1. [https://arxiv.org/pdf/2506.11666v1](https://arxiv.org/pdf/2506.11666v1)
141. <a id="ref-141"></a>Michael E. Garcia-Alcoser, Mobina GhojoghNejad, Fakrul Islam Tushar, David Kim, Kyle J. Lafata, Geoffrey D. Rubin, Joseph Y. Lo (2025). *Evaluating Large Language Models for Zero-Shot Disease Labeling in CT Radiology Reports Across Organ Systems*. ArXiv:2506.03259v1. [https://arxiv.org/pdf/2506.03259v1](https://arxiv.org/pdf/2506.03259v1)
142. <a id="ref-142"></a>Sadia Kamal, Tim Oates, Joy Wan (2025). *Towards Scalable SOAP Note Generation: A Weakly Supervised Multimodal Framework*. ArXiv:2506.10328v1. [https://arxiv.org/pdf/2506.10328v1](https://arxiv.org/pdf/2506.10328v1)
143. <a id="ref-143"></a>Thomas Sounack, Joshua Davis, Brigitte Durieux, Antoine Chaffin, Tom J. Pollard, Eric Lehman, Alistair E. W. Johnson, Matthew McDermott, Tristan Naumann, Charlotta Lindvall (2025). *BioClinical ModernBERT: A State-of-the-Art Long-Context Encoder for Biomedical and Clinical NLP*. ArXiv:2506.10896v1. [https://arxiv.org/pdf/2506.10896v1](https://arxiv.org/pdf/2506.10896v1)
144. <a id="ref-144"></a>Luc Builtjes, J. Bosma, M. Prokop, B. V. Ginneken, A. Hering (2025). *Leveraging Open-Source Large Language Models for Clinical Information Extraction in Resource-Constrained Settings*. ArXiv:2507.20859. [https://www.semanticscholar.org/paper/f2bb97e0e1dd74f6b201596295072c50ce289b57](https://www.semanticscholar.org/paper/f2bb97e0e1dd74f6b201596295072c50ce289b57)
145. <a id="ref-145"></a>Sai Prasanna Teja Reddy Bogireddy, Abrar Majeedi, Viswanatha Reddy Gajjala, Zhuoyan Xu, Siddhant Rai, Vaishnav Potlapalli (2025). *Neural at ArchEHR-QA 2025: Agentic Prompt Optimization for Evidence-Grounded Clinical Question Answering*. ArXiv:2506.10751v1. [https://arxiv.org/pdf/2506.10751v1](https://arxiv.org/pdf/2506.10751v1)
146. <a id="ref-146"></a>Rafi Al Attrach, Pedro Moreira, Rajna Fani, Renato Umeton, Leo Anthony Celi (2025). *Conversational LLMs Simplify Secure Clinical Data Access, Understanding, and Analysis*. ArXiv:2507.01053v2. [https://arxiv.org/pdf/2507.01053v2](https://arxiv.org/pdf/2507.01053v2)
147. <a id="ref-147"></a>Qinyue Zheng, Salman Abdullah, Sam Rawal, Cyril Zakka, Sophie Ostmeier, Maximilian Purk, Eduardo Reis, Eric J. Topol, Jure Leskovec, Michael Moor (2025). *MIRIAD: Augmenting LLMs with millions of medical query-response pairs*. ArXiv:2506.06091v2. [https://arxiv.org/pdf/2506.06091v2](https://arxiv.org/pdf/2506.06091v2)
148. <a id="ref-148"></a>Xiao Wang, Mengjue Tan, Qiao Jin, Guangzhi Xiong, Yu Hu, Aidong Zhang, Zhiyong Lu, Minjia Zhang (2025). *MedCite: Can Language Models Generate Verifiable Text for Medicine?*. ArXiv:2506.06605v1. [https://arxiv.org/pdf/2506.06605v1](https://arxiv.org/pdf/2506.06605v1)
149. <a id="ref-149"></a>Saptarshi Sengupta, Shuhua Yang, Paul Kwong Yu, Fali Wang, Suhang Wang (2025). *BioMol-MQA: A Multi-Modal Question Answering Dataset For LLM Reasoning Over Bio-Molecular Interactions*. ArXiv:2506.05766v1. [https://arxiv.org/pdf/2506.05766v1](https://arxiv.org/pdf/2506.05766v1)
150. <a id="ref-150"></a>Shuang Zhou, Wenya Xie, Jiaxi Li, Zaifu Zhan, Meijia Song, Han Yang, Cheyenna Espinoza, Lindsay Welton, Xinnie Mai, Yanwei Jin, Zidu Xu, Yuen-Hei Chung, Yiyun Xing, Meng-Han Tsai, Emma Schaffer, Yucheng Shi, Ninghao Liu, Zirui Liu, Rui Zhang (2025). *Automating Expert-Level Medical Reasoning Evaluation of Large Language Models*. ArXiv:2507.07988. [https://www.semanticscholar.org/paper/50f69078f1085c5967e92d0c0ac13ba2906aca83](https://www.semanticscholar.org/paper/50f69078f1085c5967e92d0c0ac13ba2906aca83)
151. <a id="ref-151"></a>Adrien Bazoge (2025). *MediQAl: A French Medical Question Answering Dataset for Knowledge and Reasoning Evaluation*. ArXiv:2507.20917. [https://www.semanticscholar.org/paper/158304f6b99482d16f70034300dd402be4f9a595](https://www.semanticscholar.org/paper/158304f6b99482d16f70034300dd402be4f9a595)
152. <a id="ref-152"></a>Gonzalo Cardenal-Antolin, J. Fellay, Bashkim Jaha, R. Kouyos, N. Beerenwinkel, Diane Duroux (2025). *HIVMedQA: Benchmarking large language models for HIV medical decision support*. ArXiv:2507.18143. [https://www.semanticscholar.org/paper/14cc521817abf23142822f880c9569498ccf129a](https://www.semanticscholar.org/paper/14cc521817abf23142822f880c9569498ccf129a)
153. <a id="ref-153"></a>Isaac Shi, Zeyuan Li, Wenli Wang, Lewei He, Yang Yang, Tianyu Shi (2025). *eSapiens: A Real-World NLP Framework for Multimodal Document Understanding and Enterprise Knowledge Processing*. ArXiv:10.48550/arXiv.2506.16768. [https://www.semanticscholar.org/paper/b6f56d5ce929b8bce857a9a3031dc5dab7f6915f](https://www.semanticscholar.org/paper/b6f56d5ce929b8bce857a9a3031dc5dab7f6915f)
154. <a id="ref-154"></a>Zongxian Yang, Jiayu Qian, Zegao Peng, Haoyu Zhang, Zhi-An Huang (2025). *Med-REFL: Medical Reasoning Enhancement via Self-Corrected Fine-grained Reflection*. ArXiv:2506.13793v2. [https://arxiv.org/pdf/2506.13793v2](https://arxiv.org/pdf/2506.13793v2)
155. <a id="ref-155"></a>Yu Sun, Xingyu Qian, Weiwen Xu, Hao Zhang, Chenghao Xiao, Long Li, Yu Rong, Wenbing Huang, Qifeng Bai, Tingyang Xu (2025). *ReasonMed: A 370K Multi-Agent Generated Dataset for Advancing Medical Reasoning*. ArXiv:2506.09513v1. [https://arxiv.org/pdf/2506.09513v1](https://arxiv.org/pdf/2506.09513v1)
156. <a id="ref-156"></a>Ha-Thanh Nguyen, Chaoran Liu, Qianying Liu, Hideyuki Tachibana, Su Myat Noe, Yusuke Miyao, Koichi Takeda, Sadao Kurohashi (2025). *BIS Reasoning 1.0: The First Large-Scale Japanese Benchmark for Belief-Inconsistent Syllogistic Reasoning*. ArXiv:2506.06955v4. [https://arxiv.org/pdf/2506.06955v4](https://arxiv.org/pdf/2506.06955v4)
157. <a id="ref-157"></a>Jaehoon Yun, Jiwoong Sohn, Jungwoo Park, Hyunjae Kim, Xiangru Tang, Yanjun Shao, Yonghoe Koo, Minhyeok Ko, Qingyu Chen, Mark Gerstein, Michael Moor, Jaewoo Kang (2025). *Med-PRM: Medical Reasoning Models with Stepwise, Guideline-verified Process Rewards*. ArXiv:2506.11474v1. [https://arxiv.org/pdf/2506.11474v1](https://arxiv.org/pdf/2506.11474v1)
158. <a id="ref-158"></a>Haoran Sun, Yankai Jiang, Wenjie Lou, Yujie Zhang, Wenjie Li, Lilong Wang, Mianxin Liu, Lei Liu, Xiaosong Wang (2025). *Enhancing Step-by-Step and Verifiable Medical Reasoning in MLLMs*. ArXiv:2506.16962v1. [https://arxiv.org/pdf/2506.16962v1](https://arxiv.org/pdf/2506.16962v1)
159. <a id="ref-159"></a>Shoubin Yu, Yue Zhang, Ziyang Wang, Jaehong Yoon, Mohit Bansal (2025). *MEXA: Towards General Multimodal Reasoning with Dynamic Multi-Expert Aggregation*. ArXiv:10.48550/arXiv.2506.17113. [https://www.semanticscholar.org/paper/5851e0eff2b2ab964a9f3e0119b8f3e3cd7f684a](https://www.semanticscholar.org/paper/5851e0eff2b2ab964a9f3e0119b8f3e3cd7f684a)
160. <a id="ref-160"></a>Tianhong Gao, Yannian Fu, Weiqun Wu, Haixiao Yue, Shanshan Liu, Gang Zhang (2025). *MMAT-1M: A Large Reasoning Dataset for Multimodal Agent Tuning*. ArXiv:2507.21924. [https://www.semanticscholar.org/paper/aefcbc059c85337d94d62c7e659db8b32e94ca87](https://www.semanticscholar.org/paper/aefcbc059c85337d94d62c7e659db8b32e94ca87)
161. <a id="ref-161"></a>Michelle M. Li, Ben Y. Reis, Adam Rodman, Tianxi Cai, Noa Dagan, Ran D. Balicer, Joseph Loscalzo, Isaac S. Kohane, Marinka Zitnik (2025). *One Patient, Many Contexts: Scaling Medical AI Through Contextual Intelligence*. ArXiv:2506.10157v1. [https://arxiv.org/pdf/2506.10157v1](https://arxiv.org/pdf/2506.10157v1)
162. <a id="ref-162"></a>Suhana Bedi, Iddah Mlauzi, Daniel Shin, Sanmi Koyejo, Nigam H. Shah (2025). *The Optimization Paradox in Clinical AI Multi-Agent Systems*. ArXiv:2506.06574v2. [https://arxiv.org/pdf/2506.06574v2](https://arxiv.org/pdf/2506.06574v2)
163. <a id="ref-163"></a>Periklis Petridis, Georgios Margaritis, Vasiliki Stoumpou, Dimitris Bertsimas (2025). *Holistic Artificial Intelligence in Medicine; improved performance and explainability*. ArXiv:2507.00205. [https://www.semanticscholar.org/paper/13a411e158ccd48c8ed969cad861a33ef2c4b9e1](https://www.semanticscholar.org/paper/13a411e158ccd48c8ed969cad861a33ef2c4b9e1)
164. <a id="ref-164"></a>Songtao Jiang, Yuan Wang, Ruizhe Chen, Yan Zhang, Ruilin Luo, Bohan Lei, Sibo Song, Yang Feng, Jimeng Sun, Jian Wu, Zuozhu Liu (2025). *CAPO: Reinforcing Consistent Reasoning in Medical Decision-Making*. ArXiv:10.48550/arXiv.2506.12849. [https://www.semanticscholar.org/paper/dd3ad0b37c2aa78ee347b04b7593b1330ff01f7f](https://www.semanticscholar.org/paper/dd3ad0b37c2aa78ee347b04b7593b1330ff01f7f)
165. <a id="ref-165"></a>Tan-Hanh Pham, Chris Ngo (2025). *RARL: Improving Medical VLM Reasoning and Generalization with Reinforcement Learning and LoRA under Data and Hardware Constraints*. ArXiv:10.48550/arXiv.2506.06600. [https://www.semanticscholar.org/paper/54bd6de7ef903ca59460f5cdd410548893ede9e5](https://www.semanticscholar.org/paper/54bd6de7ef903ca59460f5cdd410548893ede9e5)
166. <a id="ref-166"></a>Peixian Li, Yu Tian, Ruiqi Tu, Chengkai Wu, Jingjing Ren, Jingsong Li (2025). *Integrating clinical reasoning into large language model-based diagnosis through etiology-aware attention steering*. ArXiv:2508.00285. [https://www.semanticscholar.org/paper/fb69b0591a8acf0d3f36b47d3df36b1ef481a394](https://www.semanticscholar.org/paper/fb69b0591a8acf0d3f36b47d3df36b1ef481a394)
167. <a id="ref-167"></a>Akram Mustafa, Usman Naseem, M. Azghadi (2025). *Evaluating Hierarchical Clinical Document Classification Using Reasoning-Based LLMs*. ArXiv:2507.03001. [https://www.semanticscholar.org/paper/567c594b0b34f6bbd3a26d338298f5426035db5c](https://www.semanticscholar.org/paper/567c594b0b34f6bbd3a26d338298f5426035db5c)
168. <a id="ref-168"></a>Radin Shayanfar, Chu Fei Luo, Rohan Bhambhoria, Samuel Dahan, Xiaodan Zhu (2025). *CoDial: Interpretable Task-Oriented Dialogue Systems Through Dialogue Flow Alignment*. ArXiv:2506.02264v1. [https://arxiv.org/pdf/2506.02264v1](https://arxiv.org/pdf/2506.02264v1)
169. <a id="ref-169"></a>Qi Shi, Qiwei Han, Claudia Soares (2025). *C-PATH: Conversational Patient Assistance and Triage in Healthcare System*. ArXiv:10.48550/arXiv.2506.06737. [https://www.semanticscholar.org/paper/18ef1317355a5662fb9276242110637c5446eca3](https://www.semanticscholar.org/paper/18ef1317355a5662fb9276242110637c5446eca3)
170. <a id="ref-170"></a>Jin Kim, Muhammad Wahi-Anwa, Sangyun Park, Shawn Shin, John M. Hoffman, Matthew S. Brown (2025). *Autonomous Computer Vision Development with Agentic AI*. ArXiv:2506.11140v3. [https://arxiv.org/pdf/2506.11140v3](https://arxiv.org/pdf/2506.11140v3)
171. <a id="ref-171"></a>Haoneng Lin, Cheng Xu, Jing Qin (2025). *Taming Vision-Language Models for Medical Image Analysis: A Comprehensive Review*. ArXiv:10.48550/arXiv.2506.18378. [https://www.semanticscholar.org/paper/b21a2cdc6e9a841d7432b19d57ea8b9164f8f0e4](https://www.semanticscholar.org/paper/b21a2cdc6e9a841d7432b19d57ea8b9164f8f0e4)
172. <a id="ref-172"></a>Xiaotang Gai, Jiaxiang Liu, Yichen Li, Zijie Meng, Jian Wu, Zuozhu Liu (2025). *3D-RAD: A Comprehensive 3D Radiology Med-VQA Dataset with Multi-Temporal Analysis and Diverse Diagnostic Tasks*. ArXiv:10.48550/arXiv.2506.11147. [https://www.semanticscholar.org/paper/b17d087a5e4c535ece5d4f299a559129d7fd00fd](https://www.semanticscholar.org/paper/b17d087a5e4c535ece5d4f299a559129d7fd00fd)
173. <a id="ref-173"></a>Mengjie Fang, Zipei Wang, Sitian Pan, Xin Feng, Yunpeng Zhao, Dongzhi Hou, Ling Wu, Xuebin Xie, Xu-Yao Zhang, Jie Tian, Di Dong (2025). *Large models in medical imaging: Advances and prospects*. ArXiv:10.1097/CM9.0000000000003699. [https://www.semanticscholar.org/paper/6d7c4cd52faced2f265d3306b1d8de4888be2902](https://www.semanticscholar.org/paper/6d7c4cd52faced2f265d3306b1d8de4888be2902)
174. <a id="ref-174"></a>Sunggu Kyung, Hyungbin Park, Jinyoung Seo, Jimin Sung, Jihyun Kim, Dongyeong Kim, Wooyoung Jo, Yoojin Nam, Sangah Park, Taehee Kwon, Sang Min Lee, Namkug Kim (2025). *MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports*. ArXiv:10.48550/arXiv.2506.19217. [https://www.semanticscholar.org/paper/d312db9a06856a13927c5b7b5e2141ca25446b8b](https://www.semanticscholar.org/paper/d312db9a06856a13927c5b7b5e2141ca25446b8b)
175. <a id="ref-175"></a>Sebastian Wind, Jeta Sopa, Daniel Truhn, Mahshad Lotfinia, Tri-Thien Nguyen, Keno K. Bressem, Lisa Adams, Mirabela Rusu, Harald Kostler, Gerhard Wellein, Andreas Maier, Soroosh Tayebi Arasteh (2025). *Agentic large language models improve retrieval-based radiology question answering*. ArXiv:2508.00743. [https://www.semanticscholar.org/paper/0165a739c5318fe754eca9a8274b82c383ca14a3](https://www.semanticscholar.org/paper/0165a739c5318fe754eca9a8274b82c383ca14a3)
176. <a id="ref-176"></a>Chengkuan Chen, Luca L. Weishaupt, Drew F. K. Williamson, Richard J. Chen, Tong Ding, Bowen Chen, Anurag Vaidya, L. Le, Guillaume Jaume, Ming Y. Lu, Faisal Mahmood (2025). *Evidence-based diagnostic reasoning with multi-agent copilot for human pathology*. ArXiv:10.48550/arXiv.2506.20964. [https://www.semanticscholar.org/paper/da8b90bc8030fd143455ae70b7f64f03af8cece1](https://www.semanticscholar.org/paper/da8b90bc8030fd143455ae70b7f64f03af8cece1)
177. <a id="ref-177"></a>Moshi Wei, Sparks Li (2025). *Intelligent System of Emergent Knowledge: A Coordination Fabric for Billions of Minds*. ArXiv:2506.09335v1. [https://arxiv.org/pdf/2506.09335v1](https://arxiv.org/pdf/2506.09335v1)
178. <a id="ref-178"></a>Jianping Zhao, Qiong Zhou, Tian Wang, Yusi Fan, Qian Yang, Li Jiao, Chang Liu, Zhehao Guo, Qi Lu, Fengfeng Zhou, Ruochi Zhang (2025). *MolProphecy: Bridging Medicinal Chemists' Knowledge and Molecular Pre-Trained Models via a Multi-Modal Framework*. ArXiv:2507.02932v1. [https://arxiv.org/pdf/2507.02932v1](https://arxiv.org/pdf/2507.02932v1)
179. <a id="ref-179"></a>Uttej Kallakurik, Edward Humes, Rithvik Jonna, Xiaomin Lin, Tinoosh Mohsenin (2025). *Enabling On-Device Medical AI Assistants via Input-Driven Saliency Adaptation*. ArXiv:2506.11105v2. [https://arxiv.org/pdf/2506.11105v2](https://arxiv.org/pdf/2506.11105v2)
180. <a id="ref-180"></a>Wenyue Hua, Dujian Ding, Yile Gu, Yujie Ren, Kai Mei, Minghua Ma, William Yang Wang (2025). *Semantic Scheduling for LLM Inference*. ArXiv:2506.12204v1. [https://arxiv.org/pdf/2506.12204v1](https://arxiv.org/pdf/2506.12204v1)
181. <a id="ref-181"></a>Naseem Babu, Jimson Mathew, A. P. Vinod (2025). *Large Language Models for EEG: A Comprehensive Survey and Taxonomy*. ArXiv:2506.06353v1. [https://arxiv.org/pdf/2506.06353v1](https://arxiv.org/pdf/2506.06353v1)
182. <a id="ref-182"></a>Miran Özdogan, Gilad Landau, Gereon Elvers, Dulhan Jayalath, Pratik Somaiya, Francesco Mantegna, Mark Woolrich, Oiwi Parker Jones (2025). *LibriBrain: Over 50 Hours of Within-Subject MEG to Improve Speech Decoding Methods at Scale*. ArXiv:2506.02098v1. [https://arxiv.org/pdf/2506.02098v1](https://arxiv.org/pdf/2506.02098v1)
183. <a id="ref-183"></a>Kahn Rhrissorrakrai, Kathleen E. Hamilton, Prerana Bangalore Parthsarathy, Aldo Guzman-Saenz, Tyler Alban, Filippo Utro, Laxmi Parida (2025). *Quantum Ensembling Methods for Healthcare and Life Science*. ArXiv:2506.02213v1. [https://arxiv.org/pdf/2506.02213v1](https://arxiv.org/pdf/2506.02213v1)
184. <a id="ref-184"></a>LASA Team, Weiwen Xu, Hou Pong Chan, Long Li, Mahani Aljunied, Ruifeng Yuan, Jianyu Wang, Chenghao Xiao, Guizhen Chen, Chaoqun Liu, Zhaodonghui Li, Yu Sun, Junao Shen, Chaojun Wang, Jie Tan, Deli Zhao, Tingyang Xu, Hao Zhang, Yu Rong (2025). *Lingshu: A Generalist Foundation Model for Unified Multimodal Medical Understanding and Reasoning*. ArXiv:2506.07044v4. [https://arxiv.org/pdf/2506.07044v4](https://arxiv.org/pdf/2506.07044v4)
185. <a id="ref-185"></a>Carlos Garcia-Fernandez, Luis Felipe, Monique Shotande, Muntasir Zitu, Aakash Tripathi, Ghulam Rasool, Issam El Naqa, Vivek Rudrapatna, Gilmer Valdes (2025). *Trustworthy AI for Medicine: Continuous Hallucination Detection and Elimination with CHECK*. ArXiv:2506.11129v1. [https://arxiv.org/pdf/2506.11129v1](https://arxiv.org/pdf/2506.11129v1)
186. <a id="ref-186"></a>Asad Aali, V. Bikia, Maya Varma, Nicole Chiou, Sophie Ostmeier, Arnav Singhvi, Magdalini Paschali, Ashwin Kumar, Andrew Johnston, Karimar Amador-Martinez, Eduardo Juan Perez Guerrero, Paola Naovi Cruz Rivera, S. Gatidis, Christian Bluethgen, E. Reis, Eddy D. Zandee van Rilland, Poonam Hosamani, Kevin R Keet, Minjoung Go, E. Ling, David B. Larson, C. Langlotz, Roxana Daneshjou, Jason Hom, Sanmi Koyejo, Emily Alsentzer, Akshay S. Chaudhari (2025). *Expert-level validation of AI-generated medical text with scalable language models*. ArXiv:2507.03152. [https://www.semanticscholar.org/paper/793bfac5bbe4a53d6e133743643916843a7f0202](https://www.semanticscholar.org/paper/793bfac5bbe4a53d6e133743643916843a7f0202)
187. <a id="ref-187"></a>M. Azeez, Rafiq Ali, Ebad Shabbir, Z. Siddiqui, Gautam Siddharth Kashyap, Jiechao Gao, Usman Naseem (2025). *Truth, Trust, and Trouble: Medical AI on the Edge*. ArXiv:2507.02983. [https://www.semanticscholar.org/paper/26f13eb8cf9253b7fbb4bb7b67523c6e5f2151d0](https://www.semanticscholar.org/paper/26f13eb8cf9253b7fbb4bb7b67523c6e5f2151d0)
188. <a id="ref-188"></a>Alberto Testoni, Iacer Calixto (2025). *Different Questions, Different Models: Fine-Grained Evaluation of Uncertainty and Calibration in Clinical QA with LLMs*. ArXiv:2506.10769v1. [https://arxiv.org/pdf/2506.10769v1](https://arxiv.org/pdf/2506.10769v1)
189. <a id="ref-189"></a>Xiao Liang, Di Wang, Zhicheng Jiao, Ronghan Li, Pengfei Yang, Quan Wang, Tat-Seng Chua (2025). *Uncertainty-Driven Expert Control: Enhancing the Reliability of Medical Vision-Language Models*. ArXiv:2507.09209. [https://www.semanticscholar.org/paper/cf89861099246564046ea5c253ff16be00688b88](https://www.semanticscholar.org/paper/cf89861099246564046ea5c253ff16be00688b88)
190. <a id="ref-190"></a>Baqer M. Merzah, Tania Taami, Salman Asoudeh, Saeed Mirzaee, Amir reza Hossein pour, Amir Ali Bengari (2025). *BioPars: A Pretrained Biomedical Large Language Model for Persian Biomedical Text Mining*. ArXiv:2506.21567v2. [https://arxiv.org/pdf/2506.21567v2](https://arxiv.org/pdf/2506.21567v2)
191. <a id="ref-191"></a>Weiying Zheng, Ziyue Lin, Pengxin Guo, Yuyin Zhou, Feifei Wang, Liangqiong Qu (2025). *FedVLMBench: Benchmarking Federated Fine-Tuning of Vision-Language Models*. ArXiv:2506.09638v1. [https://arxiv.org/pdf/2506.09638v1](https://arxiv.org/pdf/2506.09638v1)
192. <a id="ref-192"></a>Jiahao Qiu, Xinzhe Juan, Yimin Wang, Ling Yang, Xuan Qi, Tongcheng Zhang, Jiacheng Guo, Yifu Lu, Zixin Yao, Hongru Wang, Shilong Liu, Xun Jiang, Liu Leqi, Mengdi Wang (2025). *AgentDistill: Training-Free Agent Distillation with Generalizable MCP Boxes*. ArXiv:2506.14728v1. [https://arxiv.org/pdf/2506.14728v1](https://arxiv.org/pdf/2506.14728v1)
193. <a id="ref-193"></a>Zizheng Zhan, Ken Deng, Huaixi Tang, Wen Xiang, Kun Wu, Weihao Li, Wen-ya Zhu, Jingxuan Xu, Lecheng Huang, Zongxian Feng, Shaojie Wang, Shangpeng Yan, Xuxing Chen, Jiaheng Liu, Zhongyuan Peng, Zuchen Gao, Haoyang Huang, Xiaojiang Zhang, Jinghui Wang, Zheng Lin, Mengtong Li, Huiming Wang, Ziqi Zhan, Yanan Wu, Yuanxing Zhang, Jian Yang, Guang Chen, Haotian Zhang, Bin Chen, Bing Yu (2025). *KAT-V1: Kwai-AutoThink Technical Report*. ArXiv:2507.08297. [https://www.semanticscholar.org/paper/c359ef42e054b08ea26985833842650b98a84f2c](https://www.semanticscholar.org/paper/c359ef42e054b08ea26985833842650b98a84f2c)
194. <a id="ref-194"></a>Kacper Sokol, James Fackler, Julia E Vogt (2025). *Artificial Intelligence Should Genuinely Support Clinical Reasoning and Decision Making To Bridge the Translational Gap*. ArXiv:2506.05030v1. [https://arxiv.org/pdf/2506.05030v1](https://arxiv.org/pdf/2506.05030v1)
195. <a id="ref-195"></a>Jubin Abhishek Soni, Amit Anand, Rajesh Kumar Pandey, Aniket Abhishek Soni (2025). *Dynamic Context Tuning for Retrieval-Augmented Generation: Enhancing Multi-Turn Planning and Tool Adaptation*. ArXiv:2506.11092v2. [https://arxiv.org/pdf/2506.11092v2](https://arxiv.org/pdf/2506.11092v2)
