---
title: February 2025
date: 2025-02-28
categories: [Newsletters]
tags: [AI in clinical trials, LLM, Patient Selection, Synthetic Data, Personalised Medicine ]
description: This issue explores how AI, particularly through LLMs and generative AI, is profoundly reshaping clinical trials by enhancing efficiency, precision, and ethical considerations in protocol design, patient selection, data management, and personalized treatment strategies.
---

# Introduction

The landscape of clinical trials is being profoundly reshaped by advancements in artificial intelligence (AI), offering solutions to long-standing challenges in drug development and therapeutic validation. This issue explores how AI, particularly through the application of large language models (LLMs) and generative AI, is enhancing the efficiency, precision, and ethical considerations across multiple facets of clinical research. Contributions detailed herein illustrate significant strides in optimizing clinical trial protocol design and patient selection, streamlining the complex processes of clinical data management and information extraction, and accelerating trial planning through sophisticated synthetic data generation and *in silico* simulations. Furthermore, advancements in AI for personalized treatment strategies and predictive analytics are highlighted, showcasing the potential to tailor interventions and monitor patient responses with unprecedented accuracy.

# Revolutionizing Clinical Trial Protocol Design and Patient Selection

The initiation of clinical trials, from drafting intricate protocols to identifying and recruiting suitable participants, remains a resource-intensive and time-consuming bottleneck in medical research. Artificial intelligence (AI), particularly large language models (LLMs), is rapidly transforming these foundational stages, offering unprecedented opportunities for efficiency, precision, and ethical conduct.

One of the most significant advancements lies in **automating the definition of eligibility criteria and patient pre-screening**. Traditionally, converting natural language inclusion/exclusion criteria into executable database queries or manually sifting through patient records is a laborious process. A novel automated system leverages large language models and a two-level retrieval-augmented generation (RAG) framework to translate complex clinical criteria into SQL queries for patient cohort identification from Electronic Health Records (EHRs) [1](https://arxiv.org/pdf/2502.21107v1). This system employs specialized knowledge bases (EpiAskKB and EpiCohoKB) and medical concept standardization to effectively capture temporal and logical relationships, achieving a 0.75 F1-score in cohort identification. While promising, its generalizability may be limited by its modest dataset size and reliance on the OMOP-CDM (Open Medical Ontology Project Common Data Model) standard [1](https://arxiv.org/pdf/2502.21107v1). Complementing this, an LLM-powered pre-screening pipeline, specifically validated in hepatology, significantly reduces the time and resources for patient recruitment while maintaining high precision (0.921 at criterion level) [2](https://arxiv.org/pdf/2502.18531v1). This pipeline integrates clinical expertise and employs two strategies—Anthropomorphized Experts' Chain of Thought (Pathway A) for recognition and Preset Stances within an Agent Collaboration (Pathway B) for complex reasoning—allowing for secure, locally deployed LLM applications in resource-limited environments. Acknowledged limitations include its single-center data origin and primary reliance on admission notes [2](https://arxiv.org/pdf/2502.18531v1). Furthering this automation, the ProADA framework, based on program synthesis, can adaptively determine user eligibility through interactive dialogue [3](https://arxiv.org/pdf/2502.19610v2). By mapping dialogue planning to code generation, ProADA aims to automate eligibility screening, though its current strict adherence to generated code limits recovery from unexpected user responses [3](https://arxiv.org/pdf/2502.19610v2). These advancements are broadly supported by innovations in AI-powered clinical trial recommendation systems like TrialMatchAI [4](https://www.semanticscholar.org/paper/4494f140797ded006edcb40443ad146f22574070), which automates patient-to-trial matching using RAG and medical Chain-of-Thought reasoning, and systems that leverage RAG for biomedical knowledge [5](https://www.semanticscholar.org/paper/ea2f72b979e2646dec92a9ce9b6b07dd0a20e789) and the standardization of clinical data elements (CDEs) [6](https://www.semanticscholar.org/paper/ecc3051e19f7713350e0950b6cde1f0841ca2d7c). The use of prompt ensemble techniques also enhances reliable medical entity recognition from EHRs, crucial for these automated processes [7](https://www.semanticscholar.org/paper/1f95c6911773246f99117cd583f48f2435f658a6).

Beyond initial screening, AI is enabling **personalized patient stratification and disease trajectory prediction**, leading to more targeted and efficient trial designs. Traditional models often treat disease progression as uniform, but a genetics-driven personalized disease progression model challenges this by jointly learning heterogeneous progression patterns and genetic profiles [8](https://arxiv.org/pdf/2503.00028v1). This model integrates genetic markers and clinical observations via a variational autoencoder and an RNN (Recurrent Neural Network)-based state-space model, enabling patient stratification, predictive enrichment, and the identification of surrogate endpoints. However, it is constrained by the availability and predictive power of GWAS (Genome-Wide Association Study) data, computational complexity, and data requirements [8](https://arxiv.org/pdf/2503.00028v1). Complementing this, scGSDR offers single-cell pharmacological profiling to predict drug responses at a granular level [9](https://arxiv.org/pdf/2502.01689v1). By incorporating gene semantics and an interpretability module, scGSDR can identify patient subgroups likely to benefit from specific therapies, predict responses to drug combinations, and suggest biomarkers, accelerating the exploration of novel therapeutic strategies. Its limitations include reliance on existing datasets and potential variations based on reference data [9](https://arxiv.org/pdf/2502.01689v1). Crucially, accurate patient diagnosis underpins effective stratification. MedRAG, a RAG model enhanced by knowledge graph-elicited reasoning, improves diagnostic accuracy and specificity for healthcare practitioners [10](https://arxiv.org/pdf/2502.04413v1). By constructing a four-tier hierarchical diagnostic knowledge graph and integrating it with EHRs, MedRAG can provide more specific diagnostic insights, which is vital for precise patient assignment to trial groups [10](https://arxiv.org/pdf/2502.04413v1). The effectiveness of MedRAG is dependent on the comprehensiveness and maintenance of its knowledge graph, and it currently lacks full multimodal integration [10](https://arxiv.org/pdf/2502.04413v1). These diagnostic capabilities are further enhanced by models designed for clinical diagnosis [11](https://www.semanticscholar.org/paper/ada491d38e0821d2772898036bd53a5fe2cc2b5) and those that can identify diagnostic uncertainties [12](https://www.semanticscholar.org/paper/099538285ce1f8e42fbed3e108a530c8673e03cd), contributing to more robust patient selection.

Finally, AI is contributing to the **optimization of trial design itself and the integration of fairness considerations**. Adaptive experimental designs, such as ClipOGDSC and MGATE, improve the efficiency of ATE (Average Treatment Effect) estimation in sequential randomized controlled trials [13](https://arxiv.org/pdf/2502.17427v1). ClipOGDSC achieves near-logarithmic Neyman regret, suggesting faster convergence to optimal treatment allocation, while MGATE allows efficient ATE estimation within subgroups. The "anytime validity" of these designs means pre-specification of trial duration is not required, leading to more efficient and cost-effective trials [13](https://arxiv.org/pdf/2502.17427v1). However, these designs rely on stricter assumptions and may face practical implementation barriers due to their complexity [13](https://arxiv.org/pdf/2502.17427v1). Addressing ethical considerations, a novel CMIA (Conditional Mutual Information Augmentation) approach focuses on achieving fairness in survival analysis at pre-defined time points [14](https://arxiv.org/pdf/2502.02567v1). By regularizing for equalized odds and using censored data augmentation, CMIA helps mitigate bias against disadvantaged groups in prognostic models, promoting more equitable trial outcomes and patient selection [14](https://arxiv.org/pdf/2502.02567v1). Its generalizability across diverse clinical datasets and interpretability remain areas for further research [14](https://arxiv.org/pdf/2502.02567v1). The increasing reliance on LLMs in healthcare necessitates robust evaluation and strategies to ensure interpretability and minimize hallucination [15](https://www.semanticscholar.org/paper/3982dd06568c983e94cd748ddaf123829160ee7e), [16](https://www.semanticscholar.org/paper/055f837d7b9cb855708cae3fee9104feb46d0dcb), [17](https://www.semanticscholar.org/paper/f6f8b6c25269ce53965cb65ef01b4b23a0d698fb), [18](https://www.semanticscholar.org/paper/cae8cdae8df2600c578312f1a2ac431537292d5d).

In summary, AI is profoundly impacting clinical trial design and patient selection by automating complex data extraction, enabling highly personalized patient stratification based on granular biological and genetic data, and developing more efficient and ethically robust trial methodologies. While significant progress has been made, challenges related to data generalizability, model interpretability, computational demands, and the critical need for human oversight and regulatory alignment persist, underscoring the ongoing evolution of AI in clinical research.

# AI-Driven Enhancements in Clinical Data Management and Extraction

Efficient clinical trials are critically dependent on the robust handling of vast and often disparate clinical data. A significant bottleneck lies in extracting, harmonizing, and ensuring the quality of information from unstructured clinical text, such as Electronic Health Records (EHRs). Recent advancements in Artificial Intelligence (AI), particularly Large Language Models (LLMs), are offering transformative solutions to streamline these complex data management processes, facilitating faster and more accurate data preparation for analysis.

One major thrust of AI innovation in this domain is the **automated extraction of structured information from unstructured clinical narratives**. Traditional medical abstraction is labor-intensive and challenging to scale, often requiring extensive manual rule crafting or data annotation. To address this, UNIMEDABSTRACTOR (UMA) proposes a zero-shot medical abstraction framework leveraging LLMs through a modular prompt template [19](https://arxiv.org/pdf/2502.00943v1). UMA demonstrates strong performance in extracting key clinical attributes, including complex long-context elements like cancer staging, significantly outperforming supervised and heuristic baselines. This capability can dramatically accelerate patient identification and enrollment for clinical trials. However, UMA's reliance on data from a single EHR system limits its capture of a patient's complete medical history, and its foundational prompting techniques could be further refined with more advanced methods like self-verification [19](https://arxiv.org/pdf/2502.00943v1). Similarly, ELMTEX highlights the potential of fine-tuned smaller LLMs for efficient structured clinical information extraction from reports and summaries [20](https://arxiv.org/pdf/2502.05638v1). This approach aims to reduce manual effort in data extraction and accelerate patient identification, while acknowledging limitations in addressing nuanced inclusion/exclusion criteria or longitudinal patient data complexities typical in clinical trials [20](https://arxiv.org/pdf/2502.05638v1). To enhance information extraction from clinical trial-related texts, the Multi-Mode Retrieval-Augmented Generation (MMRAG) framework has been developed. MMRAG refines in-context learning by integrating various retrieval strategies, showing improved Named Entity Recognition (NER) and Relation Extraction (RE) tasks, particularly beneficial in data-scarce scenarios often encountered in rare disease research [21](https://arxiv.org/pdf/2502.15954v1). This echoes the broader utility of LLM-based prompt ensembles for reliable medical entity recognition from EHRs, which can improve classification performance and reliability [7](https://www.semanticscholar.org/paper/1f95c6911773246f99117cd583f48f2435f658a6). The shift towards end-to-end clinical event extraction using LLMs also promises significant improvements over traditional pipeline methods by transforming the task into text generation [22](https://www.semanticscholar.org/paper/94f49036a4475a2108fba85946e73bd30a1fe2e1).

A significant development is the increasing viability of **Small Language Models (SLMs)** for clinical applications, offering a more resource-efficient and privacy-preserving alternative to larger models [23](https://www.semanticscholar.org/paper/d0e6b0a43edec2424005ee900c6d657597bd7d16), [24](https://www.semanticscholar.org/paper/72afb9cbc91c104e3bf1ead3588c6977f173591f). Lightweight models, like T5 and BERT2BERT, can outperform larger LLMs in structuring radiology reports, demonstrating that computational costs can be substantially reduced while maintaining competitive performance [25](https://www.semanticscholar.org/paper/3d7fc1824d6e6fde1b68c48015c9e3870ffd03db). This is further supported by frameworks like MediPhi, which leverage pre-instruction tuning, model merging, and synthetic data for clinical-tasks alignment, allowing SLMs to achieve high performance on medical entity recognition and ICD-10 (International Classification of Diseases, Tenth Revision) coding [26](https://www.semanticscholar.org/paper/c668268d68e646ef9d1a4df35264450d32573ca4). The strategic use of prompt engineering with lightweight LLMs can also achieve competitive results for disease labeling and clinical finding extraction in radiology, offering cost-effective and privacy-preserving solutions [27](https://www.semanticscholar.org/paper/335cd141c6f07bf3ce43eb058ace99c0d0448cac).

Beyond extraction, **data harmonization and integration** are crucial for combining datasets from diverse sources, a common challenge in clinical research, especially for rare diseases where larger sample sizes are often created by combining multiple small cohorts. Harmonia introduces a system for agent-assisted data harmonization, automating the creation of reusable pipelines that map disparate data to standard formats [28](https://arxiv.org/pdf/2502.07132v2). This interactive system, guided by domain experts, aims to reduce manual effort and accelerate meta-analyses. However, the reliance on LLMs introduces potential inconsistencies and "hallucinations," necessitating careful human oversight and robust validation for complex, heterogeneous clinical trial data [28](https://arxiv.org/pdf/2502.07132v2). Complementing this, CDE-Mapper leverages Retrieval-Augmented Generation (RAG) with LLMs to automate the linking of clinical data elements (CDEs) to controlled vocabularies, significantly improving data harmonization and interoperability [6](https://www.semanticscholar.org/paper/ecc3051e19f7713350e0950b6cde1f0841ca2d7c). The challenge of patient record linkage, vital for integrating data from diverse healthcare systems, is also being addressed by language models, showing promise in automating blocking and matching tasks, though hybrid rule-based and probabilistic approaches remain more accurate and efficient for large-scale blocking [29](https://www.semanticscholar.org/paper/6c2f5ef88f7aabc3de3101e8ca3f19ba10f152df). LLMs are also being explored for constructing RDF (Resource Description Framework) knowledge graphs by enhancing medical ontology mapping, moving towards more accurate and interoperable medical knowledge representation [30](https://www.semanticscholar.org/paper/c9d2616f0b49b9842c34309373f7d2b419f2bbcc).

Ensuring **high data quality and enabling accurate clinical prediction** from EHRs are central to accelerating clinical trials. General-purpose LLMs are being investigated as powerful EHR encoders, demonstrating performance on par with or even surpassing EHR-specific models across various clinical prediction tasks [31](https://arxiv.org/pdf/2502.17403v2). This approach holds potential for optimizing patient selection and automating data preprocessing from EHRs. A critical limitation, however, is the sensitivity of performance to context size and the serialization strategies employed, alongside the computational demands of LLMs and dataset specificities [31](https://arxiv.org/pdf/2502.17403v2). To directly address data quality, methods that improve unstructured data quality via updatable extracted views are being developed. By applying information extraction algorithms to create relational views, errors and inconsistencies in clinical trial reports and patient data can be systematically identified and corrected [32](https://arxiv.org/pdf/2502.18221v1). While promising for standardizing terminology and correcting errors, this method relies on "stable extractors" which can be difficult to achieve with the variability of medical text and currently does not address missing data [32](https://arxiv.org/pdf/2502.18221v1). To minimize manual labeling and provide uncertainty estimates, active learning combined with label-conditional conformal prediction offers a flexible and efficient framework for mining unstructured medical texts, particularly useful for extracting adverse events or patient characteristics [33](https://arxiv.org/pdf/2502.04372v1). In contexts where linguistic resources are scarce, such as Russian, automating clinical coding with LLMs has shown the potential to streamline patient cohort identification, although inter-annotator agreement and generalizability across regions remain areas for refinement [34](https://arxiv.org/pdf/2502.21263v1). The generation of high-fidelity pseudo-labels by LLMs can significantly improve the performance of radiology report classifiers, overcoming data annotation bottlenecks and enhancing medical text processing [35](https://www.semanticscholar.org/paper/6a185f003963b317f6d89802dfc6f1b0fd9b0d0c). Similarly, weakly supervised fine-tuning approaches using LLMs can automatically extract critical findings from radiology reports, aiding in research and clinical use even with limited labeled data [36](https://www.semanticscholar.org/paper/4ebfdf5de63d7c676b34a2b5115c07b3cb2a8bfd). Furthermore, an LLM-powered framework for automatic clinical data de-identification, RedactOR, helps ensure privacy while preserving data utility, a critical aspect for AI-driven healthcare [37](https://www.semanticscholar.org/paper/6a8ff1b5fc096dab785873732509e29f1752fba7).

Finally, AI is revolutionizing **event detection and temporal analysis** within clinical data. The Forward-Inverse Generation (FIG) method improves event detection in low-resource domains by generating high-quality synthetic data, crucial for identifying adverse events, treatment effects, and outcomes from clinical text [38](https://arxiv.org/pdf/2502.17394v1). This can lead to improved automation of safety monitoring and faster extraction of efficacy endpoints. However, the approach is sensitive to the quality of unlabeled data and faces risks of introducing bias in synthetic data [38](https://arxiv.org/pdf/2502.17394v1). Understanding temporal dynamics in clinical narratives is also essential for modeling patient trajectories. Research into forecasting from textual time series, where timestamped clinical findings serve as input, has shown that encoder-based models achieve high F1 scores for event forecasting, highlighting the benefits of time-ordered corpora for temporal tasks [39](https://www.semanticscholar.org/paper/c1130a3634facb2a22edde49adb58ee6f042c585). Large-scale temporally annotated resources, such as the PubMed Open Access Textual Time Series Corpus (PMOA-TTS), are being created to facilitate timeline extraction, temporal reasoning, and longitudinal modeling [40](https://www.semanticscholar.org/paper/ebf5eee9f8997ebd0586817e9fa4bacc8a1dad76).

Despite these advancements, several challenges persist for widespread adoption. Computational intensity and the need for specialized hardware remain significant hurdles, especially for larger LLMs. Data privacy and security concerns necessitate robust de-identification and privacy-preserving techniques like federated learning. Ensuring model generalizability across diverse healthcare systems, patient populations, and evolving clinical practices is crucial. The inherent variability and complexity of clinical language, coupled with regulatory requirements, demand meticulous validation and human oversight to prevent "hallucinations" or errors. The ongoing development of robust benchmarks, such as BRIDGE, which evaluates LLMs on real-world clinical data across multiple languages and tasks, is essential for guiding future research and deployment [15](https://www.semanticscholar.org/paper/3982dd06568c983e94cd748ddaf123829160ee7e). Furthermore, the strategic use of Retrieval-Augmented Generation (RAG) systems, like MIRIAD, which ground LLMs in curated medical knowledge, is vital for mitigating the risk of inaccurate medical content [41](https://www.semanticscholar.org/paper/b1afad9875b76d2746c9c1bcad2c693110920987). Efforts to address data scarcity and enable the translation of clinical data across languages also promise to bridge critical gaps in global clinical research [42](https://www.semanticscholar.org/paper/07c373c2963516cd0ac528623a745d3173638fd6), [43](https://www.semanticscholar.org/paper/e0aa296cd6c9fc7f2cbfde9ff9fc21f94cd860e), [44](https://www.semanticscholar.org/paper/351c2d7d3ce909acdfa289eccc03464ddbd028cb). The synergy of these AI-driven approaches promises to significantly enhance the efficiency, accuracy, and scalability of clinical data management, ultimately accelerating the pace of medical discovery and improving patient care.

# Accelerating Trial Planning through Synthetic Data and Simulations

The accelerating pace of clinical research demands innovative approaches to overcome traditional bottlenecks, particularly data scarcity and privacy concerns. *In silico* testing, powered by advanced artificial intelligence (AI) models, is emerging as an indispensable tool for optimizing trial designs, predicting outcomes, and validating AI models without relying on sensitive real-world patient data. This involves generating realistic synthetic patient cohorts, medical imaging data, and spatio-temporal disease progression models.

One significant area of advancement lies in simulating longitudinal medical imaging data to understand disease progression. For instance, the 4D-VQ-GAN model introduces a method for generating realistic future CT (Computed Tomography) scans for conditions like Idiopathic Pulmonary Fibrosis (IPF) [45](https://arxiv.org/pdf/2502.05713v1). This model operates by training a 3D-VQ-GAN to reconstruct CT volumes in a first stage, followed by a Neural ODE (Neural Ordinary Differential Equation)-based temporal model to capture the continuous temporal dynamics of the quantised embeddings [45](https://arxiv.org/pdf/2502.05713v1). The rationale behind using Neural ODEs is their ability to learn complex, non-linear progression patterns, moving beyond simpler linear assumptions common in earlier models [45](https://arxiv.org/pdf/2502.05713v1). This capability allows for simulating disease progression under various treatment scenarios, which can aid in optimizing trial duration, identifying suitable patient cohorts, and developing imaging biomarkers as surrogate endpoints, thereby potentially accelerating drug approval processes [45](https://arxiv.org/pdf/2502.05713v1). However, a key limitation of this approach is its reliance on a deterministic Neural ODE, which may not fully capture the inherent heterogeneity of diseases like IPF, and its validation on a single dataset limits generalizability [45](https://arxiv.org/pdf/2502.05713v1). Neural ODEs are also generally limited by requiring all data to be captured in the initial value, making them less suitable for continuously updating hidden states as new data becomes available, a challenge that Neural CDEs (Neural Controlled Differential Equations) aim to overcome [46](https://arxiv.org/pdf/2410.03514v3).

Further enhancing synthetic medical imaging, Latent Diffusion Models (LDMs) are being employed for conditional MRI (Magnetic Resonance Imaging) generation, allowing synthesis conditioned on specific pathologies (e.g., Healthy, Glioblastoma, Sclerosis, Dementia) and acquisition modalities (e.g., T1w, T1ce) [47](https://arxiv.org/pdf/2502.18620v1). This method optimizes image generation by performing diffusion in a compressed latent space, significantly reducing computational load while maintaining visual quality [47](https://arxiv.org/pdf/2502.18620v1). The ability to generate images in combinations not present in the original training data demonstrates a crucial extrapolation capability, valuable for augmenting datasets for rare diseases or underrepresented patient subgroups in clinical trials [47](https://arxiv.org/pdf/2502.18620v1). These synthetic images can also serve as robust tools for evaluating AI-based diagnostic algorithms prior to clinical deployment, ensuring their reliability and accuracy [47](https://arxiv.org/pdf/2502.18620v1). Despite these advantages, the model's performance can be affected by training data imbalance, and the proprietary nature of its internal details hinders independent validation and reproducibility [47](https://arxiv.org/pdf/2502.18620v1). Furthermore, traditional metrics like Fréchet Inception Distance (FID) and Multi-Scale Structural Similarity Index (MS-SSIM) may not fully capture the clinical relevance, necessitating expert radiological evaluation [47](https://arxiv.org/pdf/2502.18620v1). This echoes the broader challenge in generative model assessment in data-scarce domains, where utility, robustness, and privacy extend beyond the generative learning trilemma of fidelity, diversity, and sampling efficiency [48](https://www.semanticscholar.org/paper/9e14ae8063ebbd25db4eb40965e4c04babf445e4).

Beyond imaging, synthetic data generation extends to Electronic Health Records (EHR) and spatio-temporal data. The HiSGT model, for example, generates high-fidelity synthetic EHR data by integrating hierarchical and semantic information from medical codes [49](https://arxiv.org/pdf/2502.20719v1). This is critical because traditional methods often treat EHRs as flat sequences, overlooking the rich, structured nature of clinical coding systems. By embedding parent-child and sibling relationships through a hierarchical graph and fusing these with semantic embeddings from clinical language models, HiSGT creates more nuanced and clinically relevant synthetic patient sequences [49](https://arxiv.org/pdf/2502.20719v1). Such high-fidelity datasets can augment limited real-world trial data, create privacy-preserving datasets for algorithm development, and simulate diverse patient populations for trial optimization [49](https://arxiv.org/pdf/2502.20719v1). However, its generalizability across different healthcare systems and its utility for complex clinical trial endpoints still require further comprehensive assessment [49](https://arxiv.org/pdf/2502.20719v1). The computational cost and need for expertise in graph neural networks and clinical language models also pose adoption barriers [49](https://arxiv.org/pdf/2502.20719v1). This aligns with broader concerns about LLMs struggling to preserve realistic distributions and correlations as data dimensionality increases in synthetic EHR generation [50](https://www.semanticscholar.org/paper/780e184d0e0cec844353f9fd94af58100bd2bc26).

For spatio-temporal disease progression and other dynamic scenarios, synthetic datasets generated from PDEs (Partial Differential Equations) offer a controlled environment for testing machine learning models [51](https://arxiv.org/pdf/2502.04140v1). These datasets can model phenomena such as disease spread (e.g., epidemiological models based on the SIR-ODE (Susceptible-Infected-Recovered Ordinary Differential Equation) with spatial diffusion), atmospheric particle movement, or tsunami waves, which are relevant for understanding the spread of infections or the impact of interventions across regions [51](https://arxiv.org/pdf/2502.04140v1). By using methods like the FEM (Finite Element Method) to solve PDEs, researchers can create large, high-quality spatio-temporal graph datasets for benchmarking and pre-training [51](https://arxiv.org/pdf/2502.04140v1). Crucially, transfer learning experiments have shown that models pre-trained on these synthetic datasets can significantly improve performance on real-world epidemiological data, suggesting their potential to enhance prediction accuracy even with limited real data [51](https://arxiv.org/pdf/2502.04140v1). Nevertheless, the simplified nature of PDEs means these synthetic datasets may not fully capture the complexities of real-world clinical trial scenarios, such as patient heterogeneity or intricate intervention effects. The computational cost of solving high-dimensional PDEs and the lack of direct representation of clinical trial-specific elements (e.g., treatment arms) remain limitations [51](https://arxiv.org/pdf/2502.04140v1).

The generation of high-quality synthetic data is further complicated by the challenge of crafting effective prompts for large-scale prompt-based models, especially in data-free settings crucial for sensitive domains like healthcare. Automatic prompt optimization techniques are being explored to address this, leveraging feedback-driven, error-based, and control-theoretic approaches to refine prompt quality and authenticity without direct access to real datasets [52](https://arxiv.org/pdf/2502.03078v2). These frameworks aim to automate the synthetic data generation process, reducing manual intervention and enhancing realism for training AI models in tasks like predicting patient outcomes or optimizing trial designs [52](https://arxiv.org/pdf/2502.03078v2). However, the transferability of these prompt optimization techniques to the specific nuances of clinical trial data (e.g., longitudinal data, complex inclusion/exclusion criteria) still requires validation [52](https://arxiv.org/pdf/2502.03078v2). The broader field of synthetic tabular data generation highlights that while generative models offer promise, challenges remain in ensuring high fidelity, utility, and adherence to domain-specific constraints, often requiring explicit domain knowledge alongside hyperparameter optimization for clinically valid outputs [53](https://www.semanticscholar.org/paper/62623220ebe64c1ae134c51b73a1ab37667761d5), [54](https://www.semanticscholar.org/paper/e56e9f956e2965f02e5d3e621c600de3947cbf1a).

Overall, synthetic data generation and simulation models are revolutionizing trial planning by addressing fundamental challenges of data accessibility and privacy. From simulating disease progression through advanced imaging to generating realistic EHRs and spatio-temporal epidemiological patterns, these technologies provide powerful tools for *in silico* experimentation. While challenges in generalizability, clinical relevance, and computational cost persist, ongoing research is refining these methods, paving the way for more efficient, ethical, and personalized clinical trials.

# AI for Personalized Treatment Strategies and Predictive Analytics

Artificial intelligence (AI) is transforming clinical trials by enabling a more personalized approach to medicine, moving beyond generalized treatments to interventions tailored to individual patient characteristics. This paradigm shift relies on advanced AI methods for estimating heterogeneous treatment effects, predicting individual drug responses using multimodal data, and enhancing the analysis of complex physiological signals for precise outcome prediction and adverse event detection.

### Estimating Heterogeneous Treatment Effects and Personalizing Interventions

A central goal in personalized medicine is to identify which patients will benefit most from a specific treatment. Estimating HTE (Heterogeneous Treatment Effects) in time-to-event outcomes, a common challenge in clinical trials, is addressed by methods like MISTR (Multiple Imputation for Survival Treatment Response) [55](https://arxiv.org/pdf/2502.01575v1). MISTR is a novel, non-parametric approach that leverages recursively imputed survival trees to handle right-censoring, a frequent issue in survival data where the exact event time is unknown. Critically, MISTR also extends to settings with unobserved confounders by incorporating instrumental variables, a significant advancement for analyzing real-world observational data. This capability allows for more accurate HTE estimation, enabling researchers to identify specific patient subgroups that disproportionately benefit from interventions, thereby optimizing patient stratification and potentially reducing trial costs and sample sizes. However, MISTR's applicability depends on assumptions like ignorability of censoring and the availability of strong instrumental variables, and its computational complexity can be substantial [55](https://arxiv.org/pdf/2502.01575v1).

Complementing HTE estimation, counterfactual generation models enable *in silico* simulation of intervention effects. CLEF (Controllable Sequence Editing for Counterfactual Generation) [56](https://arxiv.org/pdf/2502.03569v1) provides a mechanism for precise, localized modifications of patient trajectories based on hypothetical interventions (e.g., drug dosages or schedules). This allows for reasoning about "what if" scenarios, which is invaluable for optimizing clinical trial design, personalizing treatment strategies by predicting individual responses, and enhancing patient stratification. CLEF learns temporal concepts to selectively edit relevant time steps, improving immediate and delayed effect prediction. Despite its promise, CLEF's effectiveness hinges on the quality and quantity of training data, and its current design may not fully capture higher-order relationships between variables or integrate real-world causal models, which are complex to define for multifactorial diseases [56](https://arxiv.org/pdf/2502.03569v1). The development of causally-informed prediction models, such as CRISP, which uses native counterfactuals to augment data and enhance generalizability for tasks like ICU (Intensive Care Unit) mortality prediction, further illustrates the importance of causal reasoning in clinical AI [57](https://www.semanticscholar.org/paper/61bf28607fd8973bdeec162873dab240cfeefa67). Similarly, target-oriented diffusion frameworks like TarDiff focus on generating synthetic Electronic Health Record (EHR) time series that optimize downstream model performance rather than merely replicating statistical distributions, addressing data scarcity and class imbalance to improve clinical model utility [58](https://www.semanticscholar.org/paper/63ca8f86de6b2c3299e4fd6fd28e1c24cf040341).

The choice of statistical and machine learning models for survival analysis also impacts personalization. A comparative study of Cox proportional hazards models and RSF (Random Survival Forests) for predicting patient-specific survival probabilities in clinical trial data revealed that RSF often outperforms Cox models in discrimination (Harrell's C-index), particularly with smaller sample sizes, while Cox models may exhibit better calibration in some scenarios, especially with non-proportional hazards [59](https://arxiv.org/pdf/2502.03119v1). RSF's performance can be more sensitive to higher censoring rates, a common issue in clinical trials, and its overall performance can be influenced by the choice of splitting rules. These findings emphasize the trade-offs between predictive accuracy and calibration, crucial considerations for developing prognostic models that inform personalized treatment decisions [59](https://arxiv.org/pdf/2502.03119v1).

### Harnessing Multimodal Data for Individual Drug Responses and Drug Safety

Predicting individual drug responses is fundamental to personalized medicine and clinical trial efficiency. The Foundation-Model-boosted Multimodal Learning framework (FMM$_{TC}$) for fMRI (functional Magnetic Resonance Imaging)-based Neuropathic Pain Drug Response Prediction [60](https://arxiv.org/pdf/2503.00210v1) exemplifies how multimodal data can be leveraged. FMM$_{TC}$ integrates resting-state fMRI time series and functional connectivity information, boosted by an fMRI foundation model trained on extensive pain-agnostic datasets. This approach addresses the pervasive challenge of data scarcity in specialized medical research, enhancing representation ability and generalizability, which can lead to more efficient participant stratification in clinical trials for neuropathic pain. However, its effectiveness relies on the availability and standardization of fMRI data and faces limitations due to small in-house datasets for validation [60](https://arxiv.org/pdf/2503.00210v1). The broader trend of multimodal integration in healthcare, as highlighted by Multi-Uni-Modal (MUM), shows how combining diverse data sources (biosignals, imaging, audio, lab reports) can improve diagnostic power even with unpaired datasets, enhancing task performance and robustness to data imbalance [61](https://www.semanticscholar.org/paper/adcdfc5ba7a60a05d20f9e06882817952904e36d). Similarly, Infi-Med provides a resource-efficient framework for medical MLLMs (Multimodal Large Language Models), demonstrating enhanced reasoning and rapid adaptability to clinical scenarios with minimal sample requirements [62](https://www.semanticscholar.org/paper/fd1d271d0cb4aba04aea8a495cfb2f85e03ac310).

The integration of visual and linguistic information through MLLMs is also proving valuable. Lavender [63](https://arxiv.org/pdf/2502.06814v1) introduces a supervised fine-tuning method that enhances advanced VLMs (Vision-Language Models) by aligning their text-vision attention mechanisms with those of state-of-the-art image generation models like Stable Diffusion. This alignment enriches visual understanding, significantly boosting performance across vision-language reasoning benchmarks, including challenging medical QA (Question Answering) tasks. In clinical trials, improved VLMs could automate medical imaging analysis, integrate diverse data streams for a holistic patient view, and enhance medical question answering, thereby optimizing trial design [63](https://arxiv.org/pdf/2502.06814v1). Despite its efficiency in training data requirements, the method relies on supervised fine-tuning and faces limitations related to data scarcity in specialized medical domains and potential biases inherent in medical image datasets [63](https://arxiv.org/pdf/2502.06814v1). Comprehensive surveys highlight the rapid advancements and challenges in MLLMs for medical reporting, diagnosis, and treatment [64](https://www.semanticscholar.org/paper/427781f67ea66a168a323a75fad3f6958451bf8d), [65](https://www.semanticscholar.org/paper/a4730fd88d2249de1bed9a0f1a9a7641b1caba8d), while specific work explores reinforcement learning for fine-tuning medical VQA, aiming for clinically grounded model behavior [66](https://www.semanticscholar.org/paper/945082498d29f3f88882da6d09a20e5aefb83cb5).

Beyond individual drug responses, AI's role in predicting DDIs (Drug-Drug Interactions) is crucial for patient safety and trial design. Studies demonstrate the potential of Large Language Models (LLMs) to accurately predict DDIs by processing molecular structures (SMILES - Simplified Molecular-Input Line-Entry System), target organisms, and gene interaction data as raw text [67](https://arxiv.org/pdf/2502.06890v1). Fine-tuned LLMs have shown superior performance over traditional machine learning methods in DDI prediction, achieving high sensitivity and accuracy. This capability can proactively identify potentially unsafe drug combinations, leading to more secure trial protocols and enhancing post-market surveillance. While promising, current LLM approaches primarily predict the *presence* of a DDI, but not its severity or mechanism, limiting their utility for detailed clinical trial design [67](https://arxiv.org/pdf/2502.06890v1). Furthermore, their reliance on textual drug information may overlook other patient-specific factors like genetic variations or comorbidities. The increasing application of LLMs in healthcare extends to diverse tasks, including forecasting from clinical textual time series [39](https://www.semanticscholar.org/paper/c1130a3634facb2a22edde49adb58ee6f042c585), bridging EHRs and clinical texts through contrastive learning [68](https://www.semanticscholar.org/paper/7e6cac75f28a8e1b9be883597a56d3bb6da8bb04), and adaptable cardiovascular disease risk prediction [69](https://www.semanticscholar.org/paper/bbf22ac0f6c21f3cb173b95a6c506418c2532947), underscoring their broad utility in clinical decision support and patient safety [65](https://www.semanticscholar.org/paper/a4730fd88d2249de1bed9a0f1a9a7641b1caba8d), [70](https://www.semanticscholar.org/paper/a475b202ecc3b5ec532dcfbad7092fbe3846abf7). Efforts are also underway to establish robust benchmarks for LLMs in real-world clinical practice text to address performance variations across models and tasks [15](https://www.semanticscholar.org/paper/3982dd06568c983e94cd748ddaf123829160ee7e).

### Advanced Analytics of Complex Physiological Signals

Automated and robust analysis of physiological signals, such as ECGs (Electrocardiograms), is vital for patient monitoring, adverse event detection, and inclusion criteria in clinical trials. The Multi-scale Masked Autoencoder for ECG anomaly detection (MMAE-ECG) [71](https://arxiv.org/pdf/2502.05494v1) offers an end-to-end framework that effectively captures global and local dependencies in ECG data without requiring pre-processing steps like R-peak detection or heartbeat segmentation. This significantly enhances its suitability for real-world clinical data, which is often noisy. MMAE-ECG achieves performance comparable to state-of-the-art methods while dramatically reducing computational complexity, enabling faster analysis of large datasets and timely detection of adverse events in trials. Its anomaly localization capability provides deeper insights into specific abnormal regions [71](https://arxiv.org/pdf/2502.05494v1). Despite its efficiency, the study does not fully address regulatory challenges for AI-based diagnostics or the model's generalizability across diverse ECG recording devices and patient subgroups [71](https://arxiv.org/pdf/2502.05494v1). Further advancements in ECG analysis involve integrating learnable expert knowledge into deep learning models, which can adapt during training to refine this knowledge and guide feature separation, leading to improved multi-label ECG classification and enhanced interpretability [72](https://www.semanticscholar.org/paper/2470b0ffbf6641772fd9ab8530dd8e7cc162ada7). Optimized CNNs (Convolutional Neural Networks) are also being developed for accurate arrhythmia detection, addressing issues like class imbalance and generalization through multi-scale feature extraction and sophisticated preprocessing [73](https://www.semanticscholar.org/paper/64b441e2c425554d380a7f29794f57346b6e2c08).

Another innovative approach leverages LLMs for ECG analysis. SuPreME (Supervised Pre-training Framework for Multimodal ECG Representation Learning) [74](https://arxiv.org/pdf/2502.19668v1) utilizes LLMs to extract clinically relevant information directly from free-text ECG reports, enabling zero-shot classification of unseen cardiac conditions. This capability could streamline patient selection and stratification in trials, reduce manual effort from expert cardiologists, and accelerate the identification of cardiac abnormalities, thus improving trial efficiency and safety. However, the performance of SuPreME is highly dependent on the quality and consistency of these free-text reports, and the computational cost associated with training and deploying LLMs remains a barrier [74](https://arxiv.org/pdf/2502.19668v1). The application of LLMs to clinical text extends to various predictive tasks, including drug overdose prediction from longitudinal medical records [70](https://www.semanticscholar.org/paper/a475b202ecc3b5ec532dcfbad7092fbe3846abf7) and identifying complex clinical trial designs in biomedical literature [75](https://www.semanticscholar.org/paper/bdac0e43d0bf77c037bcbe4d13ec566013af6e65).

### Challenges and Future Outlook

While AI demonstrates immense potential for personalizing treatment strategies and enhancing predictive analytics in clinical trials, several overarching challenges persist. Data scarcity, particularly for rare outcomes or specific multimodal datasets, remains a significant limitation, often necessitating transfer learning or foundation models as seen with FMM$_{TC}$ [60](https://arxiv.org/pdf/2503.00210v1) and Lavender [63](https://arxiv.org/pdf/2502.06814v1). The generalizability of models across diverse patient populations, clinical settings, and recording protocols is crucial but often unexplored, as highlighted in the limitations of MMAE-ECG [71](https://arxiv.org/pdf/2502.05494v1). Computational costs and the need for specialized expertise also pose practical barriers to widespread adoption and deployment of complex AI frameworks [55](https://arxiv.org/pdf/2502.01575v1), [60](https://arxiv.org/pdf/2503.00210v1), [74](https://arxiv.org/pdf/2502.19668v1), [63](https://arxiv.org/pdf/2502.06814v1).

A critical aspect for clinical adoption is **interpretability** and **explainability**. While some models offer insights through attention mechanisms or anomaly localization [71](https://arxiv.org/pdf/2502.05494v1), [72](https://www.semanticscholar.org/paper/2470b0ffbf6641772fd9ab8530dd8e7cc162ada7), the "black-box" nature of many deep learning models remains a concern, especially in high-stakes medical decision-making. Future research must focus on developing models that provide transparent justifications for their predictions, which is crucial for clinician trust and regulatory approval. The development of methods like AutoCT, which autonomously generates and refines tabular features with LLM agents for interpretable clinical trial prediction, represents a promising direction [76](https://www.semanticscholar.org/paper/66f9a84c44e147fdad9d983a0ca52d9284ee17f2).

**Ethical considerations** including data privacy, patient consent, and mitigating algorithmic bias are paramount. Models trained on biased datasets can perpetuate or amplify existing healthcare disparities, underscoring the need for careful attention to dataset construction and evaluation across subgroups [77](https://www.semanticscholar.org/paper/7e0034d2f5a8d1d6ec7d5ea19b2e2100b02021c6). De-identification frameworks like RedactOR are essential to balance data utility with privacy in clinical data processing [37](https://www.semanticscholar.org/paper/6a8ff1b5fc096dab785873732509e29f1752fba7).

The burgeoning field of **foundation models** and LLMs, trained on vast amounts of clinical text and EHR data, holds significant promise. These models can capture complex temporal dependencies and reasoning patterns inherent in patient trajectories [39](https://www.semanticscholar.org/paper/c1130a3634facb2a22edde49adb58ee6f042c585), [78](https://www.semanticscholar.org/paper/b4f2f2cd5f9cf6af81521c86ad47bf50107d6561), [79](https://www.semanticscholar.org/paper/0460ef4c042f24faf9ebc139279af62e4aceb0f7). Efforts to scale these models effectively in the EHR domain [79](https://www.semanticscholar.org/paper/0460ef4c042f24faf9ebc139279af62e4aceb0f7), [80](https://www.semanticscholar.org/paper/ae943be2991f4e8d4ca5dc0185747fa1d5915dba) and adapt them for specific medical tasks, such as early rare disease detection [81](https://www.semanticscholar.org/paper/563d994acaf43f3bdcf4e4ebb7146f41a9085511) or cancer pre-screening [82](https://www.semanticscholar.org/paper/196d14249ca8f448002a62c8766f48895a15d5c5), are rapidly advancing. Continued pretraining and reasoning preference optimization can stabilize reasoning in medical LLMs, ensuring both high accuracy and reliable explanations [18](https://www.semanticscholar.org/paper/cae8cdae8df2600c578312f1a2ac431537292d5d), [83](https://www.semanticscholar.org/paper/bb26c61cbe322a4f8cf81e8e461d680a5ff05923). The future of AI in personalized medicine for clinical trials lies in developing robust, interpretable, and ethically sound models that can seamlessly integrate multimodal data to support precise patient stratification, optimize treatment protocols, and proactively ensure safety, ultimately accelerating the delivery of targeted therapies.

# Ensuring Trustworthiness: Explainability, Privacy, and Integrity in AI-Enhanced Trials

*Content for this section was not provided in the assembled draft due to an agent error.*

# AI for Streamlined Communication and Collaborative Research in Clinical Trials

Effective communication and seamless collaboration are cornerstones of successful clinical trial execution, impacting everything from patient adherence to the rigor of research design. The advent of artificial intelligence (AI), particularly Large Language Models (LLMs), offers transformative potential to bridge existing gaps and optimize various facets of communication and teamwork in this complex domain.

### Enhancing Patient-Clinician Dialogue and Education

LLMs are demonstrating significant promise in improving patient engagement and understanding, crucial for recruitment, informed consent, and adherence in clinical trials. A notable example is the proposed integration of LLMs into digital adherence technologies to augment interactive communication between patients and treatment supporters, as demonstrated in a study on tuberculosis care in multilingual settings [84](https://arxiv.org/pdf/2502.21236v1). This approach aims to provide timely, culturally relevant information, thereby reducing the burden on healthcare providers and enhancing patient adherence. The exploration of privacy-preserving techniques in such systems is vital for handling sensitive patient data [84](https://arxiv.org/pdf/2502.21236v1).

Beyond direct communication, LLMs can simplify complex medical information, making it more accessible to patients with varying health literacy levels. The MeDiSumQA dataset, generated by LLMs from discharge letters, exemplifies how patient-friendly summaries and question-answer pairs can be created [85](https://arxiv.org/pdf/2502.03298v1). This capability can significantly enhance the informed consent process in clinical trials by ensuring participants clearly understand trial procedures, risks, and benefits. The finding that general-purpose LLMs can sometimes outperform biomedical-adapted models in such tasks suggests a broader applicability for clinical trial automation, potentially reducing the need for highly specialized models [85](https://arxiv.org/pdf/2502.03298v1). Challenges remain in extending these capabilities to diverse clinical documents beyond discharge summaries, such as study protocols or clinical study reports, and ensuring their applicability across multilingual trial settings [85](https://arxiv.org/pdf/2502.03298v1). Research into multilingual benchmarks, such as MedArabiQ for Arabic medical tasks [86](https://www.semanticscholar.org/paper/00873a8228e515b87a0e0690cff8fbc1e71200e9) and PerMedCQA for Persian consumer questions [43](https://www.semanticscholar.org/paper/e0aa296cd6c9fc7f2cbfde9ff9fc21f94cd860e), is crucial for equitable deployment of LLMs in healthcare globally [86](https://www.semanticscholar.org/paper/00873a8228e515b87a0e0690cff8fbc1e71200e9). The development of specialized small language models (SLMs) leveraging online data also highlights efforts to address low-resource languages and privacy concerns [87](https://www.semanticscholar.org/paper/c06557b713b5e327e668fd25abaf20fabafd6bea), [23](https://www.semanticscholar.org/paper/d0e6b0a43edec2424005ee900c6d657597bd7d16).

### Optimizing Team Coordination and Research Processes

AI can also foster improved coordination among clinical trial teams and streamline foundational research activities. The Socratic system, an AI-enabled coach for real-time teamwork, provides a compelling blueprint for enhancing clinical trial management [88](https://arxiv.org/pdf/2502.17643v1). By monitoring team behavior and detecting misalignments in understanding trial protocols or data nuances, Socratic-like systems could proactively suggest corrective actions, thereby reducing errors and improving overall trial quality and efficiency. The interactive UI for delivering recommendations is crucial for user adoption, and the AI coach's role as a complement rather than a replacement for human tasks helps build trust [88](https://arxiv.org/pdf/2502.17643v1). However, scaling such systems from simplified dyadic tasks to complex, multidisciplinary clinical trial teams presents significant challenges, as does integrating them with existing workflows and addressing the black-box nature of some AI outputs [88](https://arxiv.org/pdf/2502.17643v1).

For research design, the NeuroLit Navigator demonstrates how AI can enhance the efficiency and accuracy of literature reviews [89](https://arxiv.org/pdf/2503.00278v1). By combining domain-specific LLMs with structured knowledge sources like MeSH (Medical Subject Headings) and UMLS (Unified Medical Language System), the system refines query formulation, expands search vocabularies, and deepens search scopes, significantly reducing the time required for initial literature searches [89](https://arxiv.org/pdf/2503.00278v1). This is invaluable for identifying knowledge gaps, selecting appropriate patient populations, and assessing risks during trial design. While this system improves article retrieval, it still requires manual screening and refinement by experts [89](https://arxiv.org/pdf/2503.00278v1). Similarly, the LLM-TA (LLM-Enhanced Thematic Analysis) pipeline offers a significant advancement for analyzing qualitative data from patient interviews or focus groups in clinical trials [90](https://arxiv.org/pdf/2502.01620v1). By automating the initial stages of thematic analysis, researchers can gain insights into patient experiences and adherence barriers, informing more patient-centric trial designs [90](https://arxiv.org/pdf/2502.01620v1). However, expert evaluation highlights the need for ongoing human oversight to address potential biases and ensure clinical context is accurately captured [90](https://arxiv.org/pdf/2502.01620v1).

### Collaborative AI Model Development and Data Processing

AI also offers solutions for optimizing the development and deployment of LLMs for clinical trial tasks. AutoMedPrompt, which uses textual gradients for prompt optimization, can significantly improve the efficiency and accuracy of LLMs in tasks such as data extraction from clinical trial protocols, adverse event monitoring, patient recruitment, and regulatory compliance [91](https://arxiv.org/pdf/2502.15944v1). Its ability to surpass proprietary models without extensive fine-tuning is particularly beneficial for resource-constrained settings [91](https://arxiv.org/pdf/2502.15944v1). However, the approach's generalizability across diverse clinical trial tasks, its reliance on LLM-generated responses, and the computational costs associated with API-based setups are limitations [91](https://arxiv.org/pdf/2502.15944v1).

Addressing the critical challenge of data silos and privacy in healthcare, MedForge proposes a cooperative framework for building medical foundation models through collaborative knowledge integration [92](https://arxiv.org/pdf/2502.16055v1). By enabling multiple institutions to contribute distilled datasets, MedForge can accelerate model development and enhance generalizability across diverse patient populations without sharing raw patient data [92](https://arxiv.org/pdf/2502.16055v1). This asynchronous merging scheme allows for flexible contributions, crucial for multi-center clinical trials [92](https://arxiv.org/pdf/2502.16055v1). The framework's current focus on image classification tasks suggests further investigation is needed for its applicability to other clinical trial data types, such as electronic health records or genomic data [92](https://arxiv.org/pdf/2502.16055v1). Building on this, the Hephaestus-Forge pre-training corpus enhances LLM agentic capabilities, including API function calling and reasoning, which could automate tasks like patient recruitment from EHRs and data extraction from reports [93](https://arxiv.org/pdf/2502.06589v1). While promising for general AI agents, domain-specific adaptation for clinical trial contexts remains a key area for development [93](https://arxiv.org/pdf/2502.06589v1). The concept of leveraging specialized SLMs within a 'learnware' paradigm further supports the collaborative and privacy-preserving reuse of models for specific medical domains [94](https://www.semanticscholar.org/paper/ccef102e80438c5ea9901c0e13198cfd3e685e87).

Furthermore, Retrieval-Augmented Generation (RAG) approaches, which combine generative LLMs with external knowledge retrieval, are gaining traction in biomedicine to enhance factual accuracy and integrate up-to-date information [5](https://www.semanticscholar.org/paper/ea2f72b979e2646dec92a9ce9b6b07dd0a20e789). This is critical for tasks like linking clinical data elements to controlled vocabularies using frameworks like CDE-Mapper [6](https://www.semanticscholar.org/paper/ecc3051e19f7713350e0950b6cde1f0841ca2d7c) or improving medical question-answering systems [95](https://www.semanticscholar.org/paper/c0239788924415765305bd23e054dd06404f866b). Evaluation frameworks like RAGEv assess the trustworthiness of RAG in health documents [96](https://www.semanticscholar.org/paper/78452726f73fa58e22391cc8b3b7819f38fc24bf).

### Broader AI Contributions to Trial Efficiency and Beyond

Beyond communication and collaboration, AI's role in accelerating clinical trial efficiency extends to other critical areas. Explainable drug recommendation systems, such as KEDRec-LM (Knowledge-distilled Explainable Drug Recommendation Large Language Model), informed by the expRxRec dataset, can streamline drug repurposing and novel drug development by providing clear rationales for candidate selection, thereby aiding trial design and patient selection [97](https://arxiv.org/pdf/2502.20350v1). Similarly, Deep Active Learning frameworks can optimize the discovery of effective combination therapies by efficiently exploring synergistic genetic interactions, reducing the number of preclinical experiments required [98](https://arxiv.org/pdf/2502.01012v1). For data visualization and reporting, multi-agent frameworks like METAL (Multi-Agent Framework for Chart Generation with Test-Time Scaling) can automate the generation of accurate charts from visual references, streamlining report generation and ensuring consistency in presenting clinical trial results [99](https://arxiv.org/pdf/2502.17651v3). This is particularly relevant for generating standardized charts adhering to regulatory guidelines, though challenges exist in integrating such systems into existing clinical data management workflows and managing computational costs [99](https://arxiv.org/pdf/2502.17651v3).

### Challenges and Future Outlook

Despite these significant advancements, the widespread deployment of AI in clinical trials faces inherent challenges. These include ensuring factual accuracy and mitigating "hallucinations" in LLM outputs, particularly crucial in high-stakes medical contexts [96](https://www.semanticscholar.org/paper/78452726f73fa58e22391cc8b3b7819f38fc24bf), [100](https://www.semanticscholar.org/paper/cf927d5a0044eb56d203335949067c69c8184a45). Privacy concerns, data biases, generalizability across diverse populations, and the high computational costs of complex models necessitate continued research into privacy-preserving techniques (e.g., distilled datasets in MedForge [92](https://arxiv.org/pdf/2502.16055v1)), resource-efficient architectures (e.g., SLMs [23](https://www.semanticscholar.org/paper/d0e6b0a43edec2424005ee900c6d657597bd7d16)), and robust evaluation methods [100](https://www.semanticscholar.org/paper/cf927d5a0044eb56d203335949067c69c8184a45), [101](https://www.semanticscholar.org/paper/3c1c0364f3e1e7bbe6bcd5da4325888ca2bf3079), [102](https://www.semanticscholar.org/paper/dd9cb2ff121325bb6158df49b5df8243c815df67). The need for interpretability in AI-driven decisions (e.g., KEDRec-LM [97](https://arxiv.org/pdf/2502.20350v1)) and the necessity of human-in-the-loop validation for all AI-assisted processes remain paramount. Future work must focus on developing more comprehensive, multilingual benchmarks, fostering transparent and ethical AI development, and addressing regulatory complexities to fully realize AI's transformative potential in enhancing communication and collaboration for clinical trial success.

# Conclusion

The advancements detailed across the sections underscore the transformative potential of AI in accelerating and refining clinical trial processes. From automating intricate patient identification and pre-screening to enhancing the robust management of diverse clinical data, AI technologies are proving instrumental in streamlining operational bottlenecks. The capacity for *in silico* experimentation through the generation of high-fidelity synthetic data marks a significant leap in trial planning, addressing critical issues of data scarcity and privacy. Concurrently, AI's role in enabling personalized treatment strategies through the estimation of heterogeneous treatment effects and advanced physiological signal analysis promises more targeted and effective interventions. While these innovations converge towards a future of more efficient and precise clinical research, common challenges persist. These include ensuring model generalizability across diverse patient populations, managing significant computational demands, addressing data privacy concerns, enhancing model interpretability, and mitigating algorithmic bias. Continued research and collaboration are therefore essential to navigate these complexities, integrate AI ethically and robustly, and realize its full potential in advancing medical discovery.

# References

1. Angelo Ziletti, Leonardo D'Ambrosi (2025). *Generating patient cohorts from electronic health records using two-step retrieval-augmented text-to-SQL generation*. ArXiv:2502.21107v1. [https://arxiv.org/pdf/2502.21107v1](https://arxiv.org/pdf/2502.21107v1)
2. Xiongbin Gui, Hanlin Lv, Xiao Wang, Longting Lv, Yi Xiao, Lei Wang (2025). *Enhancing Hepatopathy Clinical Trial Efficiency: A Secure, Large Language Model-Powered Pre-Screening Pipeline*. ArXiv:2502.18531v1. [https://arxiv.org/pdf/2502.18531v1](https://arxiv.org/pdf/2502.18531v1)
3. Matthew Toles, Nikhil Balwani, Rattandeep Singh, Valentina Giulia Sartori Rodriguez, Zhou Yu (2025). *Program Synthesis Dialog Agents for Interactive Decision-Making*. ArXiv:2502.19610v2. [https://arxiv.org/pdf/2502.19610v2](https://arxiv.org/pdf/2502.19610v2)
4. Majd Abdallah, S. Nakken, M. Bierkens, Johanna Galvis, Alexis Groppi, S. Karkar, L. Meiqari, Maria A Rujano, Steve Canham, Rodrigo Dienstmann, R. Fijneman, E. Hovig, G. Meijer, Macha Nikolski (2025). *TrialMatchAI: An End-to-End AI-powered Clinical Trial Recommendation System to Streamline Patient-to-Trial Matching*. ArXiv:2505.08508. [https://www.semanticscholar.org/paper/4494f140797ded006edcb40443ad146f22574070](https://www.semanticscholar.org/paper/4494f140797ded006edcb40443ad146f22574070)
5. Jiawei He, Boya Zhang, H. Rouhizadeh, Yingjian Chen, Rui Yang, Jin Lu, Xudong Chen, Nan Liu, Irene Li, Douglas Teodoro (2025). *Retrieval-Augmented Generation in Biomedicine: A Survey of Technologies, Datasets, and Clinical Applications*. ArXiv:2505.01146. [https://www.semanticscholar.org/paper/ea2f72b979e2646dec92a9ce9b6b07dd0a20e789](https://www.semanticscholar.org/paper/ea2f72b979e2646dec92a9ce9b6b07dd0a20e789)
6. Komal Gilani, Marlo Verket, Christof Peters, M. Dumontier, Hans-Peter Brunner-La Rocca, V. Urovi (2025). *CDE-Mapper: Using Retrieval-Augmented Language Models for Linking Clinical Data Elements to Controlled Vocabularies*. ArXiv:2505.04365. [https://www.semanticscholar.org/paper/ecc3051e19f7713350e0950b6cde1f0841ca2d7c](https://www.semanticscholar.org/paper/ecc3051e19f7713350e0950b6cde1f0841ca2d7c)
7. Sajjadul Islam, Ayesha Siddika Nipu, Jiawei Wu, Praveen Madiraju (2025). *LLM-based Prompt Ensemble for Reliable Medical Entity Recognition from EHRs*. ArXiv:2505.08704. [https://www.semanticscholar.org/paper/1f95c6911773246f99117cd583f48f2435f658a6](https://www.semanticscholar.org/paper/1f95c6911773246f99117cd583f48f2435f658a6)
8. Haoyu Yang, Sanjoy Dey, Pablo Meyer (2025). *Genetics-Driven Personalized Disease Progression Model*. ArXiv:2503.00028v1. [https://arxiv.org/pdf/2503.00028v1](https://arxiv.org/pdf/2503.00028v1)
9. Yu-An Huang, Xiyue Cao, Zhu-Hong You, Yue-Chao Li, Xuequn Shang, Zhi-An Huang (2025). *scGSDR: Harnessing Gene Semantics for Single-Cell Pharmacological Profiling*. ArXiv:2502.01689v1. [https://arxiv.org/pdf/2502.01689v1](https://arxiv.org/pdf/2502.01689v1)
10. Xuejiao Zhao, Siyan Liu, Su-Yin Yang, Chunyan Miao (2025). *MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot*. ArXiv:2502.04413v1. [https://arxiv.org/pdf/2502.04413v1](https://arxiv.org/pdf/2502.04413v1)
11. Wuyang Lan, Wenzheng Wang, Changwei Ji, Guoxing Yang, Yongbo Zhang, Xiaohong Liu, Song Wu, Guangyu Wang (2025). *ClinicalGPT-R1: Pushing reasoning capability of generalist disease diagnosis with large language model*. ArXiv:10.48550/arXiv.2504.09421. [https://www.semanticscholar.org/paper/ada491d38e0821d2772898036bd53a5fe2cc2b5](https://www.semanticscholar.org/paper/ada491d38e0821d2772898036bd53a5fe2cc2b5)
12. Shuang Zhou, Jiashuo Wang, Zidu Xu, Song Wang, David Brauer, Lindsay Welton, Jacob C. Cogan, Yuen-Hei Chung, Lei Tian, Zaifu Zhan, Yu Hou, Mingquan Lin, Genevieve B. Melton, Rui Zhang (2025). *Uncertainty-Aware Large Language Models for Explainable Disease Diagnosis*. ArXiv:2505.03467. [https://www.semanticscholar.org/paper/099538285ce1f8e42fbed3e108a530c8673e03cd](https://www.semanticscholar.org/paper/099538285ce1f8e42fbed3e108a530c8673e03cd)
13. Georgy Noarov, Riccardo Fogliato, Martin Bertran, Aaron Roth (2025). *Stronger Neyman Regret Guarantees for Adaptive Experimental Design*. ArXiv:2502.17427v1. [https://arxiv.org/pdf/2502.17427v1](https://arxiv.org/pdf/2502.17427v1)
14. Tianyang Xie, Yong Ge (2025). *Fairness in Survival Analysis: A Novel Conditional Mutual Information Augmentation Approach*. ArXiv:2502.02567v1. [https://arxiv.org/pdf/2502.02567v1](https://arxiv.org/pdf/2502.02567v1)
15. Jiageng Wu, Bowen Gu, Ren Zhou, Kevin Xie, Doug Snyder, Yixing Jiang, Valentina Carducci, R. Wyss, R. J. Desai, Emily Alsentzer, L. A. Celi, A. Rodman, Sebastian Schneeweiss, Jonathan H. Chen, Santiago Romero-Brufau, K. J. Lin, Jie Yang (2025). *BRIDGE: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text*. ArXiv:10.48550/arXiv.2504.19467. [https://www.semanticscholar.org/paper/3982dd06568c983e94cd748ddaf123829160ee7e](https://www.semanticscholar.org/paper/3982dd06568c983e94cd748ddaf123829160ee7e)
16. Suhana Bedi, Hejie Cui, Miguel Fuentes, A. Unell, Michael Wornow, Juan M. Banda, N. Kotecha, Timothy Keyes, Yifan Mai, Mert Oez, Hao Qiu, Shrey Jain, Leonardo Schettini, Mehr Kashyap, J. Fries, Akshay Swaminathan, Philip Chung, Fateme Nateghi, Asad Aali, Ashwin Nayak, Shivam Vedak, Sneha S. Jain, Birju Patel, O. Fayanju, Shreya J. Shah, Ethan Goh, Dong-han Yao, Brian T. Soetikno, E. Reis, S. Gatidis, V. Divi, R. Capasso, Rachnanjali L Saralkar, Chia-Chun Chiang, Jenelle A Jindal, Tho Pham, Faraz Ghoddusi, Steven Lin, Albert S. Chiou, Christy Hong, Mohana Roy, M. Gensheimer, Hinesh Patel, Kevin A Schulman, Dev Dash, Danton Char, Lance Downing, F. Grolleau, K. Black, Bethel R Mieso, Aydin Zahedivash, Wen-wai Yim, Harshita Sharma, Tony Lee, Hannah Kirsch, Jennifer Lee, N. Ambers, Carlene Lugtu, Aditya Sharma, Bilal Mawji, A. Alekseyev, Vicky Zhou, Vikas Kakkar, Jarrod Helzer, Anurang Revri, Y. Bannett, Roxana Daneshjou, Jonathan Chen, Emily Alsentzer, Keith E. Morse, Nirmal Ravi, N. Aghaeepour, Vanessa Kennedy, A. Chaudhari, Thomas Wang, Sanmi Koyejo, M. Lungren, Eric Horvitz, Percy Liang, M. Pfeffer, Nigam H. Shah (2025). *MedHELM: Holistic Evaluation of Large Language Models for Medical Tasks*. ArXiv:2505.23802. [https://www.semanticscholar.org/paper/055f837d7b9cb855708cae3fee9104feb46d0dcb](https://www.semanticscholar.org/paper/055f837d7b9cb855708cae3fee9104feb46d0dcb)
17. Nariman Naderi, Zahra Atf, Peter R. Lewis, Aref Mahjoub far, Seyed Amir Ahmad Safavi-Naini, Ali Soroush (2025). *Evaluating Prompt Engineering Techniques for Accuracy and Confidence Elicitation in Medical LLMs*. ArXiv:2506.00072. [https://www.semanticscholar.org/paper/f6f8b6c25269ce53965cb65ef01b4b23a0d698fb](https://www.semanticscholar.org/paper/f6f8b6c25269ce53965cb65ef01b4b23a0d698fb)
18. Wataru Kawakami, Keita Suzuki, Junichiro Iwasawa (2025). *Stabilizing Reasoning in Medical LLMs with Continued Pretraining and Reasoning Preference Optimization*. ArXiv:10.48550/arXiv.2504.18080. [https://www.semanticscholar.org/paper/cae8cdae8df2600c578312f1a2ac431537292d5d](https://www.semanticscholar.org/paper/cae8cdae8df2600c578312f1a2ac431537292d5d)
19. Cliff Wong, Sam Preston, Qianchu Liu, Zelalem Gero, Jass Bagga, Sheng Zhang, Shrey Jain, Theodore Zhao, Yu Gu, Yanbo Xu, Sid Kiblawi, Roshanthi Weerasinghe, Rom Leidner, Kristina Young, Brian Piening, Carlo Bifulco, Tristan Naumann, Mu Wei, Hoifung Poon (2025). *Universal Abstraction: Harnessing Frontier Models to Structure Real-World Data at Scale*. ArXiv:2502.00943v1. [https://arxiv.org/pdf/2502.00943v1](https://arxiv.org/pdf/2502.00943v1)
20. Aynur Guluzade, Naguib Heiba, Zeyd Boukhers, Florim Hamiti, Jahid Hasan Polash, Yehya Mohamad, Carlos A Velasco (2025). *ELMTEX: Fine-Tuning Large Language Models for Structured Clinical Information Extraction. A Case Study on Clinical Reports*. ArXiv:2502.05638v1. [https://arxiv.org/pdf/2502.05638v1](https://arxiv.org/pdf/2502.05638v1)
21. Zaifu Zhan, Jun Wang, Shuang Zhou, Jiawen Deng, Rui Zhang (2025). *MMRAG: Multi-Mode Retrieval-Augmented Generation with Large Language Models for Biomedical In-Context Learning*. ArXiv:2502.15954v1. [https://arxiv.org/pdf/2502.15954v1](https://arxiv.org/pdf/2502.15954v1)
22. Bo An, Haitao Zhang, Longlong Ma, Zhen Zhao (2025). *End-to-end Chinese clinical event extraction based on large language model*. ArXiv:10.1038/s41598-025-00609-y. [https://www.semanticscholar.org/paper/94f49036a4475a2108fba85946e73bd30a1fe2e1](https://www.semanticscholar.org/paper/94f49036a4475a2108fba85946e73bd30a1fe2e1)
23. Muskan Garg, Shaina Raza, Shebuti Rayana, Xingyi Liu, Sunghwan Sohn (2025). *The Rise of Small Language Models in Healthcare: A Comprehensive Survey*. ArXiv:10.48550/arXiv.2504.17119. [https://www.semanticscholar.org/paper/d0e6b0a43edec2424005ee900c6d657597bd7d16](https://www.semanticscholar.org/paper/d0e6b0a43edec2424005ee900c6d657597bd7d16)
24. Mohammad Shoaib Ansari, Mohd Sohail Ali Khan, Shubham Revankar, Aditya Varma, A. S. Mokhade (2025). *Lightweight Clinical Decision Support System using QLoRA-Fine-Tuned LLMs and Retrieval-Augmented Generation*. ArXiv:2505.03406. [https://www.semanticscholar.org/paper/72afb9cbc91c104e3bf1ead3588c6977f173591f](https://www.semanticscholar.org/paper/72afb9cbc91c104e3bf1ead3588c6977f173591f)
25. Johannes Moll, Louisa Fay, Asfandyar Azhar, Sophie Ostmeier, Tim Lueth, S. Gatidis, Curtis P. Langlotz, Jean-Benoit Delbrouck (2025). *Structuring Radiology Reports: Challenging LLMs with Lightweight Models*. ArXiv:2506.00200. [https://www.semanticscholar.org/paper/3d7fc1824d6e6fde1b68c48015c9e3870ffd03db](https://www.semanticscholar.org/paper/3d7fc1824d6e6fde1b68c48015c9e3870ffd03db)
26. Jean-Philippe Corbeil, Amin Dada, Jean-Michel Attendu, Asma Ben Abacha, Alessandro Sordoni, Lucas Caccia, Franccois Beaulieu, Thomas Lin, J. Kleesiek, Paul Vozila (2025). *A Modular Approach for Clinical SLMs Driven by Synthetic Data with Pre-Instruction Tuning, Model Merging, and Clinical-Tasks Alignment*. ArXiv:2505.10717. [https://www.semanticscholar.org/paper/c668268d68e646ef9d1a4df35264450d32573ca4](https://www.semanticscholar.org/paper/c668268d68e646ef9d1a4df35264450d32573ca4)
27. Chayan Mondal, Duc-Son Pham, Ashu Gupta, Tele Tan, Tom Gedeon (2025). *Leveraging Prompt Engineering with Lightweight Large Language Models to Label and Extract Clinical Information from Radiology Reports*. ArXiv:10.1145/3701716.3717808. [https://www.semanticscholar.org/paper/335cd141c6f07bf3ce43eb058ace99c0d0448cac](https://www.semanticscholar.org/paper/335cd141c6f07bf3ce43eb058ace99c0d0448cac)
28. Aécio Santos, Eduardo H. M. Pena, Roque Lopez, Juliana Freire (2025). *Interactive Data Harmonization with LLM Agents*. ArXiv:2502.07132v2. [https://arxiv.org/pdf/2502.07132v2](https://arxiv.org/pdf/2502.07132v2)
29. Mohammad Beheshti, Lovedeep Gondara, Iris Zachary (2025). *Leveraging Language Models for Automated Patient Record Linkage*. ArXiv:10.48550/arXiv.2504.15261. [https://www.semanticscholar.org/paper/6c2f5ef88f7aabc3de3101e8ca3f19ba10f152df](https://www.semanticscholar.org/paper/6c2f5ef88f7aabc3de3101e8ca3f19ba10f152df)
30. A. Mavridis, Stergios Tegos, Christos Anastasiou, Maria Papoutsoglou, G. Meditskos (2025). *Large language models for intelligent RDF knowledge graph construction: results from medical ontology mapping*. ArXiv:10.3389/frai.2025.1546179. [https://www.semanticscholar.org/paper/c9d2616f0b49b9842c34309373f7d2b419f2bbcc](https://www.semanticscholar.org/paper/c9d2616f0b49b9842c34309373f7d2b419f2bbcc)
31. Stefan Hegselmann, Georg von Arnim, Tillmann Rheude, Noel Kronenberg, David Sontag, Gerhard Hindricks, Roland Eils, Benjamin Wild (2025). *Large Language Models are Powerful EHR Encoders*. ArXiv:2502.17403v2. [https://arxiv.org/pdf/2502.17403v2](https://arxiv.org/pdf/2502.17403v2)
32. Besat Kassaie, Frank Wm. Tompa (2025). *Improving Unstructured Data Quality via Updatable Extracted Views*. ArXiv:2502.18221v1. [https://arxiv.org/pdf/2502.18221v1](https://arxiv.org/pdf/2502.18221v1)
33. Juliano Genari, Guilherme Tegoni Goedert (2025). *Mining Unstructured Medical Texts With Conformal Active Learning*. ArXiv:2502.04372v1. [https://arxiv.org/pdf/2502.04372v1](https://arxiv.org/pdf/2502.04372v1)
34. Aleksandr Nesterov, Andrey Sakhovskiy, Ivan Sviridov, Airat Valiev, Vladimir Makharev, Petr Anokhin, Galina Zubkova, Elena Tutubalina (2025). *RuCCoD: Towards Automated ICD Coding in Russian*. ArXiv:2502.21263v1. [https://arxiv.org/pdf/2502.21263v1](https://arxiv.org/pdf/2502.21263v1)
35. Brian Wong, Kaito Tanaka (2025). *High-Fidelity Pseudo-label Generation by Large Language Models for Training Robust Radiology Report Classifiers*. ArXiv:2505.01693. [https://www.semanticscholar.org/paper/6a185f003963b317f6d89802dfc6f1b0fd9b0d0c](https://www.semanticscholar.org/paper/6a185f003963b317f6d89802dfc6f1b0fd9b0d0c)
36. Avisha Das, Ish A Talati, Juan Manuel Zambrano Chaves, Daniel Rubin, Imon Banerjee (2025). *Weakly supervised language models for automated extraction of critical findings from radiology reports*. ArXiv:10.1038/s41746-025-01522-4. [https://www.semanticscholar.org/paper/4ebfdf5de63d7c676b34a2b5115c07b3cb2a8bfd](https://www.semanticscholar.org/paper/4ebfdf5de63d7c676b34a2b5115c07b3cb2a8bfd)
37. Praphul Singh, Charlotte Dzialo, Jangwon Kim, Sumana Srivatsa, Irfan Bulu, Sri Gadde, K. Kenthapadi (2025). *RedactOR: An LLM-Powered Framework for Automatic Clinical Data De-Identification*. ArXiv:2505.18380. [https://www.semanticscholar.org/paper/6a8ff1b5fc096dab785873732509e29f1752fba7](https://www.semanticscholar.org/paper/6a8ff1b5fc096dab785873732509e29f1752fba7)
38. Tanmay Parekh, Yuxuan Dong, Lucas Bandarkar, Artin Kim, I-Hung Hsu, Kai-Wei Chang, Nanyun Peng (2025). *FIG: Forward-Inverse Generation for Low-Resource Domain-specific Event Detection*. ArXiv:2502.17394v1. [https://arxiv.org/pdf/2502.17394v1](https://arxiv.org/pdf/2502.17394v1)
39. Shahriar Noroozizadeh, Sayantan Kumar, Jeremy C. Weiss (2025). *Forecasting from Clinical Textual Time Series: Adaptations of the Encoder and Decoder Language Model Families*. ArXiv:10.48550/arXiv.2504.10340. [https://www.semanticscholar.org/paper/c1130a3634facb2a22edde49adb58ee6f042c585](https://www.semanticscholar.org/paper/c1130a3634facb2a22edde49adb58ee6f042c585)
40. Shahriar Noroozizadeh, Sayantan Kumar, George H. Chen, Jeremy C. Weiss (2025). *PMOA-TTS: Introducing the PubMed Open Access Textual Times Series Corpus*. ArXiv:2505.20323. [https://www.semanticscholar.org/paper/ebf5eee9f8997ebd0586817e9fa4bacc8a1dad76](https://www.semanticscholar.org/paper/ebf5eee9f8997ebd0586817e9fa4bacc8a1dad76)
41. Qinyue Zheng, Salman Abdullah, Sam Rawal, Cyril Zakka, Sophie Ostmeier, Maximilian Purk, Eduardo Reis, E.J. Topol, J. Leskovec, Michael Moor (2025). *MIRIAD: Augmenting LLMs with millions of medical query-response pairs*. ArXiv:2506.06091. [https://www.semanticscholar.org/paper/b1afad9875b76d2746c9c1bcad2c693110920987](https://www.semanticscholar.org/paper/b1afad9875b76d2746c9c1bcad2c693110920987)
42. Bernardo Magnini, Saeed Farzi, Pietro Ferrazzi, Soumitra Ghosh, A. Lavelli, Giulia Mezzanotte, Manuela Speranza (2025). *A cost-effective approach to counterbalance the scarcity of medical datasets*. ArXiv:10.3389/femer.2025.1558200. [https://www.semanticscholar.org/paper/07c373c2963516cd0ac528623a745d3173638fd6](https://www.semanticscholar.org/paper/07c373c2963516cd0ac528623a745d3173638fd6)
43. Naghme Jamali, Milad Mohammadi, Danial Baledi, Zahra Rezvani, H. Faili (2025). *PerMedCQA: Benchmarking Large Language Models on Medical Consumer Question Answering in Persian Language*. ArXiv:2505.18331. [https://www.semanticscholar.org/paper/e0aa296cd6c9fc7f2cbfde9ff9fc21f94cd860e](https://www.semanticscholar.org/paper/e0aa296cd6c9fc7f2cbfde9ff9fc21f94cd860e)
44. Yihao Ai, Zhiyuan Ning, Weiwei Dai, Pengfei Wang, Yi Du, Wenjuan Cui, Kunpeng Liu, Yuanchun Zhou (2025). *Distilling Closed-Source LLM's Knowledge for Locally Stable and Economic Biomedical Entity Linking*. ArXiv:2505.19722. [https://www.semanticscholar.org/paper/351c2d7d3ce909acdfa289eccc03464ddbd028cb](https://www.semanticscholar.org/paper/351c2d7d3ce909acdfa289eccc03464ddbd028cb)
45. An Zhao, Moucheng Xu, Ahmed H. Shahin, Wim Wuyts, Mark G. Jones, Joseph Jacob, Daniel C. Alexander (2025). *4D VQ-GAN: Synthesising Medical Scans at Any Time Point for Personalised Disease Progression Modelling of Idiopathic Pulmonary Fibrosis*. ArXiv:2502.05713v1. [https://arxiv.org/pdf/2502.05713v1](https://arxiv.org/pdf/2502.05713v1)
46. Konstantin Hess, Stefan Feuerriegel (2024). *Stabilized Neural Prediction of Potential Outcomes in Continuous Time*. ArXiv:2410.03514v3. [https://arxiv.org/pdf/2410.03514v3](https://arxiv.org/pdf/2410.03514v3)
47. Miguel Herencia García del Castillo, Ricardo Moya Garcia, Manuel Jesús Cerezo Mazón, Ekaitz Arriola Garcia, Pablo Menéndez Fernández-Miranda (2025). *Diffusion Models for conditional MRI generation*. ArXiv:2502.18620v1. [https://arxiv.org/pdf/2502.18620v1](https://arxiv.org/pdf/2502.18620v1)
48. Marco Salme, L. Tronchin, R. Sicilia, P. Soda, V. Guarrasi (2025). *Beyond the Generative Learning Trilemma: Generative Model Assessment in Data Scarcity Domains*. ArXiv:10.48550/arXiv.2504.10555. [https://www.semanticscholar.org/paper/9e14ae8063ebbd25db4eb40965e4c04babf445e4](https://www.semanticscholar.org/paper/9e14ae8063ebbd25db4eb40965e4c04babf445e4)
49. Guanglin Zhou, Sebastiano Barbieri (2025). *Generating Clinically Realistic EHR Data via a Hierarchy- and Semantics-Guided Transformer*. ArXiv:2502.20719v1. [https://arxiv.org/pdf/2502.20719v1](https://arxiv.org/pdf/2502.20719v1)
50. Yihan Lin, Zhirong Bella Yu, Simon Lee (2025). *A Case Study Exploring the Current Landscape of Synthetic Medical Record Generation with Commercial LLMs*. ArXiv:10.48550/arXiv.2504.14657. [https://www.semanticscholar.org/paper/780e184d0e0cec844353f9fd94af58100bd2bc26](https://www.semanticscholar.org/paper/780e184d0e0cec844353f9fd94af58100bd2bc26)
51. Jost Arndt, Utku Isil, Michael Detzel, Wojciech Samek, Jackie Ma (2025). *Synthetic Datasets for Machine Learning on Spatio-Temporal Graphs using PDEs*. ArXiv:2502.04140v1. [https://arxiv.org/pdf/2502.04140v1](https://arxiv.org/pdf/2502.04140v1)
52. Nina Freise, Marius Heitlinger, Ruben Nuredini, Gerrit Meixner (2025). *Automatic Prompt Optimization Techniques: Exploring the Potential for Synthetic Data Generation*. ArXiv:2502.03078v2. [https://arxiv.org/pdf/2502.03078v2](https://arxiv.org/pdf/2502.03078v2)
53. Ruxue Shi, Yili Wang, Mengnan Du, Xu Shen, Xin Wang (2025). *A Comprehensive Survey of Synthetic Tabular Data Generation*. ArXiv:10.48550/arXiv.2504.16506. [https://www.semanticscholar.org/paper/62623220ebe64c1ae134c51b73a1ab37667761d5](https://www.semanticscholar.org/paper/62623220ebe64c1ae134c51b73a1ab37667761d5)
54. Waldemar Hahn, Jan-Niklas Eckardt, C. Rollig, Martin Sedlmayr, J. Middeke, Markus Wolfien (2025). *Generating Reliable Synthetic Clinical Trial Data: The Role of Hyperparameter Optimization and Domain Constraints*. ArXiv:2505.05019. [https://www.semanticscholar.org/paper/e56e9f956e2965f02e5d3e621c600de3947cbf1a](https://www.semanticscholar.org/paper/e56e9f956e2965f02e5d3e621c600de3947cbf1a)
55. Tomer Meir, Uri Shalit, Malka Gorfine (2025). *Heterogeneous Treatment Effect in Time-to-Event Outcomes: Harnessing Censored Data with Recursively Imputed Trees*. ArXiv:2502.01575v1. [https://arxiv.org/pdf/2502.01575v1](https://arxiv.org/pdf/2502.01575v1)
56. Michelle M. Li, Kevin Li, Yasha Ektefaie, Shvat Messica, Marinka Zitnik (2025). *Controllable Sequence Editing for Counterfactual Generation*. ArXiv:2502.03569v1. [https://arxiv.org/pdf/2502.03569v1](https://arxiv.org/pdf/2502.03569v1)
57. Linna Wang, Xinyu Guo, Haoyue Shi, Yuehang Ma, Han Bao, Lihua Jiang, Li Zhao, Ziliang Feng, Tao Zhu, Li Lu (2025). *CRISP: A causal relationships-guided deep learning framework for advanced ICU mortality prediction*. ArXiv:10.1186/s12911-025-02981-1. [https://www.semanticscholar.org/paper/61bf28607fd8973bdeec162873dab240cfeefa67](https://www.semanticscholar.org/paper/61bf28607fd8973bdeec162873dab240cfeefa67)
58. Bowen Deng, Chang Xu, Hao Li, Yuhao Huang, Min Hou, Jiang Bian (2025). *TarDiff: Target-Oriented Diffusion Guidance for Synthetic Electronic Health Record Time Series Generation*. ArXiv:10.48550/arXiv.2504.17613. [https://www.semanticscholar.org/paper/63ca8f86de6b2c3299e4fd6fd28e1c24cf040341](https://www.semanticscholar.org/paper/63ca8f86de6b2c3299e4fd6fd28e1c24cf040341)
59. Ricarda Graf, Susan Todd, M. Fazil Baksh (2025). *Comparison of the Cox proportional hazards model and Random Survival Forest algorithm for predicting patient-specific survival probabilities in clinical trial data*. ArXiv:2502.03119v1. [https://arxiv.org/pdf/2502.03119v1](https://arxiv.org/pdf/2502.03119v1)
60. Wenrui Fan, L. M. Riza Rizky, Jiayang Zhang, Chen Chen, Haiping Lu, Kevin Teh, Dinesh Selvarajah, Shuo Zhou (2025). *Foundation-Model-Boosted Multimodal Learning for fMRI-based Neuropathic Pain Drug Response Prediction*. ArXiv:2503.00210v1. [https://arxiv.org/pdf/2503.00210v1](https://arxiv.org/pdf/2503.00210v1)
61. Karthick Sharma, Mokeeshan Vathanakumar, Gamika Seneviratne, Sathursan Kanagarajah (2025). *MUM: Enhancing Medical Diagnostics Through Unpaired Multimodal Data Integration*. ArXiv:10.1109/ISBI60581.2025.10981182. [https://www.semanticscholar.org/paper/adcdfc5ba7a60a05d20f9e06882817952904e36d](https://www.semanticscholar.org/paper/adcdfc5ba7a60a05d20f9e06882817952904e36d)
62. Zeyu Liu, Zhitian Hou, Yining Di, Kejing Yang, Zhijie Sang, Congkai Xie, Jingwen Yang, Siyuan Liu, Jialu Wang, Chunming Li, Ming Li, Hongxia Yang (2025). *Infi-Med: Low-Resource Medical MLLMs with Robust Reasoning Evaluation*. ArXiv:2505.23867. [https://www.semanticscholar.org/paper/fd1d271d0cb4aba04aea8a495cfb2f85e03ac310](https://www.semanticscholar.org/paper/fd1d271d0cb4aba04aea8a495cfb2f85e03ac310)
63. Chen Jin, Ryutaro Tanno, Amrutha Saseendran, Tom Diethe, Philip Teare (2025). *Diffusion Instruction Tuning*. ArXiv:2502.06814v1. [https://arxiv.org/pdf/2502.06814v1](https://arxiv.org/pdf/2502.06814v1)
64. Jiarui Ye, Hao Tang (2025). *Multimodal Large Language Models for Medicine: A Comprehensive Survey*. ArXiv:10.48550/arXiv.2504.21051. [https://www.semanticscholar.org/paper/427781f67ea66a168a323a75fad3f6958451bf8d](https://www.semanticscholar.org/paper/427781f67ea66a168a323a75fad3f6958451bf8d)
65. Faisal Abdullah, Althobaiti (2025). *A Survey on Using Large Language Models in Healthcare*. ArXiv:10.7753/ijsea1406.1001. [https://www.semanticscholar.org/paper/a4730fd88d2249de1bed9a0f1a9a7641b1caba8d](https://www.semanticscholar.org/paper/a4730fd88d2249de1bed9a0f1a9a7641b1caba8d)
66. Wenhui Zhu, Xuanzhao Dong, Xin Li, Peijie Qiu, Xiwen Chen, Abolfazl Razi, Aristeidis Sotiras, Yi Su, Yalin Wang (2025). *Toward Effective Reinforcement Learning Fine-Tuning for Medical VQA in Vision-Language Models*. ArXiv:2505.13973. [https://www.semanticscholar.org/paper/945082498d29f3f88882da6d09a20e5aefb83cb5](https://www.semanticscholar.org/paper/945082498d29f3f88882da6d09a20e5aefb83cb5)
67. Gabriele De Vito, Filomena Ferrucci, Athanasios Angelakis (2025). *LLMs for Drug-Drug Interaction Prediction: A Comprehensive Comparison*. ArXiv:2502.06890v1. [https://arxiv.org/pdf/2502.06890v1](https://arxiv.org/pdf/2502.06890v1)
68. Sara Ketabi, D. Ramachandram (2025). *Bridging Electronic Health Records and Clinical Texts: Contrastive Learning for Enhanced Clinical Tasks*. ArXiv:2505.17643. [https://www.semanticscholar.org/paper/7e6cac75f28a8e1b9be883597a56d3bb6da8bb04](https://www.semanticscholar.org/paper/7e6cac75f28a8e1b9be883597a56d3bb6da8bb04)
69. Frederike Lubeck, J. Wildberger, Frederik Trauble, Maximilian Mordig, S. Gatidis, Andreas Krause, Bernhard Scholkopf (2025). *Adaptable Cardiovascular Disease Risk Prediction from Heterogeneous Data using Large Language Models*. ArXiv:2505.24655. [https://www.semanticscholar.org/paper/bbf22ac0f6c21f3cb173b95a6c506418c2532947](https://www.semanticscholar.org/paper/bbf22ac0f6c21f3cb173b95a6c506418c2532947)
70. Md Sultan Al Nahian, Chris Delcher, Daniel Harris, Peter Akpunonu, R. Kavuluru (2025). *Large Language Models for Drug Overdose Prediction from Longitudinal Medical Records*. ArXiv:10.48550/arXiv.2504.11792. [https://www.semanticscholar.org/paper/a475b202ecc3b5ec532dcfbad7092fbe3846abf7](https://www.semanticscholar.org/paper/a475b202ecc3b5ec532dcfbad7092fbe3846abf7)
71. Ya Zhou, Yujie Yang, Jianhuang Gan, Xiangjie Li, Jing Yuan, Wei Zhao (2025). *Multi-scale Masked Autoencoder for Electrocardiogram Anomaly Detection*. ArXiv:2502.05494v1. [https://arxiv.org/pdf/2502.05494v1](https://arxiv.org/pdf/2502.05494v1)
72. Qiao Xiao, Yue Li, Khuan Lee, Siti Aisah Mokhtar, Iskasymar Ismail, Ahmad Luqman bin Md Pauzi, Poh Ying Lim (2025). *Integrating learnable expert knowledge into deep learning-based multi-label ECG classification*. ArXiv:10.1088/1361-6501/adcce7. [https://www.semanticscholar.org/paper/2470b0ffbf6641772fd9ab8530dd8e7cc162ada7](https://www.semanticscholar.org/paper/2470b0ffbf6641772fd9ab8530dd8e7cc162ada7)
73. Kamala Priya Anthani, Bhavani Madireddy (2025). *Deep learning driven electrocardiogram classification ‎with optimized convolutional neural network for ‎accurate arrhythmia detection and explainable clinical*. ArXiv:10.14419/sbrrvz11. [https://www.semanticscholar.org/paper/64b441e2c425554d380a7f29794f57346b6e2c08](https://www.semanticscholar.org/paper/64b441e2c425554d380a7f29794f57346b6e2c08)
74. Mingsheng Cai, Jiuming Jiang, Wenhao Huang, Che Liu, Rossella Arcucci (2025). *SuPreME: A Supervised Pre-training Framework for Multimodal ECG Representation Learning*. ArXiv:2502.19668v1. [https://arxiv.org/pdf/2502.19668v1](https://arxiv.org/pdf/2502.19668v1)
75. Elaheh Aghaarabi, David M Murray (2025). *Transformer-Based Language Models for Group Randomized Trial Classification in Biomedical Literature: Model Development and Validation.*. ArXiv:10.2196/63267. [https://www.semanticscholar.org/paper/bdac0e43d0bf77c037bcbe4d13ec566013af6e65](https://www.semanticscholar.org/paper/bdac0e43d0bf77c037bcbe4d13ec566013af6e65)
76. Fengze Liu, Haoyu Wang, Joonhyuk Cho, Dan Roth, Andrew W. Lo (2025). *AUTOCT: Automating Interpretable Clinical Trial Prediction with LLM Agents*. ArXiv:2506.04293. [https://www.semanticscholar.org/paper/66f9a84c44e147fdad9d983a0ca52d9284ee17f2](https://www.semanticscholar.org/paper/66f9a84c44e147fdad9d983a0ca52d9284ee17f2)
77. Joseph Lee, Tianqi Shang, Jae Young Baik, D. Duong-Tran, Shu Yang, Lingyao Li, Li Shen (2025). *Investigating LLMs in Clinical Triage: Promising Capabilities, Persistent Intersectional Biases*. ArXiv:10.48550/arXiv.2504.16273. [https://www.semanticscholar.org/paper/7e0034d2f5a8d1d6ec7d5ea19b2e2100b02021c6](https://www.semanticscholar.org/paper/7e0034d2f5a8d1d6ec7d5ea19b2e2100b02021c6)
78. Ali Amirahmadi, Farzaneh Etminani, Jonas Björk, Olle Melander, Mattias Ohlsson (2025). *Trajectory-Ordered Objectives for Self-Supervised Representation Learning of Temporal Healthcare Data Using Transformers: Model Development and Evaluation Study.*. ArXiv:10.2196/68138. [https://www.semanticscholar.org/paper/b4f2f2cd5f9cf6af81521c86ad47bf50107d6561](https://www.semanticscholar.org/paper/b4f2f2cd5f9cf6af81521c86ad47bf50107d6561)
79. Sheng Zhang, Qin Liu, N. Usuyama, Cliff Wong, Tristan Naumann, H. Poon (2025). *Exploring Scaling Laws for EHR Foundation Models*. ArXiv:2505.22964. [https://www.semanticscholar.org/paper/0460ef4c042f24faf9ebc139279af62e4aceb0f7](https://www.semanticscholar.org/paper/0460ef4c042f24faf9ebc139279af62e4aceb0f7)
80. Chao Pang, Vincent Jeanselme, Young Sang Choi, Xinzhuo Jiang, Zilin Jing, Aparajita Kashyap, Yuta Kobayashi, Yanwei Li, Florent Pollet, Karthik Natarajan, Shalmali Joshi (2025). *FoMoH: A clinically meaningful foundation model evaluation for structured electronic health records*. ArXiv:2505.16941. [https://www.semanticscholar.org/paper/ae943be2991f4e8d4ca5dc0185747fa1d5915dba](https://www.semanticscholar.org/paper/ae943be2991f4e8d4ca5dc0185747fa1d5915dba)
81. Dr. Vijay Kumar Salvia, Ms. Vasundhara, Manthena Swapna Kumari, B. Sruthi, Shobhanjaly P. Nair, P. Devasudha (2025). *Deep Learning-Based Early Detection of Rare Diseases Using Electronic Health Records*. ArXiv:10.63682/jns.v14i14s.3653. [https://www.semanticscholar.org/paper/563d994acaf43f3bdcf4e4ebb7146f41a9085511](https://www.semanticscholar.org/paper/563d994acaf43f3bdcf4e4ebb7146f41a9085511)
82. Liwen Sun, Hao-Ren Yao, Gary Gao, O. Frieder, Chenyan Xiong (2025). *Intercept Cancer: Cancer Pre-Screening with Large Scale Healthcare Foundation Models*. ArXiv:2506.00209. [https://www.semanticscholar.org/paper/196d14249ca8f448002a62c8766f48895a15d5c5](https://www.semanticscholar.org/paper/196d14249ca8f448002a62c8766f48895a15d5c5)
83. Che Liu, Haozhe Wang, Jiazhen Pan, Zhongwei Wan, Yong Dai, Fangzhen Lin, Wenjia Bai, D. Rueckert, Rossella Arcucci (2025). *Beyond Distillation: Pushing the Limits of Medical LLM Reasoning with Minimalist Rule-Based RL*. ArXiv:2505.17952. [https://www.semanticscholar.org/paper/bb26c61cbe322a4f8cf81e8e461d680a5ff05923](https://www.semanticscholar.org/paper/bb26c61cbe322a4f8cf81e8e461d680a5ff05923)
84. Daniil Filienko, Mahek Nizar, Javier Roberti, Denise Galdamez, Haroon Jakher, Sarah Iribarren, Weichao Yuwen, Martine De Cock (2025). *Transforming Tuberculosis Care: Optimizing Large Language Models For Enhanced Clinician-Patient Communication*. ArXiv:2502.21236v1. [https://arxiv.org/pdf/2502.21236v1](https://arxiv.org/pdf/2502.21236v1)
85. Amin Dada, Osman Alperen Koras, Marie Bauer, Amanda Butler, Kaleb E. Smith, Jens Kleesiek, Julian Friedrich (2025). *MeDiSumQA: Patient-Oriented Question-Answer Generation from Discharge Letters*. ArXiv:2502.03298v1. [https://arxiv.org/pdf/2502.03298v1](https://arxiv.org/pdf/2502.03298v1)
86. Mouath Abu Daoud, Chaimae Abouzahir, Leen Kharouf, Walid Al-Eisawi, Nizar Habash, Farah E. Shamout (2025). *MedArabiQ: Benchmarking Large Language Models on Arabic Medical Tasks*. ArXiv:2505.03427. [https://www.semanticscholar.org/paper/00873a8228e515b87a0e0690cff8fbc1e71200e9](https://www.semanticscholar.org/paper/00873a8228e515b87a0e0690cff8fbc1e71200e9)
87. Mehrdad ghassabi, Pedram Rostami, Hamidreza Baradaran Kashani, Amirhossein Poursina, Zahra Kazemi, M. Tavakoli (2025). *Leveraging Online Data to Enhance Medical Knowledge in a Small Persian Language Model*. ArXiv:2505.16000. [https://www.semanticscholar.org/paper/c06557b713b5e327e668fd25abaf20fabafd6bea](https://www.semanticscholar.org/paper/c06557b713b5e327e668fd25abaf20fabafd6bea)
88. Sangwon Seo, Bing Han, Rayan E. Harari, Roger D. Dias, Marco A. Zenati, Eduardo Salas, Vaibhav Unhelkar (2025). *Socratic: Enhancing Human Teamwork via AI-enabled Coaching*. ArXiv:2502.17643v1. [https://arxiv.org/pdf/2502.17643v1](https://arxiv.org/pdf/2502.17643v1)
89. Vedant Khandelwal, Kaushik Roy, Valerie Lookingbill, Ritvik Garimella, Harshul Surana, Heather Heckman, Amit Sheth (2025). *NeuroLit Navigator: A Neurosymbolic Approach to Scholarly Article Searches for Systematic Reviews*. ArXiv:2503.00278v1. [https://arxiv.org/pdf/2503.00278v1](https://arxiv.org/pdf/2503.00278v1)
90. Muhammad Zain Raza, Jiawei Xu, Terence Lim, Lily Boddy, Carlos M. Mery, Andrew Well, Ying Ding (2025). *LLM-TA: An LLM-Enhanced Thematic Analysis Pipeline for Transcripts from Parents of Children with Congenital Heart Disease*. ArXiv:2502.01620v1. [https://arxiv.org/pdf/2502.01620v1](https://arxiv.org/pdf/2502.01620v1)
91. Sean Wu, Michael Koo, Fabien Scalzo, Ira Kurtz (2025). *AutoMedPrompt: A New Framework for Optimizing LLM Medical Prompts Using Textual Gradients*. ArXiv:2502.15944v1. [https://arxiv.org/pdf/2502.15944v1](https://arxiv.org/pdf/2502.15944v1)
92. Zheling Tan, Kexin Ding, Jin Gao, Mu Zhou, Dimitris Metaxas, Shaoting Zhang, Dequan Wang (2025). *MedForge: Building Medical Foundation Models Like Open Source Software Development*. ArXiv:2502.16055v1. [https://arxiv.org/pdf/2502.16055v1](https://arxiv.org/pdf/2502.16055v1)
93. Yuchen Zhuang, Jingfeng Yang, Haoming Jiang, Xin Liu, Kewei Cheng, Sanket Lokegaonkar, Yifan Gao, Qing Ping, Tianyi Liu, Binxuan Huang, Zheng Li, Zhengyang Wang, Pei Chen, Ruijie Wang, Rongzhi Zhang, Nasser Zalmout, Priyanka Nigam, Bing Yin, Chao Zhang (2025). *Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training*. ArXiv:2502.06589v1. [https://arxiv.org/pdf/2502.06589v1](https://arxiv.org/pdf/2502.06589v1)
94. Zhi-Hao Tan, Zi-Chen Zhao, Hao-Yu Shi, Xin-Yu Zhang, Peng Tan, Yang Yu, Zhi-Hua Zhou (2025). *Learnware of Language Models: Specialized Small Language Models Can Do Big*. ArXiv:2505.13425. [https://www.semanticscholar.org/paper/ccef102e80438c5ea9901c0e13198cfd3e685e87](https://www.semanticscholar.org/paper/ccef102e80438c5ea9901c0e13198cfd3e685e87)
95. Ebtehal H. Omoush, Rawan Ghnemat (2025). *Advancing Arabic Medical Question Answering Systems with RAG and LLMs Integration*. ArXiv:10.1109/ICTCS65341.2025.10989446. [https://www.semanticscholar.org/paper/c0239788924415765305bd23e054dd06404f866b](https://www.semanticscholar.org/paper/c0239788924415765305bd23e054dd06404f866b)
96. Mario Ceresa, Lorenzo Bertolini, Valentin Comte, Nicholas Spadaro, B. Raffael, Brigitte Toussaint, Sergio Consoli, Amalia Munoz Pineiro, Alex Patak, M. Querci, Tobias Wiesenthal (2025). *Retrieval Augmented Generation Evaluation for Health Documents*. ArXiv:2505.04680. [https://www.semanticscholar.org/paper/78452726f73fa58e22391cc8b3b7819f38fc24bf](https://www.semanticscholar.org/paper/78452726f73fa58e22391cc8b3b7819f38fc24bf)
97. Kai Zhang, Rui Zhu, Shutian Ma, Jingwei Xiong, Yejin Kim, Fabricio Murai, Xiaozhong Liu (2025). *KEDRec-LM: A Knowledge-distilled Explainable Drug Recommendation Large Language Model*. ArXiv:2502.20350v1. [https://arxiv.org/pdf/2502.20350v1](https://arxiv.org/pdf/2502.20350v1)
98. Haonan Zhu, Mary Silva, Jose Cadena, Braden Soper, Michał Lisicki, Braian Peetoom, Sergio E. Baranzini, Shivshankar Sundaram, Priyadip Ray, Jeff Drocco (2025). *Deep Active Learning based Experimental Design to Uncover Synergistic Genetic Interactions for Host Targeted Therapeutics*. ArXiv:2502.01012v1. [https://arxiv.org/pdf/2502.01012v1](https://arxiv.org/pdf/2502.01012v1)
99. Bingxuan Li, Yiwei Wang, Jiuxiang Gu, Kai-Wei Chang, Nanyun Peng (2025). *METAL: A Multi-Agent Framework for Chart Generation with Test-Time Scaling*. ArXiv:2502.17651v3. [https://arxiv.org/pdf/2502.17651v3](https://arxiv.org/pdf/2502.17651v3)
100. Yinuo Wang, Robert E. Mercer, Frank Rudzicz, Sudipta Singha Roy, Pengjie Ren, Zhumin Chen, Xindi Wang (2025). *Trustworthy Medical Question Answering: An Evaluation-Centric Survey*. ArXiv:2506.03659. [https://www.semanticscholar.org/paper/cf927d5a0044eb56d203335949067c69c8184a45](https://www.semanticscholar.org/paper/cf927d5a0044eb56d203335949067c69c8184a45)
101. Mohit Gupta, Akiko Aizawa, R. Shah (2025). *Med-CoDE: Medical Critique based Disagreement Evaluation Framework*. ArXiv:10.48550/arXiv.2504.15330. [https://www.semanticscholar.org/paper/3c1c0364f3e1e7bbe6bcd5da4325888ca2bf3079](https://www.semanticscholar.org/paper/3c1c0364f3e1e7bbe6bcd5da4325888ca2bf3079)
102. Xiechi Zhang, Zetian Ouyang, Linlin Wang, Gerard de Melo, Zhu Cao, Xiaoling Wang, Ya Zhang, Yanfeng Wang, Liang He (2025). *AutoMedEval: Harnessing Language Models for Automatic Medical Capability Evaluation*. ArXiv:2505.11887. [https://www.semanticscholar.org/paper/dd9cb2ff121325bb6158df49b5df8243c815df67](https://www.semanticscholar.org/paper/dd9cb2ff121325bb6158df49b5df8243c815df67)
